{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanjan02/four_fruit_classification/blob/master/fruit_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3xlfCA3FM-FF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.cluster import KMeans, estimate_bandwidth, MeanShift\n",
        "from glob import glob\n",
        "import cv2\n",
        "import fnmatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eJcZv4zNORw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9adb98f-7431-40f4-f0fb-1f973737e829"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HSJCH_1rNaYe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.load('/content/drive/My Drive/x_train.npy')\n",
        "y = np.load('/content/drive/My Drive/y_train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72Hh_h46PehX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 101)\n",
        "y_train = to_categorical(y_train, num_classes = 4)\n",
        "y_valid = to_categorical(y_valid, num_classes = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cilu36SfOdPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1138
        },
        "outputId": "2ab2e535-5e4c-43b1-8500-6922e3d1b724"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.vgg19 import VGG19\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = VGG19(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 3s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 4004      \n",
            "=================================================================\n",
            "Total params: 20,541,388\n",
            "Trainable params: 517,004\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ud5Lkqr8QRex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5441
        },
        "outputId": "2e812491-74ab-4333-a6a7-08b298cd7d53"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 150, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/150\n",
            "192/192 [==============================] - 7s 38ms/step - loss: 3.0756 - acc: 0.6146 - val_loss: 2.5266 - val_acc: 0.8333\n",
            "Epoch 2/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.1314 - acc: 0.9167 - val_loss: 2.4989 - val_acc: 0.8125\n",
            "Epoch 3/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6899 - val_acc: 0.8125\n",
            "Epoch 4/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.1067 - acc: 0.9271 - val_loss: 2.7798 - val_acc: 0.8125\n",
            "Epoch 5/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.7335 - val_acc: 0.8125\n",
            "Epoch 6/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.7025 - val_acc: 0.8125\n",
            "Epoch 7/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6851 - val_acc: 0.8125\n",
            "Epoch 8/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6746 - val_acc: 0.8125\n",
            "Epoch 9/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6685 - val_acc: 0.8125\n",
            "Epoch 10/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6650 - val_acc: 0.8125\n",
            "Epoch 11/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6630 - val_acc: 0.8125\n",
            "Epoch 12/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6619 - val_acc: 0.8125\n",
            "Epoch 13/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6612 - val_acc: 0.8125\n",
            "Epoch 14/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6609 - val_acc: 0.8125\n",
            "Epoch 15/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6607 - val_acc: 0.8125\n",
            "Epoch 16/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6606 - val_acc: 0.8125\n",
            "Epoch 17/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6605 - val_acc: 0.8125\n",
            "Epoch 18/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6605 - val_acc: 0.8125\n",
            "Epoch 19/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 20/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 21/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 22/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 23/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 24/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 25/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6604 - val_acc: 0.8125\n",
            "Epoch 26/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 27/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 28/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 29/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 30/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 31/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 32/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 33/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 34/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6603 - val_acc: 0.8125\n",
            "Epoch 35/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 36/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 37/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 38/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 39/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 40/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 41/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6602 - val_acc: 0.8125\n",
            "Epoch 42/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 43/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 44/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 45/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 46/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 47/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 48/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6601 - val_acc: 0.8125\n",
            "Epoch 49/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6600 - val_acc: 0.8125\n",
            "Epoch 50/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6600 - val_acc: 0.8125\n",
            "Epoch 51/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6600 - val_acc: 0.8125\n",
            "Epoch 52/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6600 - val_acc: 0.8125\n",
            "Epoch 53/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6600 - val_acc: 0.8125\n",
            "Epoch 54/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 55/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 56/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 57/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 58/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 59/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6599 - val_acc: 0.8125\n",
            "Epoch 60/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6598 - val_acc: 0.8125\n",
            "Epoch 61/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6598 - val_acc: 0.8125\n",
            "Epoch 62/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6598 - val_acc: 0.8125\n",
            "Epoch 63/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6598 - val_acc: 0.8125\n",
            "Epoch 64/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6598 - val_acc: 0.8125\n",
            "Epoch 65/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6597 - val_acc: 0.8125\n",
            "Epoch 66/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6597 - val_acc: 0.8125\n",
            "Epoch 67/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6597 - val_acc: 0.8125\n",
            "Epoch 68/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6597 - val_acc: 0.8125\n",
            "Epoch 69/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6597 - val_acc: 0.8125\n",
            "Epoch 70/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6596 - val_acc: 0.8125\n",
            "Epoch 71/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6596 - val_acc: 0.8125\n",
            "Epoch 72/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6596 - val_acc: 0.8125\n",
            "Epoch 73/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6596 - val_acc: 0.8125\n",
            "Epoch 74/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6596 - val_acc: 0.8125\n",
            "Epoch 75/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6595 - val_acc: 0.8125\n",
            "Epoch 76/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6595 - val_acc: 0.8125\n",
            "Epoch 77/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6595 - val_acc: 0.8125\n",
            "Epoch 78/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6595 - val_acc: 0.8125\n",
            "Epoch 79/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6595 - val_acc: 0.8125\n",
            "Epoch 80/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6594 - val_acc: 0.8125\n",
            "Epoch 81/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6594 - val_acc: 0.8125\n",
            "Epoch 82/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6594 - val_acc: 0.8125\n",
            "Epoch 83/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6594 - val_acc: 0.8125\n",
            "Epoch 84/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6594 - val_acc: 0.8125\n",
            "Epoch 85/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6593 - val_acc: 0.8125\n",
            "Epoch 86/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6593 - val_acc: 0.8125\n",
            "Epoch 87/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6593 - val_acc: 0.8125\n",
            "Epoch 88/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6593 - val_acc: 0.8125\n",
            "Epoch 89/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6592 - val_acc: 0.8125\n",
            "Epoch 90/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6592 - val_acc: 0.8125\n",
            "Epoch 91/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6592 - val_acc: 0.8125\n",
            "Epoch 92/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6592 - val_acc: 0.8125\n",
            "Epoch 93/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6592 - val_acc: 0.8125\n",
            "Epoch 94/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6591 - val_acc: 0.8125\n",
            "Epoch 95/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6591 - val_acc: 0.8125\n",
            "Epoch 96/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6591 - val_acc: 0.8125\n",
            "Epoch 97/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6591 - val_acc: 0.8125\n",
            "Epoch 98/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6590 - val_acc: 0.8125\n",
            "Epoch 99/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6590 - val_acc: 0.8125\n",
            "Epoch 100/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6590 - val_acc: 0.8125\n",
            "Epoch 101/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6590 - val_acc: 0.8125\n",
            "Epoch 102/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6589 - val_acc: 0.8125\n",
            "Epoch 103/150\n",
            "192/192 [==============================] - 3s 13ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6589 - val_acc: 0.8125\n",
            "Epoch 104/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6589 - val_acc: 0.8125\n",
            "Epoch 105/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6589 - val_acc: 0.8125\n",
            "Epoch 106/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6588 - val_acc: 0.8125\n",
            "Epoch 107/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6588 - val_acc: 0.8125\n",
            "Epoch 108/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6588 - val_acc: 0.8125\n",
            "Epoch 109/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6588 - val_acc: 0.8125\n",
            "Epoch 110/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6587 - val_acc: 0.8125\n",
            "Epoch 111/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6587 - val_acc: 0.8125\n",
            "Epoch 112/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6587 - val_acc: 0.8125\n",
            "Epoch 113/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6587 - val_acc: 0.8125\n",
            "Epoch 114/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6586 - val_acc: 0.8125\n",
            "Epoch 115/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6586 - val_acc: 0.8125\n",
            "Epoch 116/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6586 - val_acc: 0.8125\n",
            "Epoch 117/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6586 - val_acc: 0.8125\n",
            "Epoch 118/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6585 - val_acc: 0.8125\n",
            "Epoch 119/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6585 - val_acc: 0.8125\n",
            "Epoch 120/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6585 - val_acc: 0.8125\n",
            "Epoch 121/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6584 - val_acc: 0.8125\n",
            "Epoch 122/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6584 - val_acc: 0.8125\n",
            "Epoch 123/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6584 - val_acc: 0.8125\n",
            "Epoch 124/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6584 - val_acc: 0.8125\n",
            "Epoch 125/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6583 - val_acc: 0.8125\n",
            "Epoch 126/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6583 - val_acc: 0.8125\n",
            "Epoch 127/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6583 - val_acc: 0.8125\n",
            "Epoch 128/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6582 - val_acc: 0.8125\n",
            "Epoch 129/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6582 - val_acc: 0.8125\n",
            "Epoch 130/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6582 - val_acc: 0.8125\n",
            "Epoch 131/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6582 - val_acc: 0.8125\n",
            "Epoch 132/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6581 - val_acc: 0.8125\n",
            "Epoch 133/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6581 - val_acc: 0.8125\n",
            "Epoch 134/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6581 - val_acc: 0.8125\n",
            "Epoch 135/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6581 - val_acc: 0.8125\n",
            "Epoch 136/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6580 - val_acc: 0.8125\n",
            "Epoch 137/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6580 - val_acc: 0.8125\n",
            "Epoch 138/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6580 - val_acc: 0.8125\n",
            "Epoch 139/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6579 - val_acc: 0.8125\n",
            "Epoch 140/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6579 - val_acc: 0.8125\n",
            "Epoch 141/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6579 - val_acc: 0.8125\n",
            "Epoch 142/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6579 - val_acc: 0.8125\n",
            "Epoch 143/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6578 - val_acc: 0.8125\n",
            "Epoch 144/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6578 - val_acc: 0.8125\n",
            "Epoch 145/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6578 - val_acc: 0.8125\n",
            "Epoch 146/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6577 - val_acc: 0.8125\n",
            "Epoch 147/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6577 - val_acc: 0.8125\n",
            "Epoch 148/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6577 - val_acc: 0.8125\n",
            "Epoch 149/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6576 - val_acc: 0.8125\n",
            "Epoch 150/150\n",
            "192/192 [==============================] - 3s 14ms/step - loss: 1.0913 - acc: 0.9323 - val_loss: 2.6576 - val_acc: 0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2N3jY1d0r-On",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6825
        },
        "outputId": "ac44bf2f-8f23-46bb-cb76-c1f66c1cb475"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.resnet50 import ResNet50\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = ResNet50(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            4004        dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,640,716\n",
            "Trainable params: 2,053,004\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "giZkbibAw5ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5367
        },
        "outputId": "83cbbfc3-035e-4fa5-ab22-eb1618514d8b"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 150, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/150\n",
            "192/192 [==============================] - 5s 26ms/step - loss: 2.1376 - acc: 0.5104 - val_loss: 1.1888 - val_acc: 0.7500\n",
            "Epoch 2/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.3602 - acc: 0.8646 - val_loss: 0.4254 - val_acc: 0.8542\n",
            "Epoch 3/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0737 - acc: 0.9688 - val_loss: 1.0261 - val_acc: 0.7292\n",
            "Epoch 4/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0993 - acc: 0.9792 - val_loss: 0.7022 - val_acc: 0.7917\n",
            "Epoch 5/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0241 - acc: 0.9896 - val_loss: 0.4638 - val_acc: 0.8750\n",
            "Epoch 6/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.8958\n",
            "Epoch 7/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5364 - val_acc: 0.8333\n",
            "Epoch 8/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 0.8333\n",
            "Epoch 9/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.6864 - val_acc: 0.8333\n",
            "Epoch 10/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6824 - val_acc: 0.8333\n",
            "Epoch 11/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.3823e-04 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.8333\n",
            "Epoch 12/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.7270e-04 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8333\n",
            "Epoch 13/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8333\n",
            "Epoch 14/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.4199e-04 - acc: 1.0000 - val_loss: 0.6703 - val_acc: 0.8333\n",
            "Epoch 15/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.2725e-04 - acc: 1.0000 - val_loss: 0.6743 - val_acc: 0.8333\n",
            "Epoch 16/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 0.8333\n",
            "Epoch 17/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.8333\n",
            "Epoch 18/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.1636e-04 - acc: 1.0000 - val_loss: 0.7168 - val_acc: 0.8333\n",
            "Epoch 19/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.3273e-04 - acc: 1.0000 - val_loss: 0.7290 - val_acc: 0.8333\n",
            "Epoch 20/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.6557e-04 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.8333\n",
            "Epoch 21/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.5718e-04 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.8333\n",
            "Epoch 22/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.8804e-04 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.8333\n",
            "Epoch 23/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.8333\n",
            "Epoch 24/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7155 - val_acc: 0.8333\n",
            "Epoch 25/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.2380e-04 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.8333\n",
            "Epoch 26/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.6547e-04 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 0.8333\n",
            "Epoch 27/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.9539e-04 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.8333\n",
            "Epoch 28/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.0768e-04 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8333\n",
            "Epoch 29/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.8696e-04 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.8333\n",
            "Epoch 30/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.9046e-04 - acc: 1.0000 - val_loss: 0.6933 - val_acc: 0.8333\n",
            "Epoch 31/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.5086e-04 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.8333\n",
            "Epoch 32/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.2245e-04 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.8542\n",
            "Epoch 33/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.8830e-04 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.8333\n",
            "Epoch 34/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.6386e-04 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 0.8333\n",
            "Epoch 35/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.1694e-04 - acc: 1.0000 - val_loss: 0.7556 - val_acc: 0.8542\n",
            "Epoch 36/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9368e-04 - acc: 1.0000 - val_loss: 0.7493 - val_acc: 0.8542\n",
            "Epoch 37/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.9014e-04 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.8542\n",
            "Epoch 38/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.2992e-04 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.8542\n",
            "Epoch 39/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.0590e-04 - acc: 1.0000 - val_loss: 0.7487 - val_acc: 0.8542\n",
            "Epoch 40/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.4910e-04 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.8542\n",
            "Epoch 41/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.2448e-04 - acc: 1.0000 - val_loss: 0.7401 - val_acc: 0.8542\n",
            "Epoch 42/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.0701e-04 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.8542\n",
            "Epoch 43/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.5322e-04 - acc: 1.0000 - val_loss: 0.7214 - val_acc: 0.8542\n",
            "Epoch 44/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.4623e-04 - acc: 1.0000 - val_loss: 0.7189 - val_acc: 0.8333\n",
            "Epoch 45/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.9146e-04 - acc: 1.0000 - val_loss: 0.7247 - val_acc: 0.8333\n",
            "Epoch 46/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.5530e-04 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.8333\n",
            "Epoch 47/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.3942e-04 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.8333\n",
            "Epoch 48/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.6055e-04 - acc: 1.0000 - val_loss: 0.7784 - val_acc: 0.8333\n",
            "Epoch 49/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.8827e-04 - acc: 1.0000 - val_loss: 0.7763 - val_acc: 0.8333\n",
            "Epoch 50/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.1400e-04 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.8333\n",
            "Epoch 51/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9200e-04 - acc: 1.0000 - val_loss: 0.7438 - val_acc: 0.8333\n",
            "Epoch 52/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.4359e-04 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.8333\n",
            "Epoch 53/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.0300e-04 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.8333\n",
            "Epoch 54/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.1032e-04 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 0.8333\n",
            "Epoch 55/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.4329e-04 - acc: 1.0000 - val_loss: 0.7173 - val_acc: 0.8333\n",
            "Epoch 56/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.4828e-04 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 0.8333\n",
            "Epoch 57/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.1361e-04 - acc: 1.0000 - val_loss: 0.7458 - val_acc: 0.8333\n",
            "Epoch 58/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9013e-04 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.8333\n",
            "Epoch 59/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.6528e-04 - acc: 1.0000 - val_loss: 0.7447 - val_acc: 0.8333\n",
            "Epoch 60/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.1864e-04 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.8333\n",
            "Epoch 61/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2208e-04 - acc: 1.0000 - val_loss: 0.7394 - val_acc: 0.8333\n",
            "Epoch 62/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.0206e-05 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.8333\n",
            "Epoch 63/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.3600e-05 - acc: 1.0000 - val_loss: 0.7413 - val_acc: 0.8333\n",
            "Epoch 64/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.3782e-05 - acc: 1.0000 - val_loss: 0.7445 - val_acc: 0.8333\n",
            "Epoch 65/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2931e-04 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.8333\n",
            "Epoch 66/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.7032e-04 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.8333\n",
            "Epoch 67/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.1541e-04 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 0.8333\n",
            "Epoch 68/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.8339e-05 - acc: 1.0000 - val_loss: 0.7800 - val_acc: 0.8333\n",
            "Epoch 69/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.9586e-05 - acc: 1.0000 - val_loss: 0.7811 - val_acc: 0.8333\n",
            "Epoch 70/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.9820e-05 - acc: 1.0000 - val_loss: 0.7824 - val_acc: 0.8333\n",
            "Epoch 71/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.6002e-04 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.8333\n",
            "Epoch 72/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2186e-04 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.8333\n",
            "Epoch 73/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.3127e-05 - acc: 1.0000 - val_loss: 0.7622 - val_acc: 0.8333\n",
            "Epoch 74/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9631 - val_acc: 0.8125\n",
            "Epoch 75/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.0148e-04 - acc: 1.0000 - val_loss: 1.0300 - val_acc: 0.8125\n",
            "Epoch 76/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.4376e-04 - acc: 1.0000 - val_loss: 1.0248 - val_acc: 0.8125\n",
            "Epoch 77/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6556 - val_acc: 0.8542\n",
            "Epoch 78/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.8262e-04 - acc: 1.0000 - val_loss: 0.4910 - val_acc: 0.8958\n",
            "Epoch 79/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4583 - val_acc: 0.8958\n",
            "Epoch 80/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.8590e-04 - acc: 1.0000 - val_loss: 0.6802 - val_acc: 0.8958\n",
            "Epoch 81/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.6246e-04 - acc: 1.0000 - val_loss: 0.9263 - val_acc: 0.8125\n",
            "Epoch 82/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.4135e-04 - acc: 1.0000 - val_loss: 0.9453 - val_acc: 0.8333\n",
            "Epoch 83/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.5252e-04 - acc: 1.0000 - val_loss: 1.0109 - val_acc: 0.8333\n",
            "Epoch 84/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2594e-04 - acc: 1.0000 - val_loss: 1.0378 - val_acc: 0.8125\n",
            "Epoch 85/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8006e-04 - acc: 1.0000 - val_loss: 1.0082 - val_acc: 0.8125\n",
            "Epoch 86/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.1319e-04 - acc: 1.0000 - val_loss: 0.9603 - val_acc: 0.8125\n",
            "Epoch 87/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.9955e-05 - acc: 1.0000 - val_loss: 0.9182 - val_acc: 0.8333\n",
            "Epoch 88/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9117e-04 - acc: 1.0000 - val_loss: 0.9132 - val_acc: 0.8333\n",
            "Epoch 89/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.0988e-04 - acc: 1.0000 - val_loss: 0.9265 - val_acc: 0.8333\n",
            "Epoch 90/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.4622e-05 - acc: 1.0000 - val_loss: 0.9295 - val_acc: 0.8333\n",
            "Epoch 91/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8422e-04 - acc: 1.0000 - val_loss: 0.9020 - val_acc: 0.8333\n",
            "Epoch 92/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9566e-04 - acc: 1.0000 - val_loss: 0.8774 - val_acc: 0.8333\n",
            "Epoch 93/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.7841e-05 - acc: 1.0000 - val_loss: 0.8667 - val_acc: 0.8333\n",
            "Epoch 94/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.5364e-04 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.8333\n",
            "Epoch 95/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2602e-04 - acc: 1.0000 - val_loss: 0.7050 - val_acc: 0.8542\n",
            "Epoch 96/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.3041e-05 - acc: 1.0000 - val_loss: 0.6864 - val_acc: 0.8542\n",
            "Epoch 97/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8709e-04 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.8542\n",
            "Epoch 98/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 7.0462e-05 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.8333\n",
            "Epoch 99/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.6606e-05 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.8333\n",
            "Epoch 100/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.5320e-05 - acc: 1.0000 - val_loss: 0.7555 - val_acc: 0.8333\n",
            "Epoch 101/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.3497e-05 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.8333\n",
            "Epoch 102/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.6361e-05 - acc: 1.0000 - val_loss: 0.7778 - val_acc: 0.8333\n",
            "Epoch 103/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.5854e-05 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.8333\n",
            "Epoch 104/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.0451e-05 - acc: 1.0000 - val_loss: 0.8009 - val_acc: 0.8333\n",
            "Epoch 105/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.1193e-05 - acc: 1.0000 - val_loss: 0.8085 - val_acc: 0.8333\n",
            "Epoch 106/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.7472e-05 - acc: 1.0000 - val_loss: 0.8160 - val_acc: 0.8333\n",
            "Epoch 107/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.1247e-04 - acc: 1.0000 - val_loss: 0.8102 - val_acc: 0.8333\n",
            "Epoch 108/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.6408e-05 - acc: 1.0000 - val_loss: 0.8054 - val_acc: 0.8333\n",
            "Epoch 109/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.9452e-04 - acc: 1.0000 - val_loss: 0.8121 - val_acc: 0.8333\n",
            "Epoch 110/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.3784e-04 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.8333\n",
            "Epoch 111/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.2123e-05 - acc: 1.0000 - val_loss: 0.9396 - val_acc: 0.8333\n",
            "Epoch 112/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 8.4723e-05 - acc: 1.0000 - val_loss: 0.9671 - val_acc: 0.8125\n",
            "Epoch 113/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.8355e-04 - acc: 1.0000 - val_loss: 0.8889 - val_acc: 0.8333\n",
            "Epoch 114/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.6102e-05 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.8333\n",
            "Epoch 115/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.8340e-05 - acc: 1.0000 - val_loss: 0.8088 - val_acc: 0.8333\n",
            "Epoch 116/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.6709e-05 - acc: 1.0000 - val_loss: 0.7947 - val_acc: 0.8333\n",
            "Epoch 117/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.1812e-05 - acc: 1.0000 - val_loss: 0.7904 - val_acc: 0.8333\n",
            "Epoch 118/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.3167e-04 - acc: 1.0000 - val_loss: 0.7963 - val_acc: 0.8333\n",
            "Epoch 119/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.2253e-05 - acc: 1.0000 - val_loss: 0.8227 - val_acc: 0.8333\n",
            "Epoch 120/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.3804e-05 - acc: 1.0000 - val_loss: 0.8379 - val_acc: 0.8333\n",
            "Epoch 121/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.1753e-05 - acc: 1.0000 - val_loss: 0.8459 - val_acc: 0.8333\n",
            "Epoch 122/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 6.4344e-05 - acc: 1.0000 - val_loss: 0.8414 - val_acc: 0.8333\n",
            "Epoch 123/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8650e-05 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.8333\n",
            "Epoch 124/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.9715e-05 - acc: 1.0000 - val_loss: 0.8315 - val_acc: 0.8333\n",
            "Epoch 125/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.8188e-05 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.8333\n",
            "Epoch 126/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.9231e-05 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.8333\n",
            "Epoch 127/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.2296e-05 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.8333\n",
            "Epoch 128/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8906e-05 - acc: 1.0000 - val_loss: 0.8264 - val_acc: 0.8333\n",
            "Epoch 129/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.6746e-05 - acc: 1.0000 - val_loss: 0.8252 - val_acc: 0.8333\n",
            "Epoch 130/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.1733e-05 - acc: 1.0000 - val_loss: 0.8140 - val_acc: 0.8333\n",
            "Epoch 131/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.5386e-05 - acc: 1.0000 - val_loss: 0.8092 - val_acc: 0.8333\n",
            "Epoch 132/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.7405e-05 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.8333\n",
            "Epoch 133/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 9.5360e-05 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 0.8333\n",
            "Epoch 134/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.1350e-05 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.8333\n",
            "Epoch 135/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.6767e-05 - acc: 1.0000 - val_loss: 0.8023 - val_acc: 0.8333\n",
            "Epoch 136/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.1424e-05 - acc: 1.0000 - val_loss: 0.8045 - val_acc: 0.8333\n",
            "Epoch 137/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.4599e-05 - acc: 1.0000 - val_loss: 0.8018 - val_acc: 0.8333\n",
            "Epoch 138/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.8161e-04 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.8333\n",
            "Epoch 139/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.6250e-05 - acc: 1.0000 - val_loss: 0.8135 - val_acc: 0.8333\n",
            "Epoch 140/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 5.4225e-05 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.8333\n",
            "Epoch 141/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 3.4309e-05 - acc: 1.0000 - val_loss: 0.8346 - val_acc: 0.8333\n",
            "Epoch 142/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.5346e-05 - acc: 1.0000 - val_loss: 0.8397 - val_acc: 0.8333\n",
            "Epoch 143/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.6951e-05 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.8333\n",
            "Epoch 144/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2010e-05 - acc: 1.0000 - val_loss: 0.8431 - val_acc: 0.8333\n",
            "Epoch 145/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.0750e-05 - acc: 1.0000 - val_loss: 0.8451 - val_acc: 0.8333\n",
            "Epoch 146/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.0816e-04 - acc: 1.0000 - val_loss: 0.8442 - val_acc: 0.8333\n",
            "Epoch 147/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.6918e-05 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.8333\n",
            "Epoch 148/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 1.2261e-04 - acc: 1.0000 - val_loss: 0.8747 - val_acc: 0.8333\n",
            "Epoch 149/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 2.0363e-05 - acc: 1.0000 - val_loss: 0.8530 - val_acc: 0.8333\n",
            "Epoch 150/150\n",
            "192/192 [==============================] - 2s 10ms/step - loss: 4.3370e-05 - acc: 1.0000 - val_loss: 0.8387 - val_acc: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8xSVxWQzOfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d1d1174c-83b0-495b-c20d-67741d7c27a2"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4FGW6/vFvZyMQkpBgAgYIYlxQ\nEGQRxQQQBIKDelxAgwccUUdnHJejowiIojJsiooXOCPDyOhhEUTzG7dBFJURJAKKsg5HFiVhTyB0\n0lnI0vX7o+kmgU7SKJVOpe7PdXElVdV0PUVC7jxvvVXlMAzDQERERCwjJNgFiIiIyJlReIuIiFiM\nwltERMRiFN4iIiIWo/AWERGxGIW3iIiIxSi8RRqRp556ilmzZtX6mszMTO666676KUhETKHwFhER\nsRiFt0iQ7N27l7S0NObOnUt6ejrp6en88MMP3HffffTp04dx48b5Xrts2TKuv/56hgwZwp133kl2\ndjYA+fn53H333QwYMID77ruPwsJC39/ZuXMnI0eOJD09nRtuuIHNmzfXWdNrr71Geno6AwcO5P77\n76egoACA0tJSxowZw4ABA7juuut4//33a10/duxY/vKXv/jet+rygAEDmD17Nunp6ezfv5/du3cz\nYsQIrrvuOgYNGsRHH33k+3tfffUVQ4cOJT09nfvvv59jx47x8MMP88Ybb/he8+OPP3LVVVdRUVFx\nxl8DEatSeIsEUX5+PgkJCSxfvpyLL76YRx99lGnTpvHBBx/w0UcfkZ2dzf79+3n66ad57bXX+OST\nT7jmmmt45plnAJg7dy5xcXF88cUXPPPMM6xevRoAt9vNH//4R/7rv/6L5cuX8+yzz/LAAw/UGnBb\ntmxh4cKFvPfee3z66aeUlZWxYMECAObNm0d5eTlffPEF//jHP5g0aRKHDh2qcX1dDh06xPLly0lK\nSuKFF16gf//+LFu2jClTpvDUU09RXl5OcXExTzzxBK+88grLly8nOTmZV199leuvv75awH/22WcM\nHjyYsLCwX/OlELEUfbeLBFFFRQVDhgwB4KKLLgIgPj4egISEBA4fPsxPP/3ElVdeSfv27QEYPnw4\nL774IhUVFXz77bfcd999ALRt25ZevXoBsHv3bo4cOcKwYcMA6NGjB/Hx8Xz//fc11tK5c2dWrlxJ\nREQEAN26dSMnJwfwdMD33nsvAK1bt+bf//43UVFRNa6vyzXXXOP7/C9/+QveuzT36NGD48ePk5ub\ny+7du2ndurXv3+WJJ54AwDAMxo0bx+7duzn//PNZsWIFTz75ZJ37FGlMFN4iQRQaGkpkZCQAISEh\nNGvWrNq2yspK8vPziYmJ8a2Pjo7GMAzy8/NxOp1ER0f7tnlfV1BQQGlpKdddd51vm8vl4tixYzXW\nUlJSwtSpU1m7di0ATqfTF7L5+fnV9uMN6JrW1yU2Ntb3+apVq/jrX/9Kfn4+DocDwzBwu92nHbf3\nlwrAN7w+bNgwcnNzfb+0iNiFwlukgWvZsmW1jtnpdBISEkJcXBwxMTHVznMfPXqUdu3akZiYSFRU\nFJ988slp75eZmel3P2+99RY///wzmZmZREVF8corr/iGwOPi4sjPz/e99uDBg8TGxta4PiQkBLfb\nXa1mf8rLy/mf//kfZs6cSb9+/SgrK6NLly5+91lSUoLT6aR169YMHTqUqVOnEh0dTXp6OiEhOgMo\n9qLveJEGLjU1lW+//dY3hL148WJSU1MJCwvj8ssvZ8WKFQBkZ2fz3XffAdCmTRtat27tC++jR4/y\n2GOPUVxcXON+jhw5wvnnn09UVBT79u3j3//+t+/1AwYM4J///CeGYZCbm8tNN91Efn5+jesTEhLY\nvn07ADk5OWzYsMHvPktKSiguLqZz586A5xeI8PBwiouL6dGjB7m5uWzatAnwDK+/9tprAFx99dUc\nO3aM+fPnVxtdELELdd4iDVzr1q3585//zAMPPEB5eTlt27Zl0qRJANx///08+uijDBgwgJSUFAYP\nHgyAw+Hg5Zdf5tlnn2XmzJmEhIQwevToasPyp8rIyODhhx8mPT2diy++mLFjx/LQQw/x5ptvctdd\nd7Fnzx769+9PZGQkTz75JElJSTWuv+2223jwwQcZPHgwl156Kenp6X73GRMTw7333stNN91Ey5Yt\n+cMf/sDAgQP5/e9/z0cffcSsWbN857rbt2/PtGnTAM8phSFDhvD555/To0ePs/nPLWIJDj3PW0Ss\naO7cueTn5zNmzJhglyJS7zRsLiKWc/ToUd555x1GjBgR7FJEgkLhLSKWsnjxYm699VZ+97vf0a5d\nu2CXIxIUGjYXERGxGHXeIiIiFqPwFhERsRiFt4iIiMUovEVERCxG4S0iImIxCm8RERGLUXiLiIhY\njMJbRETEYhTeIiIiFqPwFhERsRiFt4iIiMUovEVERCzG1PD+8ccfGThwIAsWLDht25o1axg2bBi3\n3347r732mplliIiINCqmhXdxcTGTJk2id+/efrf/+c9/ZtasWbz99tt8/fXX7Ny506xSREREGpUw\ns944IiKCuXPnMnfu3NO25eTkEBsby7nnngtAv379yMrK4oILLjCrnLPjhx9g+fJgVyEiIg1RUhKM\nHAkOh+m7Mi28w8LCCAvz//a5ubnEx8f7luPj48nJyTGrlLOjrAxuvBEaep0iIhI8Q4ZAQoLpuzEt\nvBudRYs8wf3f/+35IyIiUtW559ZLcEOQwjsxMZG8vDzf8qFDh0hMTAxGKYFxu2H6dAgLg6lToV27\nYFckIiI2FpRLxdq2bYvL5WLv3r1UVFTw5ZdfkpqaGoxSAvP++7B9u+dchoJbRESCzGEYhmHGG2/Z\nsoXp06ezb98+wsLCaNWqFQMGDKBt27YMGjSI9evXM2PGDAAGDx7MPffcY0YZv55hwFVXwfr1sHUr\nXHJJsCsSERGbMy28G40vvoBrr4Wbb4bMzGBXIyIiojus1WnqVM/HceOCW4eIiMgJCu/afPstrFjh\n6byvuCLY1YiIiAAK79pNm+b5OHZscOsQERGpQue8a/J//+eZnNajB6xbVy93zBEREQmEOu+avPCC\nZ6b52LEKbhERaVDUefuzdy+cf77nz7ZtEKLfcUREpOFQKvnz8stQXg5jxii4RUSkwVHnfaojR6B9\ne4iLg127ICIi2BWJiIhUo7byVLNnQ1ER/OlPCm4REWmQ1HlXVVQEycmez/fsgebNg1uPiIiIH+q8\nq5o7F44ehYcfVnCLiEiDpc67qgsugAMHIDsbWrYMdjUiIiJ+qfOuKjsbunRRcIuISIOm8PYqK/Nc\nHqbhchERaeAU3l4ul+ejwltERBo4hbeXwltERCxC4e2l8BYREYtQeHspvEVExCIU3l4KbxERsQiF\nt5fCW0RELELh7aXwFhERi1B4eym8RUTEIhTeXgpvERGxCIW3l8JbREQsQuHtVVjo+RgdHdw6RERE\n6qDw9lLnLSIiFqHw9lJ4i4iIRSi8vRTeIiJiEQpvL4W3iIhYhMLby+WC8HCIiAh2JSIiIrVSeHu5\nXOq6RUTEEhTeXgpvERGxCIW3l8JbREQsQuHtpfAWERGLUHgDVFRAaanCW0RELEHhDVBU5Pmo8BYR\nEQtQeIOu8RYREUtReIPCW0RELEXhDQpvERGxFIU3KLxFRMRSFN6g8BYREUtReIPCW0RELEXhDSfD\nOzo6uHWIiIgEQOEN6rxFRMRSFN4AhYWejwpvERGxAIU3qPMWERFLMTW8p0yZwu23305GRgabNm2q\ntm3FihXceuutjBgxggULFphZRt0U3iIiYiGmhfe6devYs2cPS5YsYfLkyUyePNm3ze12M2nSJObO\nncvChQv58ssvOXjwoFml1E3hLSIiFmJaeGdlZTFw4EAAUlJScDqduE6EZH5+PjExMcTHxxMSEsJV\nV13FmjVrzCqlbgpvERGxENPCOy8vj7i4ON9yfHw8ubm5vs+Lior4+eefKS8vZ+3ateTl5ZlVSt0U\n3iIiYiFh9bUjwzB8nzscDqZNm8b48eOJjo6mbdu29VWGfy4XhIRAZGRw6xAREQmAaeGdmJhYrZs+\nfPgwCQkJvuVevXqxaNEiAF566SXatGljVil1c7k8XbfDUevLVuxeQY4zh9HdRtdTYSIN15qcNcz5\nbg5uw11tfXhIOGNSx9DxnI5Bqkyk8TMtvFNTU5k1axYZGRls3bqVxMREmlcZlr733nuZPn06TZs2\n5csvv2T06CAGoje86/DAxw+wK38Xo7qOIiyk3gYtRBqkKaum8PGOj/1ua9m0JS8OfrGeKxKxD9MS\nqHv37nTq1ImMjAwcDgcTJ04kMzOT6OhoBg0axG233cbdd9+Nw+HgvvvuIz4+3qxS6uZyQWxsrS85\n6DrIjqM7AMgvySchKqHW14s0dnuce4iOiGbrA1t963469hP93uxHfml+ECsTafxMbR8ff/zxassd\nO54cRhs8eDCDBw82c/eBc7mgjmH7r7O/9n2eV5yn8Bbby3Zm075Fe9rFtvOtiwiNAMB53BmsskRs\nQXdYc7uhqKjOYfPV2at9n+cVB3FmvEgD4Cx1UnC8gOTY5GrrYyNjfdtFxDwK7+Jiz8e6wjvnZHjn\nFueaWZFIg5ftzAagfWz7ausjwyKJCI1Q5y1iMoV3ANd4u8pcfH/ge9+yOm+xO294n9p5A8Q2iVXn\nLWIyhXcA4f3N3m+oNCq5vPXlgMJbpNbwjoxV5y1iMoV3AOHtPd9908U3AQpvEXXeIsGl8PaGd3R0\njS/xhveNF98IKLxF9jj3ADV33iUVJZRXltd3WSK2ofCuo/Murywna28WnRM7c1HLiwCFt0i2M5tQ\nRyhJ0UmnbYttcmLGuYbORUyj8K4jvH84+APF5cWktUujWXgzIsMiFd5ie9nObNrEtPF7p8EWkS0A\nXS4mYiaFdx3hvSbH86jS1ORUHA4H5zQ7R+EttlbhrmBf4T6/Q+agzlukPii8Cws9H2sI7/2F+wG4\nIP4CAIW32N7+wv24DXfN4a0btYiYTuFdR+ft7R683cQ5zc6hsKyQ4xXH66U8kYbGN9M8pvbO+1jp\nsXqrScRuFN6BhnfkyfAGOFJyxPzaRBqg2i4Tgyqdt4bNRUyj8K4rvEtP6bybesI7t0i3SBV72nOs\n5svEoMo5bw2bi5hG4R1A5x3qCKVZeDMA39PEdN5b7Eqdt0jwKbyLijwfo6L8bj5WeozYyFgcDgdw\ncthc4S12lV1w4qEkLdr73a7OW8R8Cu/yE3eBCg/3u9lZ6vT9MAKFt0i2M5vYJrHENInxu12dt4j5\nFN4VFZ6PYaffbAI8P4C8P4xA4S2S7cyuccgcdJ23SH1QeFdWej6Ghp6+yV2Jq8ylzlvkBGepk4Lj\nBbWHt67zFjGdwruWzrvgeAGA/867ROEt9lPXZDWAyLBIIkIj1HmLmMj/WLGN/BhewHedYYSf8D71\nBi0ALZu2BNR5n+rz3Z8T1zSO7ud297t93b51fPzjx6bs+8aLb6RHUg9T3luqq+1pYlU15MeCFpUV\n8dr61ygqKzpt26CUQaQlpwWhKpEzY/vwfrbdLt7uCYOO53NOeGK1bade4w3QJKwJ0RHRCu8qSspL\nGLpoKOe1OI/tD273+5rR749mW+42U/b/4Y8fsuH+Daa8t1Tn7bzbx/qfae7VIrJFg+2839r4Fk+u\neNLvtjc3vsme/9lTzxWJnDnbh/fRMM9s84JyF+dwSnifcnc1L93fvLp1+9ZxvPI4/3fk/zjkOkSr\n5q2qbc8rzmNb7jZ6t+3N1GunntV9P/7Z43y3/zvPVQGnfJ3k7Atk2Bw8/2f2Fuytj5LO2Fd7vgLg\nnWHvkBh18v/8pK8m8flPn7Pn2J4aL4MTaShsH96uEM857+Ly4tO2+eu8wRPemw9vxjAM3/XfdrY6\ne7Xv869zvuaWS26ptv3r7K8BuO6C6+h3Xr+zuu/0lHS+3f8tWXuzGHLBkLP63nK6gMO7SSwlFSWU\nV5YTHur/MsxgMAyDVdmraBXVimGXDqv2/3fDgQ18/tPnrM5erfCWBs/2E9ZcoZ7Z5n7Du5bOu7Si\nlKLy08+Z2dHqnJPhXTXIT11nxrlE73v626+cfdnObEIdoZwbfW6tr2uo13rvce5hf+F+0pLTTvvF\nW99LYiUK79rC+0Tn3SKyRbX1ukXqSZXuStbkrKF9bHvCQ8JZlb3qtNesyl5FWEgYV7a98qzvv3fb\n3jhw+N2vnH3ZzmzaxLQhLKT2QbuGepe1VXs83yd9kvuctu3y1pfTLLyZvpfEEhTegXTepw6bN9W1\n3l6bD2+m4HgB13a4lp5JPfn+wPe4yly+7cXlxXx34Dt6nNvDd3/4syk2Mpaurbt6zrvrMa2mqnBX\nsK9wX51D5tBwHwta2yhQeGg4vdv2ZmvuVo6WHK3v0kTOiMI7zA3Ucc7bz7A5KLzh5A/DPu370Ce5\nD5VGJWv3rvVtX7dvHRXuClMvv0lrl0ZpRSkbDmjGuZn2F+7HbbjrnGkODXfYfHXOappHNKdr665+\nt3u/T9fkrKnPskTOmK3D2224KToR3v6u+ayx81Z4+1TtZLw/+KoOO3qHKU0Nbz/7lbOvrkeBVtUQ\nh82PFB/xXfVQ07C/73tpj76XpGGzdXhX7bb9dd7eIT913v5VnbmbEpfC1e2uBqpP+PFOZkttl2pa\nHZpoVD8CnWkODbPz/jrHc9VDbb9IXtX2KkIdodUmYYo0RLYO71PPzZ5KnXftTp2527JZSy5NuJRv\n9n5DeWU5Fe4K1uSsoeM5HX2T/MzQJqYNHVp04Oucr3EbbtP2Y3dnFN4NsPMO5KqH5hHN6XZuN9bv\nW09JeUl9lSZyxhTeJ9R0zjvUEXraRCuFt4e/mbt9kvtQVF7EDwd/YNOhTbjKXKS1M/92k2nJaRwt\nOcp/cv9j+r7syuqdt++qhza1X/WQ1i6Ncnc56/evr6fKRM6crW/SEkjnHRsZe9r1oN7wfuP7N1i8\nZbG5RTZgpRWlQPVOJi05jTnfzaHfm/2qrTNbWnIa8zfNp9ffexEe0nBuCmIVTcKasODmBQxKGVTj\na7ILfnnnPXbFWF7/9nUAHA4HT6Y+ydi0sbW+h7PUSeq81LN2pzbncSe92vQiKiKq1telJacxc+1M\nhiwYQkRoxFnZ96+VmpzKx3ecfDbAlsNbGLJgSLWfYRJ8SdFJfHPvNzU+6/5sUnifUFPnfeqQOXjC\ne1SXUWw6tMnU+qzgopYXcXnry33LQy8cyrUdrvWNSsQ3jef6i643vY6bOt7Eos2LGtylSVZQ4a5g\na+5WFm1ZVHt4O7OJbRIb0A+mqp2323Azd8NcyirLuKjlRfwn7z/8fcPf6wzvL3/+kq25W2kb09b3\nQKBfI8QRwqNXPVrn6wanDGZwymAOuQ796n2eDTkFOfxrx7+q3bb13W3vsq9wHxfGX2jKJZjyyyRF\nJ9XbL3wK7xNq6rwviL/gtPUOh4P/vfl/Ta3NquKaxrHizhX1vt/EqERW3rWy3vfbGLgNN/HT4+uc\n8JftzOa8FucF9J6+zvu4k//k/oejJUcZ1WUU/3vz/zJ00VD+teNfHCg8UOud2rz1zL95Ptecd01A\n+z0boptEs3zk8nrbX11eznqZP336p2q3bfX+23xz7zfEN40PZnkSJDrnfUJxRfXwrnRX4ipz+e28\nRRqTEEcIqcmp7Dy6k4Oug35fc6z0GAXHCwIaMocqnXep87SJYt45EN7Z3zVZnb2asJAwerXpFdA+\nG6tTr6Yoryznm73f0Cmhk4LbxhTeJ5zaeRccLwBOv0xMpDHyBmpN3bdvslpMYOEdGRZJk9AmOI87\nfZdd+cI7gEv7isqKTL0zn5V0a92NZuHNfP+OGw9tpKi8SM8dtzmF9wmnhndNl4mJNEZ92nuuGKgz\nvAPsvMHzi6+3827ZtCWXnHMJAFe0uYKI0Ihaw7s+7sxnFeGh4VzV9iq2HN7C0ZKj9XLjI2n4FN4n\nnBbeNTwOVKQx6pnUs9ZA/UXh3SSWn4/9zM/HfiY1OdV31UZkWCRXJF3B9we/p/B4od+/67vtrp8H\niNiRd2RkTc4aXweufxt7s3V4V/3BUWPnrWFzsYG6AvWXdt7HKz0Pizn1Wv+05DTchptv9n7j9+96\nb3XrvWuf3VW9bevq7NW0jWl7Rl8LaXxsHd6uslrCu4bHgYo0VrUFqje8vbOdA1F11Mo7LO9bTq55\nmL7CXUHW3izT78xnJd7bti7cvJDDRYf9Po9c7MXe4V0aQOetYXOxidomkmU7swl1hHJu85ov7TqV\nd9QqMiyS7ud2r7bNdx98P/cQr88781lFdJNoLm99OfsK9wGnj2SI/dg7vE8MD8aXh9d8zlvD5mIT\n3ofH+Hs62x7nHtrGtCU0JDTg9/P+4ntlmytPu3FFXNM4Oid29t0HvyrfbXfb65xuVVUnqOnfRmx+\nkxZPeCdWRJCtzltsrmqgvvnDmzjwDMsaGOwv3H/GT4bz/t+paWJVn+Q+bDm8hRe+foG2MW1965du\nWwpoNvWp+iT34dW1rxLbJJZOCZ2CXY4Emc3D2zPb/JzKJmwvP4phGL7zSDU9DlSkMet/Xn+2HN7C\n6PdHn7btopYXndF7tYttB8CADgNq3Ndfv/0rE76ccPrfjWlHhxYdzmh/jV1achrhIeFcc941ZzQC\nIo2T7cM7qgyauz0PsiitKKVpeFNAl4qJPT13zXNckXQFFe6KautDHCH85sLfnNF73d/jfnom9aRv\n+75+t99yyS0sHb7U7+z2Xm16aULWKVo1b8Wae9ZUG6UQ+7J5eBfRvAyanfhnKC4vPhneulRMbCiu\naRyjuo46K+8VFRFVY3ADhIaEMuzSYWdlX3bRM6lnsEuQBsLeE9bKXZ7wNjydd9VJazrnLSIiDZWp\nnfeUKVPYuHEjDoeD8ePH06VLF9+2hQsX8sEHHxASEkLnzp156qmnzCzFL1d5MQll0Kypn/AudRLq\nCLX9fZVFRKThMa3zXrduHXv27GHJkiVMnjyZyZMn+7a5XC7eeOMNFi5cyNtvv82uXbv44YcfzCrF\nL8MwcFV4h8094V1UXuTb7jzuJDYyVufdRESkwTEtvLOyshg4cCAAKSkpOJ1OXC7P7O7w8HDCw8Mp\nLi6moqKCkpISYmPrd3i6tKIUt+H2hLfDf+etIXMREWmITAvvvLw84uLifMvx8fHk5uYC0KRJE/74\nxz8ycOBA+vfvT9euXenQoX4vC/FeJuYJb88NJE49563JaiIi0hDV24Q1wzB8n7tcLubMmcMnn3zC\n559/zsaNG9m+fXt9leKpoZbwrnRX4ipzqfMWEZEGybTwTkxMJC8vz7d8+PBhEhI8DxnYtWsX7dq1\nIz4+noiICHr27MmWLVvMKsWv6uHdBDgZ3gXHCwBdJiYiIg2TaeGdmprK8uXLAdi6dSuJiYk0b94c\ngDZt2rBr1y5KS0sB2LJlC+edd55ZpfjlDe/o49AspHrnrcvERESkITPtUrHu3bvTqVMnMjIycDgc\nTJw4kczMTKKjoxk0aBD33HMPd955J6GhoXTr1o2ePev35gPVOu+Q6p23HgcqIiINWUDhXfWe32fi\n8ccfr7bcsWNH3+cZGRlkZGSc8XueLbWFd35pPqDwFhGRhimgYfP+/fvzyiuvkJOTY3Y99aZ6eEcC\nJ8M7t8gzKz6hWUJwihMREalFQOG9dOlSEhISGD9+PKNHj+bDDz+krKzM7NpMVXjicaDNy6BZaPXO\nO6/YM9HunGbnBKc4ERGRWgQU3gkJCYwcOZL58+fz7LPP8vbbb9OnTx9eeeUVjh8/bnaNpqjWeYdW\n77wV3iIi0pAFPNt8/fr1jBs3jt/97nd0796dRYsWERMTwyOPPGJmfaZReIuIiFUFNGFt0KBBtGnT\nhttuu43nn3+e8HDP7URTUlJYsWKFqQWapWp4R4U1g7Iq4V2i8BYRkYYroPD++9//jmEYvmuxt23b\nxqWXXgrAokWLTCvOTOq8RUTEqgIaNs/MzGTOnDm+5b/97W/MmDEDwLJP3aoa3k3DmgLVwzsqPIqm\n4U2DVp+IiEhNAgrvtWvXMnXqVN/yzJkz+e6770wrqj5UDe/Q8AiahDapFt7qukVEpKEKKLzLy8ur\nXRpWVFRERUWFaUXVB294R5UDoaE0C2+m8BYREUsI6Jx3RkYGv/nNb+jcuTNut5vNmzfz4IMPml2b\nqVxlLpo6Ighzl0FYmC+8vX8U3iIi0lAFFN7Dhw8nNTWVzZs343A4GDdunO8hI1blKnPR3NEEKPN1\n3q4yF0eKjwCarCYiIg1XwNd5FxcXEx8fT1xcHLt37+a2224zsy7TnQxvqnXemmkuIiINXUCd95//\n/Ge+/vpr8vLySE5OJicnh7vvvtvs2kzlKnPRlhOzyauc884t9tzXXOEtIiINVUCd9+bNm1m2bBkd\nO3bkvffeY968eZSUlJhdm6n8dd7l7nIOFB4AFN4iItJwBRTeERERgGfWuWEYdO7cmQ0bNphamJnK\nKssod5fTHM+d4rydN0C2MxvQE8VERKThCmjYvEOHDixcuJCePXsyevRoOnToQGFhodm1mcZ3jbfh\n+aXE23nDyfBW5y0iIg1VQOH93HPP4XQ6iYmJ4eOPP+bIkSPcf//9ZtdmmpPh7afzLlB4i4hIwxZQ\neE+ZMoWnnnoKgBtuuMHUgurDaeEdFkYz1HmLiIg1BHTOOzQ0lKysLI4fP47b7fb9sSq/4X3KsHl8\n0/ig1CYiIlKXgDrvpUuX8tZbb2EYhm+dw+HgP//5j2mFmckX3u4Thx8aSrMQT3gXlxfTIrIF4aHh\nwSpPRESkVgGFt9UfQnKqwuOeyXa+8K4ybA4aMhcRkYYtoPB+9dVX/a5/5JFHzmox9cXXeVeGelZU\n6bxB4S0iIg1bwOe8vX/cbjdr16619KViybHJNA1rSueKE+e1q5zzBoW3iIg0bAF13qc+QayyspKH\nHnrIlILqQ5/2fSgYV0DYY497VlS5VAx0gxYREWnYAn4wSVUVFRVkZ2ef7VrqVVhIGFRWnlhQ5y0i\nItYRUOfdr18/HA6Hb9npdHLzzTebVlS9qajwfDyl81Z4i4hIQxZQeC9atMj3ucPhoHnz5sTExJhW\nVL3xhrc6bxERsZCAhs1LSkouMQYuAAAWBElEQVRYvHgxbdq0ISkpialTp7Jjxw6zazOfd9hcnbeI\niFhIQOH93HPP0a9fP9/yrbfeyvPPP29aUfVGnbeIiFhQQMPmlZWV9OzZ07fcs2fPandbs6xqE9ZC\nfasV3iIi0pAFFN7R0dEsWrSIK6+8ErfbzapVq4iKijK7NvNVm7AW4Vut8BYRkYYsoPCeOnUqL730\nEm+//TYA3bt3Z+rUqaYWVi/8XCoW6gilRWSLIBYlIiJSu4DCOz4+nt/97necd955AGzbto34+Ebw\n1K0qnXeT0CY4cNCyWUtCHL/o8ncREZF6EVBKvfLKK8yZM8e3/Le//Y0ZM2aYVlS9qdJ5OxwOoptE\n6+5qIiLS4AXUea9du5bFixf7lmfOnMmIESNMK6reVOm8AV4f+jpxTeOCWJCIiEjdAgrv8vJyysrK\niIjwTOoqKiqiwht8Vlal8wYYcVkj+IVEREQavYDCOyMjg9/85jd07twZt9vN5s2b+e1vf2t2beY7\npfMWERGxAocR4AXb69evJz8/H4fDQVFREXPmzGHZsmVm12euvn1h1Spwu6HKvdtFREQasoA678mT\nJ7N69Wry8vJITk4mJyeHu+++2+zazFdZ6em6FdwiImIhAc0237RpE8uWLaNjx4689957zJs3j5KS\nErNrM19Fhe98t4iIiFUEFN7eiWrl5eUYhkHnzp3ZsGGDqYXVi8pKhbeIiFhOQMnVoUMHFi5cSM+e\nPRk9ejQdOnSgsLDQ7NrMV1GhyWoiImI5AU1YMwwDp9NJTEwMH3/8MUeOHGHIkCG0bt26Pmo0z2WX\nwf79cORIsCsREREJWMCzzRulSy7xBPfhw8GuREREJGD2vom3znmLiIgF2Tu8dc5bREQsyNS2c8qU\nKWzcuBGHw8H48ePp0qULAIcOHeLxxx/3vS4nJ4c//elP3HDDDWaWczp13iIiYkGmJde6devYs2cP\nS5YsYdeuXYwfP54lS5YA0KpVK+bPnw9ARUUFo0aNYsCAAWaVUrOKCmjatP73KyIi8iuYNmyelZXF\nwIEDAUhJScHpdOJyuU573f/7f/+P9PR0oqKizCqlZrpJi4iIWJBp4Z2Xl0dc3MnHa8bHx5Obm3va\n65YuXcqwYcPMKqN23tujioiIWEi9TVjzd0Xa999/z/nnn0/z5s3rq4zq1HmLiIgFmRbeiYmJ5OXl\n+ZYPHz5MQkJCtdesXLmS3r17m1VC3TRhTURELMi08E5NTWX58uUAbN26lcTExNM67M2bN9OxY0ez\nSqibLhUTERELMq3t7N69O506dSIjIwOHw8HEiRPJzMwkOjqaQYMGAZCbm0vLli3NKqFu6rxFRMSC\n7H171JAQSE2FVauCXYmIiEjA7HuHNbcbDEOdt4iIWI59w7uy0vNR57xFRMRiFN7qvEVExGLsG94V\nFZ6P6rxFRMRiFN7qvEVExGLsG9465y0iIhZl3/BW5y0iIhZl3/DWhDUREbEo+4a3JqyJiIhF2Te8\n1XmLiIhF2Te81XmLiIhF2Te81XmLiIhF2Te81XmLiIhF2Te81XmLiIhF2Te81XmLiIhFKbzVeYuI\niMXYN7x1e1QREbEo+4a3Om8REbEo+4a3JqyJiIhF2Te8NWFNREQsyr7hrc5bREQsyr7hrc5bREQs\nyr7hrc5bREQsyr7hrc5bREQsyr7hrc5bREQsyr7hrc5bREQsyr7hrc5bREQsyr7hrc5bREQsSuGt\nzltERCzGvuGtYXMREbEo+4a3hs1FRMSi7Bve6rxFRMSi7Bve6rxFRMSi7Bve6rxFRMSi7Bve6rxF\nRMSi7Bve6rxFRMSi7Bve6rxFRMSi7Bve6rxFRMSi7Bve6rxFRMSiFN7qvEVExGLsG94aNhcREYuy\nb3hr2FxERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzK1OSa\nMmUKGzduxOFwMH78eLp06eLbduDAAR577DHKy8u59NJLef75580s5XTqvEVExKJM67zXrVvHnj17\nWLJkCZMnT2by5MnVtk+bNo27776bd999l9DQUPbv329WKf6p8xYREYsyLbyzsrIYOHAgACkpKTid\nTlwuFwBut5vvvvuOAQMGADBx4kSSkpLMKsU/dd4iImJRpoV3Xl4ecXFxvuX4+Hhyc3MBOHr0KFFR\nUUydOpURI0bw0ksvmVVGzXR7VBERsah6m7BmGEa1zw8dOsSdd97JggUL2LZtGytXrqyvUjw0bC4i\nIhZlWngnJiaSl5fnWz58+DAJCQkAxMXFkZSURHJyMqGhofTu3ZsdO3aYVYp/GjYXERGLMi28U1NT\nWb58OQBbt24lMTGR5s2bAxAWFka7du34+eeffds7dOhgVin+qfMWERGLMi25unfvTqdOncjIyMDh\ncDBx4kQyMzOJjo5m0KBBjB8/nrFjx2IYBhdddJFv8lq98XbeIfa91F1ERKzJYVQ9GW0naWnwzTcn\nQ1xERMQi7Nt2VlTofLeIiFiSfcO7slLnu0VExJLsG97qvEVExKLsG97qvEVExKLsG97qvEVExKLs\nHd7qvEVExILsG94aNhcREYuyb3hr2FxERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzKvuGt\nzltERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzKvuGtzltERCzKnuFtGOB2q/MWERFLsmd4\nV1Z6Piq8RUTEguwZ3hUVno8aNhcREQuyZ3ir8xYREQuzZ3ir8xYREQuzZ3ir8xYREQuzZ3ir8xYR\nEQuzZ3ir8xYREQuzZ3ir8xYRkV9g+fLlAb1u8uTJ5OTkmFaHPcNbnbeIiJyhvXv38vHHHwf02qee\neop27dqZVos900udt4iInKHnn3+eTZs20bFjR2688Ub27t3Lm2++ybhx4zh06BDFxcU89NBD9O/f\nn1GjRvH000+zfPlyCgsL+emnn8jOzmb8+PH069fvV9di7/BW5y0iYk1PPAFLl57d9xw+HF58scbN\n99xzDwsXLuTCCy9k9+7dLFq0iCNHjpCWlsbNN99MTk4OjzzyCP3796/29w4ePMjcuXP56quvWLx4\nscL7F9OwuYiI/ApdunQBICYmhs2bN7NkyRJCQkI4duzYaa/t3r07AK1bt6awsPCs7N+e6aVhcxER\na3vxxVq7ZLOFh4cD8NFHH+F0Olm0aBHHjh1j2LBhp702zIRGURPWREREAhASEkKFt/k7IT8/n7Zt\n2xISEsJnn31GWVlZ/dRSL3tpaNR5i4jIGUpJSWHbtm3Vhr4HDx7MF198wW9/+1uaNm1K69atmT17\ntum1OAzDMEzfS0OTlQVXXw1jx8LUqcGuRkRE5Iyo8xYREbEYe4a3znmLiIiF2TO81XmLiIiF2TO8\n1XmLiIiF2TO81XmLiIiF2Tu81XmLiIgF2TO8NWwuIiK/QKCPBPVav349R44cOet12DO8NWwuIiJn\n6EweCer13nvvmRLe9mw91XmLiMgZ8j4SdPbs2fz44484nU4qKyuZMGECHTt25G9/+xufffYZISEh\n9O/fn8suu4wVK1awY8cOZs2aRVJS0lmrxZ7ppc5bRMTSnvj0CZZuO7uPBB1+6XBeHFz3I0EdDgd9\n+vRh+PDh7Ny5k8mTJ/OPf/yDefPmsXr1akJDQ3n77bdJTU3lkksu4emnnz6rwQ12DW913iIi8gt9\n//33HD16lA8++ACAkpISANLT0xk9ejTXX389N954o6k12DO9zj8fIiPhwguDXYmIiPwCLw5+sdYu\n2Uzh4eE8/fTTdOvWrdr65557jl27drFs2TJGjRrF0qVnd2SgKntOWOvbFwoKIDU12JWIiIhFeB8J\n2rVrV1asWAHAzp07+cc//kFhYSGzZ88mJSWFBx98kNjYWFwuFw6Hg0rvaO9ZZGrnPWXKFDZu3IjD\n4WD8+PF06dLFt23AgAG0bt2a0BPnnWfMmEGrVq3MLKe6Ew9SFxERCYT3kaBt27blwIED3HHHHbjd\nbp566imio6PJz89n2LBhNGvWjG7dutGiRQt69erFww8/zF/+8hcuPIujvaY9EnTdunW88cYbzJkz\nh127djF+/HiWLFni2z5gwAA+/PBDoqKizNi9iIhIo2XasHlWVhYDBw4EPL+tOJ1OXC6XWbsTERGx\nDdPCOy8vj7i4ON9yfHw8ubm51V4zceJERowYwYwZMzBpAEBERKTRqbcJa6eG88MPP8y4ceOYP38+\nO3bsOONbzomIiNiVaeGdmJhIXl6eb/nw4cMkJCT4lm+66SZatmxJWFgYffv25ccffzSrFBERkUbF\ntPBOTU31ddNbt24lMTGR5s2bA1BYWMg999xDWVkZ4Llx+9mchSciItKYmXapWPfu3enUqRMZGRk4\nHA4mTpxIZmYm0dHRDBo0iL59+3L77bfTpEkTLr30UoYMGWJWKSIiIo2KaZeKiYiIiDnseYc1ERER\nC1N4i4iIWIzCW0RExGIU3iIiIhaj8BYREbEYhbeIiIjFKLxFREQsRuEtIiJiMQpvERERi1F4i4iI\nWIwtw3vKlCncfvvtZGRksGnTpmCX86u98MIL3H777dx66618+umnHDhwgFGjRnHHHXfwyCOP+B4A\nY0WlpaUMHDiQzMzMRnVcH3zwATfeeCO33HILK1eubBTHVlRUxIMPPsioUaPIyMhg1apVbN++nYyM\nDDIyMpg4cWKwSzxjP/74IwMHDmTBggUANX6dPvjgA2699VaGDx/O0qVLg1lywPwd21133cXIkSO5\n6667yM3NBax3bKcel9eqVau4+OKLfctWO67TGDazdu1a47777jMMwzB27txp3HbbbUGu6NfJysoy\n7r33XsMwDOPo0aNGv379jLFjxxr/+te/DMMwjJdeeslYuHBhMEv8VV5++WXjlltuMd57771Gc1xH\njx41Bg8ebBQWFhqHDh0yJkyY0CiObf78+caMGTMMwzCMgwcPGunp6cbIkSONjRs3GoZhGI899pix\ncuXKYJZ4RoqKioyRI0caEyZMMObPn28YhuH361RUVGQMHjzYKCgoMEpKSoyhQ4ca+fn5wSy9Tv6O\nbcyYMcbHH39sGIZhLFiwwJg+fbrljs3fcRmGYZSWlhojR440UlNTfa+z0nH5Y7vOOysri4EDBwKQ\nkpKC0+nE5XIFuapf7oorruDVV18FICYmhpKSEtauXcu1114LQP/+/cnKygpmib/Yrl272LlzJ9dc\ncw1AozmurKwsevfuTfPmzUlMTGTSpEmN4tji4uI4duwYAAUFBbRo0YJ9+/bRpUsXwHrHFRERwdy5\nc0lMTPSt8/d12rhxI5dddhnR0dFERkbSvXt3NmzYEKyyA+Lv2CZOnEh6ejpw8mtptWPzd1wAr7/+\nOnfccQcREREAljsuf2wX3nl5ecTFxfmW4+PjfcNDVhQaGkqzZs0AePfdd+nbty8lJSW+b9KWLVta\n9vimT5/O2LFjfcuN5bj27t1LaWkpv//977njjjvIyspqFMc2dOhQ9u/fz6BBgxg5ciRjxowhJibG\nt91qxxUWFkZkZGS1df6+Tnl5ecTHx/teY4WfKf6OrVmzZoSGhlJZWcmiRYu44YYbLHds/o7rp59+\nYvv27Vx33XW+dVY7Ln9Me563VRiN5ImoK1as4N1332XevHkMHjzYt96qx/fPf/6Tyy+/nHbt2vnd\nbtXj8jp27BizZ89m//793HnnndWOx6rH9v7775OUlMQbb7zB9u3b+eMf/0h0dLRvu1WPqyY1HY+V\nj7OyspIxY8Zw1VVX0bt3bz788MNq2614bFOnTmXChAm1vsaKx2W78E5MTCQvL8+3fPjwYRISEoJY\n0a+3atUqXn/9df7+978THR1Ns2bNKC0tJTIykkOHDp02hGQFK1euJCcnh5UrV3Lw4EEiIiIaxXGB\np2Pr1q0bYWFhJCcnExUVRWhoqOWPbcOGDaSlpQHQsWNHjh8/TkVFhW+7VY+rKn/fg/5+plx++eVB\nrPKXGzduHO3bt+fBBx8E/P+8tNKxHTp0iN27d/P4448DnvpHjhzJQw89ZOnjAhsOm6emprJ8+XIA\ntm7dSmJiIs2bNw9yVb9cYWEhL7zwAnPmzKFFixYAXH311b5j/PTTT+nTp08wS/xFZs6cyXvvvcc7\n77zD8OHDeeCBBxrFcQGkpaXxzTff4Ha7yc/Pp7i4uFEcW/v27dm4cSMA+/btIyoqipSUFL799lvA\nusdVlb+vU9euXdm8eTMFBQUUFRWxYcMGevbsGeRKz9wHH3xAeHg4Dz/8sG+d1Y+tVatWrFixgnfe\neYd33nmHxMREFixYYPnjAnAYVhwv+JVmzJjBt99+i8PhYOLEiXTs2DHYJf1iS5YsYdasWXTo0MG3\nbtq0aUyYMIHjx4+TlJTE1KlTCQ8PD2KVv86sWbNo06YNaWlpPPnkk43iuBYvXsy7774LwB/+8Acu\nu+wyyx9bUVER48eP58iRI1RUVPDII4+QkJDAM888g9vtpmvXrowbNy7YZQZsy5YtTJ8+nX379hEW\nFkarVq2YMWMGY8eOPe3r9Mknn/DGG2/gcDgYOXIkN954Y7DLr5W/Yzty5AhNmjTxNTMpKSk8++yz\nljo2f8c1a9YsX2MzYMAAvvjiCwBLHZc/tgxvERERK7PdsLmIiIjVKbxFREQsRuEtIiJiMQpvERER\ni1F4i4iIWIzCW0R+tczMTN+NMETEfApvERERi7Hd7VFF7Gz+/PksW7aMyspKzj//fO69917uv/9+\n+vbty/bt2wF45ZVXaNWqFStXruS1114jMjKSpk2bMmnSJFq1asXGjRuZMmUK4eHhxMbGMn36dABc\nLhePP/44u3btIikpidmzZ+NwOIJ5uCKNljpvEZvYtGkTn332GQsXLmTJkiVER0ezZs0acnJyuOWW\nW1i0aBG9evVi3rx5lJSUMGHCBGbNmsX8+fPp27cvM2fOBOCJJ55g0qRJLFiwgCuuuIJ///vfAOzc\nuZNJkyaRmZnJjh072Lp1azAPV6RRU+ctYhNr164lOzubO++8E4Di4mIOHTpEixYt6Ny5MwDdu3fn\nrbfe4ueff6Zly5a0bt0agF69erF48WKOHj1KQUEBF110EQB33XUX4Dnnfdlll9G0aVPAc0/pwsLC\nej5CEftQeIvYREREBAMGDOCZZ57xrdu7dy+33HKLb9kwDBwOx2nD3VXX13RH5dDQ0NP+joiYQ8Pm\nIjbRvXt3vvrqK4qKigBYuHAhubm5OJ1Otm3bBnge63nxxRdz3nnnceTIEfbv3w9AVlYWXbt2JS4u\njhYtWrBp0yYA5s2bx8KFC4NzQCI2ps5bxCYuu+wy/vu//5tRo0bRpEkTEhMTufLKK2nVqhWZmZlM\nmzYNwzB4+eWXiYyMZPLkyTz66KO+Z6lPnjwZgBdffJEpU6YQFhZGdHQ0L774Ip9++mmQj07EXvRU\nMREb27t3L3fccQdfffVVsEsRkTOgYXMRERGLUectIiJiMeq8RURELEbhLSIiYjEKbxEREYtReIuI\niFiMwltERMRiFN4iIiIW8/8BmMgbErtXBqQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pXg5hw9M0A5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "fd9c8d9a-d403-4e95-f52e-4c3d1dc43f41"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng7bMvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UqzJCQIZ0NH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = np.load('/content/drive/My Drive/x_test.npy')\n",
        "y_test = np.load('/content/drive/My Drive/y_test.npy')\n",
        "y_test = to_categorical(y_test, num_classes = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lv_6Hl8i33WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "914573b3-a74b-4fea-83df-cebb6ddd83ab"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        19\n",
            "           1       0.94      0.94      0.94        18\n",
            "           2       0.75      1.00      0.86        18\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.88      0.88      0.88        60\n",
            "   macro avg       0.67      0.72      0.69        60\n",
            "weighted avg       0.82      0.88      0.85        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8q_eEL3i4oTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.grid(b=False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSGu7ymO5LWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "699a6ec7-af66-4781-e719-780e941f3ce3"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['apple', 'banana', 'orange', 'mixed'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAG+CAYAAACteRxWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "457ixQhi5ksp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11963
        },
        "outputId": "c022f987-9c21-4792-a8c8-f5dea0dc9417"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = InceptionV3(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 4s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_55[0][0]              \n",
            "                                                                 activation_57[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "                                                                 activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_62[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_67[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_69[0][0]              \n",
            "                                                                 activation_71[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_76[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_80[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_90[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "                                                                 activation_98[0][0]              \n",
            "                                                                 activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_100[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_110[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_121[0][0]             \n",
            "                                                                 activation_125[0][0]             \n",
            "                                                                 max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_128[0][0]             \n",
            "                                                                 activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_126[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_137[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_141[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_135[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 4)            4004        dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,855,788\n",
            "Trainable params: 2,053,004\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ugN0dR9c56Xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5367
        },
        "outputId": "c8e45153-a6dd-40ac-f884-5dd418c4b844"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 150, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/150\n",
            "192/192 [==============================] - 7s 36ms/step - loss: 2.8792 - acc: 0.4219 - val_loss: 9.2269 - val_acc: 0.3333\n",
            "Epoch 2/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0621 - acc: 0.6823 - val_loss: 12.2034 - val_acc: 0.2292\n",
            "Epoch 3/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.6939 - acc: 0.7865 - val_loss: 9.2536 - val_acc: 0.3333\n",
            "Epoch 4/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.4465 - acc: 0.8594 - val_loss: 10.1274 - val_acc: 0.2917\n",
            "Epoch 5/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.3189 - acc: 0.9010 - val_loss: 11.3521 - val_acc: 0.1875\n",
            "Epoch 6/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.3132 - acc: 0.8958 - val_loss: 9.6929 - val_acc: 0.2708\n",
            "Epoch 7/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1881 - acc: 0.9635 - val_loss: 11.0755 - val_acc: 0.2708\n",
            "Epoch 8/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1319 - acc: 0.9792 - val_loss: 12.1549 - val_acc: 0.1875\n",
            "Epoch 9/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0983 - acc: 1.0000 - val_loss: 10.4553 - val_acc: 0.2083\n",
            "Epoch 10/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0737 - acc: 0.9896 - val_loss: 11.8185 - val_acc: 0.2083\n",
            "Epoch 11/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0500 - acc: 0.9948 - val_loss: 12.5307 - val_acc: 0.2083\n",
            "Epoch 12/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0534 - acc: 0.9948 - val_loss: 12.2325 - val_acc: 0.1875\n",
            "Epoch 13/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0476 - acc: 0.9948 - val_loss: 11.7384 - val_acc: 0.1667\n",
            "Epoch 14/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0792 - acc: 0.9792 - val_loss: 12.2175 - val_acc: 0.2083\n",
            "Epoch 15/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0795 - acc: 0.9844 - val_loss: 12.1322 - val_acc: 0.2292\n",
            "Epoch 16/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0911 - acc: 0.9635 - val_loss: 9.4466 - val_acc: 0.3750\n",
            "Epoch 17/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1079 - acc: 0.9792 - val_loss: 11.9836 - val_acc: 0.1875\n",
            "Epoch 18/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0662 - acc: 0.9844 - val_loss: 12.0786 - val_acc: 0.1875\n",
            "Epoch 19/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0332 - acc: 0.9896 - val_loss: 11.3913 - val_acc: 0.1667\n",
            "Epoch 20/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0331 - acc: 1.0000 - val_loss: 11.7830 - val_acc: 0.2083\n",
            "Epoch 21/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 10.7703 - val_acc: 0.1875\n",
            "Epoch 22/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 11.7820 - val_acc: 0.2083\n",
            "Epoch 23/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0475 - acc: 0.9896 - val_loss: 12.2133 - val_acc: 0.1667\n",
            "Epoch 24/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0711 - acc: 0.9740 - val_loss: 11.0773 - val_acc: 0.2500\n",
            "Epoch 25/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0228 - acc: 0.9948 - val_loss: 11.9624 - val_acc: 0.2083\n",
            "Epoch 26/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0411 - acc: 0.9896 - val_loss: 11.6745 - val_acc: 0.2500\n",
            "Epoch 27/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0529 - acc: 0.9844 - val_loss: 11.9464 - val_acc: 0.2083\n",
            "Epoch 28/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0916 - acc: 0.9583 - val_loss: 11.3897 - val_acc: 0.2292\n",
            "Epoch 29/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0987 - acc: 0.9740 - val_loss: 11.8554 - val_acc: 0.2083\n",
            "Epoch 30/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 12.3592 - val_acc: 0.1875\n",
            "Epoch 31/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0520 - acc: 0.9896 - val_loss: 11.5855 - val_acc: 0.2083\n",
            "Epoch 32/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 12.4470 - val_acc: 0.1875\n",
            "Epoch 33/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 12.0817 - val_acc: 0.2083\n",
            "Epoch 34/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 12.7911 - val_acc: 0.1875\n",
            "Epoch 35/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 12.9092 - val_acc: 0.1875\n",
            "Epoch 36/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 13.0335 - val_acc: 0.1875\n",
            "Epoch 37/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 12.6631 - val_acc: 0.1875\n",
            "Epoch 38/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 12.4640 - val_acc: 0.1667\n",
            "Epoch 39/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 12.2786 - val_acc: 0.1875\n",
            "Epoch 40/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 12.6583 - val_acc: 0.1875\n",
            "Epoch 41/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 12.6326 - val_acc: 0.1667\n",
            "Epoch 42/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 12.2063 - val_acc: 0.1875\n",
            "Epoch 43/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 11.6441 - val_acc: 0.2292\n",
            "Epoch 44/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 12.1288 - val_acc: 0.2083\n",
            "Epoch 45/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 12.2835 - val_acc: 0.2083\n",
            "Epoch 46/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 12.2668 - val_acc: 0.2083\n",
            "Epoch 47/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0283 - acc: 0.9948 - val_loss: 12.3028 - val_acc: 0.1875\n",
            "Epoch 48/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0249 - acc: 0.9948 - val_loss: 12.2158 - val_acc: 0.2292\n",
            "Epoch 49/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 12.3136 - val_acc: 0.2083\n",
            "Epoch 50/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 12.6435 - val_acc: 0.1667\n",
            "Epoch 51/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 11.9440 - val_acc: 0.1875\n",
            "Epoch 52/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 12.2965 - val_acc: 0.2292\n",
            "Epoch 53/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0298 - acc: 0.9948 - val_loss: 10.6748 - val_acc: 0.3333\n",
            "Epoch 54/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 10.8942 - val_acc: 0.2917\n",
            "Epoch 55/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 12.2361 - val_acc: 0.2083\n",
            "Epoch 56/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 11.9429 - val_acc: 0.2500\n",
            "Epoch 57/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 12.2047 - val_acc: 0.2292\n",
            "Epoch 58/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 12.2242 - val_acc: 0.2083\n",
            "Epoch 59/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 12.3739 - val_acc: 0.1875\n",
            "Epoch 60/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 12.1510 - val_acc: 0.2083\n",
            "Epoch 61/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 12.5122 - val_acc: 0.1667\n",
            "Epoch 62/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 12.9856 - val_acc: 0.1875\n",
            "Epoch 63/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 12.8335 - val_acc: 0.1875\n",
            "Epoch 64/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 12.1641 - val_acc: 0.2083\n",
            "Epoch 65/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 12.5593 - val_acc: 0.1875\n",
            "Epoch 66/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 12.7602 - val_acc: 0.2083\n",
            "Epoch 67/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 12.2055 - val_acc: 0.2292\n",
            "Epoch 68/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 12.3624 - val_acc: 0.1875\n",
            "Epoch 69/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 12.0722 - val_acc: 0.2083\n",
            "Epoch 70/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.6446 - val_acc: 0.2083\n",
            "Epoch 71/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 12.0505 - val_acc: 0.2083\n",
            "Epoch 72/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 12.9486 - val_acc: 0.1875\n",
            "Epoch 73/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 12.7603 - val_acc: 0.2083\n",
            "Epoch 74/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 12.6778 - val_acc: 0.1875\n",
            "Epoch 75/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 11.3565 - val_acc: 0.2917\n",
            "Epoch 76/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 11.3171 - val_acc: 0.2083\n",
            "Epoch 77/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 12.7255 - val_acc: 0.1875\n",
            "Epoch 78/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 12.7528 - val_acc: 0.1875\n",
            "Epoch 79/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 10.5989 - val_acc: 0.3125\n",
            "Epoch 80/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0206 - acc: 0.9948 - val_loss: 12.2028 - val_acc: 0.2292\n",
            "Epoch 81/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0393 - acc: 0.9896 - val_loss: 12.4586 - val_acc: 0.1875\n",
            "Epoch 82/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 10.4098 - val_acc: 0.3542\n",
            "Epoch 83/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0183 - acc: 0.9948 - val_loss: 12.7658 - val_acc: 0.2083\n",
            "Epoch 84/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 12.4692 - val_acc: 0.2083\n",
            "Epoch 85/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 12.4327 - val_acc: 0.2292\n",
            "Epoch 86/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 11.9259 - val_acc: 0.2292\n",
            "Epoch 87/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 12.2677 - val_acc: 0.2083\n",
            "Epoch 88/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0225 - acc: 0.9896 - val_loss: 12.7393 - val_acc: 0.1875\n",
            "Epoch 89/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 12.0706 - val_acc: 0.2083\n",
            "Epoch 90/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 12.0399 - val_acc: 0.2083\n",
            "Epoch 91/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 12.2424 - val_acc: 0.2083\n",
            "Epoch 92/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 12.4845 - val_acc: 0.1667\n",
            "Epoch 93/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.4598e-04 - acc: 1.0000 - val_loss: 12.5719 - val_acc: 0.1667\n",
            "Epoch 94/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 12.6233 - val_acc: 0.1667\n",
            "Epoch 95/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 12.3505 - val_acc: 0.2083\n",
            "Epoch 96/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 12.1648 - val_acc: 0.2083\n",
            "Epoch 97/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1597e-04 - acc: 1.0000 - val_loss: 12.2956 - val_acc: 0.1875\n",
            "Epoch 98/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 12.2690 - val_acc: 0.1875\n",
            "Epoch 99/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0085 - acc: 0.9948 - val_loss: 12.5528 - val_acc: 0.1458\n",
            "Epoch 100/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 12.3691 - val_acc: 0.1875\n",
            "Epoch 101/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.4715 - val_acc: 0.2083\n",
            "Epoch 102/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 11.1814 - val_acc: 0.2708\n",
            "Epoch 103/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.7285e-04 - acc: 1.0000 - val_loss: 10.9578 - val_acc: 0.2917\n",
            "Epoch 104/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 12.0880 - val_acc: 0.2500\n",
            "Epoch 105/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8056e-04 - acc: 1.0000 - val_loss: 11.8079 - val_acc: 0.1875\n",
            "Epoch 106/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 11.9936 - val_acc: 0.2083\n",
            "Epoch 107/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 12.1635 - val_acc: 0.2083\n",
            "Epoch 108/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.4675e-04 - acc: 1.0000 - val_loss: 11.8214 - val_acc: 0.2083\n",
            "Epoch 109/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 12.2344 - val_acc: 0.1875\n",
            "Epoch 110/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 12.3507 - val_acc: 0.2292\n",
            "Epoch 111/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 12.1157 - val_acc: 0.2292\n",
            "Epoch 112/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 10.6359 - val_acc: 0.2917\n",
            "Epoch 113/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0067 - acc: 0.9948 - val_loss: 11.7755 - val_acc: 0.2292\n",
            "Epoch 114/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 12.2558 - val_acc: 0.2292\n",
            "Epoch 115/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 10.3354 - val_acc: 0.2917\n",
            "Epoch 116/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 10.0005 - val_acc: 0.3542\n",
            "Epoch 117/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.7917e-04 - acc: 1.0000 - val_loss: 10.0153 - val_acc: 0.3333\n",
            "Epoch 118/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0120 - acc: 0.9896 - val_loss: 11.0113 - val_acc: 0.3125\n",
            "Epoch 119/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0294 - acc: 0.9896 - val_loss: 12.6302 - val_acc: 0.2083\n",
            "Epoch 120/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0325 - acc: 0.9896 - val_loss: 11.7327 - val_acc: 0.2292\n",
            "Epoch 121/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0223 - acc: 0.9948 - val_loss: 9.1682 - val_acc: 0.3958\n",
            "Epoch 122/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 12.1889 - val_acc: 0.2083\n",
            "Epoch 123/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0283 - acc: 0.9896 - val_loss: 10.3263 - val_acc: 0.3542\n",
            "Epoch 124/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0448 - acc: 0.9896 - val_loss: 11.7539 - val_acc: 0.2292\n",
            "Epoch 125/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1500 - acc: 0.9427 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 126/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0500 - acc: 0.9740 - val_loss: 11.3917 - val_acc: 0.2708\n",
            "Epoch 127/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 11.1467 - val_acc: 0.2917\n",
            "Epoch 128/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0075 - acc: 0.9948 - val_loss: 12.1739 - val_acc: 0.2083\n",
            "Epoch 129/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0222 - acc: 0.9896 - val_loss: 11.2484 - val_acc: 0.2708\n",
            "Epoch 130/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0264 - acc: 0.9948 - val_loss: 12.9989 - val_acc: 0.1667\n",
            "Epoch 131/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 13.5805 - val_acc: 0.1458\n",
            "Epoch 132/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 13.1072 - val_acc: 0.1458\n",
            "Epoch 133/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.8695e-04 - acc: 1.0000 - val_loss: 12.4120 - val_acc: 0.2083\n",
            "Epoch 134/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8930e-04 - acc: 1.0000 - val_loss: 11.8427 - val_acc: 0.2292\n",
            "Epoch 135/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 13.0238 - val_acc: 0.1875\n",
            "Epoch 136/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.4890e-04 - acc: 1.0000 - val_loss: 13.2745 - val_acc: 0.1042\n",
            "Epoch 137/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 13.5963 - val_acc: 0.1250\n",
            "Epoch 138/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 13.2523 - val_acc: 0.1042\n",
            "Epoch 139/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.2208e-04 - acc: 1.0000 - val_loss: 12.9947 - val_acc: 0.1667\n",
            "Epoch 140/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2926e-04 - acc: 1.0000 - val_loss: 12.4515 - val_acc: 0.2083\n",
            "Epoch 141/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0188 - acc: 0.9948 - val_loss: 12.4305 - val_acc: 0.1875\n",
            "Epoch 142/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0417 - acc: 0.9896 - val_loss: 10.8351 - val_acc: 0.3125\n",
            "Epoch 143/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 11.4267 - val_acc: 0.2708\n",
            "Epoch 144/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0139 - acc: 0.9948 - val_loss: 11.6306 - val_acc: 0.2292\n",
            "Epoch 145/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0218 - acc: 0.9948 - val_loss: 12.9329 - val_acc: 0.1875\n",
            "Epoch 146/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0322 - acc: 0.9844 - val_loss: 10.9400 - val_acc: 0.2917\n",
            "Epoch 147/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0361 - acc: 0.9844 - val_loss: 12.4649 - val_acc: 0.1667\n",
            "Epoch 148/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0311 - acc: 0.9896 - val_loss: 12.7603 - val_acc: 0.2083\n",
            "Epoch 149/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0121 - acc: 0.9896 - val_loss: 12.4648 - val_acc: 0.2083\n",
            "Epoch 150/150\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 12.7761 - val_acc: 0.1875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qffN58QI--5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "ae5e187a-eb92-4f37-b8b3-ae5e273a85a9"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1_LhBJKq_IMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "bafa0b29-2316-4be8-92d1-8e3841f543d8"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACxBaAMAYIn/AZ5eUBMWTm+NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MPnHFAfc_MxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f880ba2a-8de6-4575-fad4-a2061184852c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.32      0.24        19\n",
            "           1       0.20      0.06      0.09        18\n",
            "           2       0.12      0.17      0.14        18\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.17      0.17      0.17        60\n",
            "   macro avg       0.13      0.13      0.12        60\n",
            "weighted avg       0.16      0.17      0.15        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QDO3qGZz_QQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "0f147b96-efa0-4c3e-8fcd-190fe6e26694"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['apple', 'banana', 'orange', 'mixed'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAG+CAYAAACteRxWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXOg+8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f4KVhcyV_ZzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29758
        },
        "outputId": "2641a3bc-122b-4190-cbb0-a97a48fdb7de"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = InceptionResNetV2(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 7s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 111, 111, 32) 864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 111, 111, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 111, 111, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 109, 109, 32) 9216        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 109, 109, 32) 96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 109, 109, 32) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 109, 109, 64) 18432       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 109, 109, 64) 192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 109, 109, 64) 0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 54, 54, 80)   240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 54, 54, 80)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 52, 52, 192)  138240      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 52, 52, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 52, 52, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 25, 25, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 25, 25, 64)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 25, 25, 96)   55296       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 25, 25, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 25, 25, 48)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 25, 25, 96)   18432       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 25, 25, 64)   76800       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 25, 25, 96)   82944       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 25, 25, 64)   12288       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 25, 25, 96)   288         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 25, 25, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 25, 25, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 25, 25, 96)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 25, 25, 96)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 25, 25, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_149[0][0]             \n",
            "                                                                 activation_151[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 25, 25, 32)   96          conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 25, 25, 32)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 25, 25, 48)   13824       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 25, 25, 32)   96          conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 25, 25, 48)   144         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 25, 25, 32)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 25, 25, 48)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 25, 25, 32)   9216        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 25, 25, 64)   27648       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 25, 25, 32)   96          conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 25, 25, 32)   96          conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 25, 25, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 25, 25, 32)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 25, 25, 32)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 25, 25, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_156[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 25, 25, 32)   96          conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 25, 25, 32)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 25, 25, 48)   13824       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 25, 25, 32)   96          conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 25, 25, 48)   144         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 25, 25, 32)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 25, 25, 48)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 25, 25, 32)   9216        activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 25, 25, 64)   27648       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 25, 25, 32)   96          conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 25, 25, 32)   96          conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 25, 25, 64)   192         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 25, 25, 32)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 25, 25, 32)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 25, 25, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_162[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "                                                                 activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 25, 25, 32)   96          conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 25, 25, 32)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 25, 25, 48)   13824       activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 25, 25, 32)   96          conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 25, 25, 48)   144         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 25, 25, 32)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 25, 25, 48)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 25, 25, 32)   9216        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 25, 25, 64)   27648       activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 25, 25, 32)   96          conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 25, 25, 32)   96          conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 25, 25, 64)   192         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 25, 25, 32)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 25, 25, 32)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 25, 25, 64)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_168[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 25, 25, 32)   96          conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 25, 25, 32)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 25, 25, 48)   13824       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 25, 25, 32)   96          conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 25, 25, 48)   144         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 25, 25, 32)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 25, 25, 48)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 25, 25, 32)   9216        activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 25, 25, 64)   27648       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 25, 25, 32)   96          conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 25, 25, 32)   96          conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 25, 25, 64)   192         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 25, 25, 32)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 25, 25, 32)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 25, 25, 64)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_174[0][0]             \n",
            "                                                                 activation_176[0][0]             \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 25, 25, 32)   96          conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 25, 25, 32)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 25, 25, 48)   13824       activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 25, 25, 32)   96          conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 25, 25, 48)   144         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 25, 25, 32)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 25, 25, 48)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 25, 25, 32)   9216        activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 25, 25, 64)   27648       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 25, 25, 32)   96          conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 25, 25, 32)   96          conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 25, 25, 64)   192         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 25, 25, 32)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 25, 25, 32)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 25, 25, 64)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_180[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "                                                                 activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 25, 25, 32)   96          conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 25, 25, 32)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 25, 25, 48)   13824       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 25, 25, 32)   96          conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 25, 25, 48)   144         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 25, 25, 32)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 25, 25, 48)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 25, 25, 32)   9216        activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 25, 25, 64)   27648       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 25, 25, 32)   96          conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 25, 25, 32)   96          conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 25, 25, 64)   192         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 25, 25, 32)   0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 25, 25, 32)   0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 25, 25, 64)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_186[0][0]             \n",
            "                                                                 activation_188[0][0]             \n",
            "                                                                 activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 25, 25, 32)   96          conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 25, 25, 32)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 25, 25, 48)   13824       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 25, 25, 32)   96          conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 25, 25, 48)   144         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 25, 25, 32)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 25, 25, 48)   0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 25, 25, 32)   9216        activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 25, 25, 64)   27648       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 25, 25, 32)   96          conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 25, 25, 32)   96          conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 25, 25, 64)   192         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 25, 25, 32)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 25, 25, 32)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 25, 25, 64)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_192[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "                                                                 activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 25, 25, 32)   96          conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 25, 25, 32)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 25, 25, 48)   13824       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 25, 25, 32)   96          conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 25, 25, 48)   144         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 25, 25, 32)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 25, 25, 48)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 25, 25, 32)   9216        activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 25, 25, 64)   27648       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 25, 25, 32)   96          conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 25, 25, 32)   96          conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 25, 25, 64)   192         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 25, 25, 32)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 25, 25, 32)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 25, 25, 64)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_198[0][0]             \n",
            "                                                                 activation_200[0][0]             \n",
            "                                                                 activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 25, 25, 32)   96          conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 25, 25, 32)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 25, 25, 48)   13824       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 25, 25, 32)   96          conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 25, 25, 48)   144         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 25, 25, 32)   0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 25, 25, 48)   0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 25, 25, 32)   9216        activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 25, 25, 64)   27648       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 25, 25, 32)   96          conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 25, 25, 32)   96          conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 25, 25, 64)   192         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 25, 25, 32)   0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 25, 25, 32)   0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 25, 25, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_204[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 25, 25, 32)   96          conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 25, 25, 32)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 25, 25, 48)   13824       activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 25, 25, 32)   96          conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 25, 25, 48)   144         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 25, 25, 32)   0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 25, 25, 48)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 25, 25, 32)   9216        activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 25, 25, 64)   27648       activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 25, 25, 32)   96          conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 25, 25, 32)   96          conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 25, 25, 64)   192         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 25, 25, 32)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 25, 25, 32)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 25, 25, 64)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_210[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 25, 25, 256)  768         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 25, 25, 256)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 25, 25, 256)  589824      activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 25, 25, 256)  768         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 25, 25, 256)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 12, 12, 384)  884736      activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 12, 12, 384)  1152        conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 12, 12, 384)  1152        conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 12, 12, 384)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 12, 12, 384)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_216[0][0]             \n",
            "                                                                 activation_219[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 12, 12, 128)  384         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 12, 12, 128)  0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 12, 12, 160)  143360      activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 12, 12, 160)  480         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 12, 12, 160)  0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 12, 12, 192)  215040      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 12, 12, 192)  576         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 12, 12, 192)  576         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 12, 12, 192)  0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 12, 12, 192)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_220[0][0]             \n",
            "                                                                 activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 12, 12, 128)  384         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 12, 12, 128)  0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 12, 12, 160)  143360      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 12, 12, 160)  480         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 12, 12, 160)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 12, 12, 192)  215040      activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 12, 12, 192)  576         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 12, 12, 192)  576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 12, 12, 192)  0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 12, 12, 192)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_224[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 12, 12, 128)  384         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 12, 12, 128)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 12, 12, 160)  143360      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 12, 12, 160)  480         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 12, 12, 160)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 12, 12, 192)  215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 12, 12, 192)  576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 12, 12, 192)  576         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 12, 12, 192)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 12, 12, 192)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 12, 12, 128)  384         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 12, 12, 128)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 12, 12, 160)  143360      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 12, 12, 160)  480         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 12, 12, 160)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 12, 12, 192)  215040      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 12, 12, 192)  576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 12, 12, 192)  576         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 12, 12, 192)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 12, 12, 192)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_232[0][0]             \n",
            "                                                                 activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 12, 12, 128)  384         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 12, 12, 128)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 12, 12, 160)  143360      activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 12, 12, 160)  480         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 12, 12, 160)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 12, 12, 192)  215040      activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 12, 12, 192)  576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 12, 12, 192)  576         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 12, 12, 192)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 12, 12, 192)  0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_236[0][0]             \n",
            "                                                                 activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 12, 12, 128)  384         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 12, 12, 128)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 12, 12, 160)  143360      activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 12, 12, 160)  480         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 12, 12, 160)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 12, 12, 192)  215040      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 12, 12, 192)  576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 12, 12, 192)  576         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 12, 12, 192)  0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 12, 12, 192)  0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_240[0][0]             \n",
            "                                                                 activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 12, 12, 128)  384         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 12, 12, 128)  0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 12, 12, 160)  143360      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 12, 12, 160)  480         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 12, 12, 160)  0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 12, 12, 192)  215040      activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 12, 12, 192)  576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 12, 12, 192)  576         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 12, 12, 192)  0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 12, 12, 192)  0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_244[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 12, 12, 128)  384         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 12, 12, 128)  0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 12, 12, 160)  143360      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 12, 12, 160)  480         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 12, 12, 160)  0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 12, 12, 192)  215040      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 12, 12, 192)  576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 12, 12, 192)  576         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 12, 12, 192)  0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 12, 12, 192)  0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 12, 12, 128)  384         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 12, 12, 128)  0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 12, 12, 160)  143360      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 12, 12, 160)  480         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 12, 12, 160)  0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 12, 12, 192)  215040      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 12, 12, 192)  576         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 12, 12, 192)  576         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 12, 12, 192)  0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 12, 12, 192)  0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_252[0][0]             \n",
            "                                                                 activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 12, 12, 128)  384         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 12, 12, 128)  0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 12, 12, 160)  143360      activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 12, 12, 160)  480         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 12, 12, 160)  0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 12, 12, 192)  215040      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 12, 12, 192)  576         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 12, 12, 192)  576         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 12, 12, 192)  0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 12, 12, 192)  0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_256[0][0]             \n",
            "                                                                 activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 12, 12, 128)  384         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 12, 12, 128)  0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 12, 12, 160)  143360      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 12, 12, 160)  480         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 12, 12, 160)  0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 12, 12, 192)  215040      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 12, 12, 192)  576         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 12, 12, 192)  576         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 12, 12, 192)  0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 12, 12, 192)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_260[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 12, 12, 128)  384         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 12, 12, 128)  0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 12, 12, 160)  143360      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 12, 12, 160)  480         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 12, 12, 160)  0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 12, 12, 192)  215040      activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 12, 12, 192)  576         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 12, 12, 192)  576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 12, 12, 192)  0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 12, 12, 192)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_264[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 12, 12, 160)  143360      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 12, 12, 160)  480         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 12, 12, 160)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 12, 12, 192)  215040      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 12, 12, 192)  576         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 12, 12, 192)  576         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 12, 12, 192)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 12, 12, 192)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_268[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 12, 12, 160)  143360      activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 12, 12, 160)  480         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 12, 12, 160)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 12, 12, 192)  215040      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 12, 12, 192)  576         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 12, 12, 192)  576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 12, 12, 192)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 12, 12, 192)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_272[0][0]             \n",
            "                                                                 activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 12, 12, 128)  384         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 12, 12, 128)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 12, 12, 160)  143360      activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 12, 12, 160)  480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 12, 12, 160)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 12, 12, 192)  215040      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 12, 12, 192)  576         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 12, 12, 192)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_276[0][0]             \n",
            "                                                                 activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 12, 12, 128)  384         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 12, 12, 128)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 12, 12, 160)  143360      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 12, 12, 192)  215040      activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 12, 12, 192)  576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 12, 12, 192)  576         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 12, 12, 192)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 12, 12, 192)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_280[0][0]             \n",
            "                                                                 activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 12, 12, 128)  384         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 12, 12, 128)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 12, 12, 160)  143360      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 12, 12, 160)  480         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 12, 12, 160)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 12, 12, 192)  215040      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 12, 12, 192)  576         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 12, 12, 192)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_284[0][0]             \n",
            "                                                                 activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 12, 12, 128)  384         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 12, 12, 128)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 12, 12, 160)  143360      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 12, 12, 160)  480         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 12, 12, 160)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 12, 12, 192)  215040      activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 12, 12, 192)  576         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 12, 12, 192)  576         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 12, 12, 192)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 12, 12, 192)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_288[0][0]             \n",
            "                                                                 activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 12, 12, 128)  384         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 12, 12, 128)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 12, 12, 160)  143360      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 12, 12, 192)  215040      activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 12, 12, 192)  576         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 12, 12, 192)  576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 12, 12, 192)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 12, 12, 192)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_292[0][0]             \n",
            "                                                                 activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 12, 12, 128)  384         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 12, 12, 128)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 12, 12, 160)  143360      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 12, 12, 160)  480         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 12, 12, 160)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 12, 12, 192)  215040      activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_296[0][0]             \n",
            "                                                                 activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 12, 12, 256)  768         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 12, 12, 256)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 12, 12, 288)  663552      activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 12, 12, 256)  768         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 12, 12, 256)  768         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 12, 12, 288)  864         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 12, 12, 256)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 12, 12, 256)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 12, 12, 288)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 5, 5, 384)    884736      activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 5, 5, 288)    663552      activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 5, 5, 320)    829440      activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 5, 5, 384)    1152        conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 5, 5, 288)    864         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 5, 5, 320)    960         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 5, 5, 384)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 5, 5, 288)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 5, 5, 320)    0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_301[0][0]             \n",
            "                                                                 activation_303[0][0]             \n",
            "                                                                 activation_306[0][0]             \n",
            "                                                                 max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 5, 5, 192)    576         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 5, 5, 192)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 5, 5, 224)    129024      activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 5, 5, 224)    672         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 5, 5, 224)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 5, 5, 256)    172032      activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 5, 5, 192)    576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 5, 5, 256)    768         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 5, 5, 192)    0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 5, 5, 256)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_307[0][0]             \n",
            "                                                                 activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 5, 5, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 5, 5, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 5, 5, 224)    129024      activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 5, 5, 224)    672         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 5, 5, 224)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 5, 5, 256)    172032      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 5, 5, 192)    576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 5, 5, 256)    768         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 5, 5, 192)    0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 5, 5, 256)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_311[0][0]             \n",
            "                                                                 activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 5, 5, 192)    576         conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 5, 5, 192)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 5, 5, 224)    129024      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 5, 5, 224)    672         conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 5, 5, 224)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 5, 5, 256)    172032      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 5, 5, 192)    576         conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 5, 5, 256)    768         conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 5, 5, 192)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 5, 5, 256)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_315[0][0]             \n",
            "                                                                 activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 5, 5, 192)    576         conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 5, 5, 192)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 5, 5, 224)    129024      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 5, 5, 224)    672         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 5, 5, 224)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 5, 5, 256)    172032      activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 5, 5, 192)    576         conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 5, 5, 256)    768         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 5, 5, 192)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 5, 5, 256)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_319[0][0]             \n",
            "                                                                 activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 5, 5, 192)    576         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 5, 5, 192)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 5, 5, 224)    129024      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 5, 5, 224)    672         conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 5, 5, 224)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 5, 5, 256)    172032      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 5, 5, 192)    576         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 5, 5, 256)    768         conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 5, 5, 192)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 5, 5, 256)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_323[0][0]             \n",
            "                                                                 activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 5, 5, 192)    576         conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 5, 5, 192)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 5, 5, 224)    129024      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 5, 5, 224)    672         conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 5, 5, 224)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 5, 5, 256)    172032      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 5, 5, 192)    576         conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 5, 5, 256)    768         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 5, 5, 192)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 5, 5, 256)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_327[0][0]             \n",
            "                                                                 activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 5, 5, 192)    576         conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 5, 5, 192)    0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 5, 5, 224)    129024      activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 5, 5, 224)    672         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 5, 5, 224)    0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 5, 5, 256)    172032      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 5, 5, 192)    576         conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 5, 5, 256)    768         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 5, 5, 192)    0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 5, 5, 256)    0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_331[0][0]             \n",
            "                                                                 activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 5, 5, 192)    576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 5, 5, 192)    0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 5, 5, 224)    129024      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 5, 5, 224)    672         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 5, 5, 224)    0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 5, 5, 256)    172032      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 5, 5, 192)    576         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 5, 5, 256)    768         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 5, 5, 192)    0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 5, 5, 256)    0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_335[0][0]             \n",
            "                                                                 activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 5, 5, 192)    576         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 5, 5, 192)    0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 5, 5, 224)    129024      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 5, 5, 224)    672         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 5, 5, 224)    0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 5, 5, 256)    172032      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 5, 5, 192)    576         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 5, 5, 256)    768         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 5, 5, 192)    0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 5, 5, 256)    0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_339[0][0]             \n",
            "                                                                 activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 5, 5, 192)    576         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 5, 5, 192)    0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 5, 5, 224)    129024      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 5, 5, 224)    672         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 5, 5, 224)    0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 5, 5, 256)    172032      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 5, 5, 192)    576         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 5, 5, 256)    768         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 5, 5, 192)    0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 5, 5, 256)    0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_343[0][0]             \n",
            "                                                                 activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 1536)         0           conv_7b_ac[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1000)         1537000     global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4)            4004        dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 55,877,740\n",
            "Trainable params: 1,541,004\n",
            "Non-trainable params: 54,336,736\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soyV7mEu_pti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7145
        },
        "outputId": "83b0e4d3-a709-44b0-8081-6c9f591a1afd"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 200, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/200\n",
            "192/192 [==============================] - 15s 78ms/step - loss: 1.8062 - acc: 0.4688 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 2/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.8113 - acc: 0.7917 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 3/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.4845 - acc: 0.8073 - val_loss: 11.4170 - val_acc: 0.2917\n",
            "Epoch 4/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.3150 - acc: 0.8958 - val_loss: 11.4170 - val_acc: 0.2917\n",
            "Epoch 5/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2123 - acc: 0.9323 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 6/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1315 - acc: 0.9635 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 7/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1231 - acc: 0.9740 - val_loss: 11.9542 - val_acc: 0.2500\n",
            "Epoch 8/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1521 - acc: 0.9635 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 9/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0986 - acc: 0.9583 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 10/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0685 - acc: 0.9844 - val_loss: 11.5270 - val_acc: 0.2708\n",
            "Epoch 11/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1639 - acc: 0.9479 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 12/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0665 - acc: 0.9896 - val_loss: 13.4326 - val_acc: 0.1667\n",
            "Epoch 13/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0450 - acc: 0.9948 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 14/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0449 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 15/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0449 - acc: 0.9896 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 16/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1180 - acc: 0.9635 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 17/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1431 - acc: 0.9531 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 18/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0864 - acc: 0.9688 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 19/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0656 - acc: 0.9740 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 20/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0697 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 21/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.4140 - acc: 0.8958 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 22/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.6760 - acc: 0.8802 - val_loss: 11.4170 - val_acc: 0.2917\n",
            "Epoch 23/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.7352 - acc: 0.8750 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 24/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2372 - acc: 0.9115 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 25/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0489 - acc: 0.9896 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 26/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0922 - acc: 0.9688 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 27/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0625 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 28/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0674 - acc: 0.9792 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 29/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0485 - acc: 0.9844 - val_loss: 12.1435 - val_acc: 0.2292\n",
            "Epoch 30/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0950 - acc: 0.9583 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 31/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0782 - acc: 0.9688 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 32/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0527 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 33/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0183 - acc: 0.9948 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 34/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 35/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 36/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0306 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 37/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 38/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0352 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 39/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0203 - acc: 0.9896 - val_loss: 12.7603 - val_acc: 0.2083\n",
            "Epoch 40/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0752 - acc: 0.9688 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 41/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1519 - acc: 0.9375 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 42/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0841 - acc: 0.9688 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 43/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0471 - acc: 0.9844 - val_loss: 11.4170 - val_acc: 0.2917\n",
            "Epoch 44/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 45/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0506 - acc: 0.9740 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 46/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0373 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 47/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 48/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 49/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 50/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 51/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 52/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 53/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0196 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 54/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 55/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0458 - acc: 0.9792 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 56/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0515 - acc: 0.9792 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 57/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 58/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 10.9893 - val_acc: 0.3125\n",
            "Epoch 59/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 10.7455 - val_acc: 0.3333\n",
            "Epoch 60/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 10.6410 - val_acc: 0.3333\n",
            "Epoch 61/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0145 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 62/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0217 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 63/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0200 - acc: 0.9948 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 64/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0279 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 65/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 66/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 67/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 68/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 10.7089 - val_acc: 0.3333\n",
            "Epoch 69/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 70/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 12.4337 - val_acc: 0.2292\n",
            "Epoch 71/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 72/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 73/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 74/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 75/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0126 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 76/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0417 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 77/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0284 - acc: 0.9896 - val_loss: 11.0108 - val_acc: 0.3125\n",
            "Epoch 78/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0180 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 79/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0198 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 80/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1082 - acc: 0.9635 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 81/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0681 - acc: 0.9792 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 82/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0305 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 83/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0167 - acc: 0.9948 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 84/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0147 - acc: 0.9948 - val_loss: 11.4170 - val_acc: 0.2917\n",
            "Epoch 85/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 86/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0144 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 87/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0280 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 88/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 89/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0383 - acc: 0.9896 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 90/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1059 - acc: 0.9688 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 91/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0690 - acc: 0.9792 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 92/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0309 - acc: 0.9948 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 93/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0422 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 94/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 95/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 96/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0242 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 97/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 98/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0552 - acc: 0.9792 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 99/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2090 - acc: 0.9375 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 100/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0880 - acc: 0.9583 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 101/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0215 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 102/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0714 - acc: 0.9688 - val_loss: 11.0090 - val_acc: 0.3125\n",
            "Epoch 103/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0471 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 104/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0243 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 105/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0257 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 106/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 107/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0302 - acc: 0.9896 - val_loss: 12.1568 - val_acc: 0.2292\n",
            "Epoch 108/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.5046e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 109/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 110/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 111/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 112/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0315 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 113/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0504 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 114/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0207 - acc: 0.9948 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 115/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2579 - acc: 0.9427 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 116/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1885 - acc: 0.9115 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 117/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0710 - acc: 0.9635 - val_loss: 11.1335 - val_acc: 0.2917\n",
            "Epoch 118/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2287 - acc: 0.9531 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 119/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1565 - acc: 0.9323 - val_loss: 13.0961 - val_acc: 0.1875\n",
            "Epoch 120/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1179 - acc: 0.9635 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 121/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.3667 - acc: 0.8854 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 122/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1086 - acc: 0.9688 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 123/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0463 - acc: 0.9844 - val_loss: 12.4244 - val_acc: 0.2292\n",
            "Epoch 124/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1480 - acc: 0.9375 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 125/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.1414 - acc: 0.9531 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 126/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.2653 - acc: 0.9115 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 127/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.3116 - acc: 0.9271 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 128/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0484 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 129/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0217 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 130/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0201 - acc: 0.9948 - val_loss: 10.8094 - val_acc: 0.3125\n",
            "Epoch 131/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 132/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 133/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 134/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 135/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 136/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 137/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0202 - acc: 0.9844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 138/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 139/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 140/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0117 - acc: 0.9948 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 141/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 142/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0201 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 143/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 144/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 10.4096 - val_acc: 0.3542\n",
            "Epoch 145/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0169 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 146/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 11.7528 - val_acc: 0.2708\n",
            "Epoch 147/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0323 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 148/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 6.6487e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 149/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0176 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 150/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0069 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 151/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 152/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 153/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.4215e-04 - acc: 1.0000 - val_loss: 11.0817 - val_acc: 0.3125\n",
            "Epoch 154/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 155/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 156/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 157/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 3.7250e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 158/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0056 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 159/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 9.0380e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 160/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0234 - acc: 0.9948 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 161/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 162/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0164 - acc: 0.9896 - val_loss: 11.7529 - val_acc: 0.2708\n",
            "Epoch 163/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 9.0475e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 164/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0113 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 165/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 166/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 167/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 4.0038e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 168/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 9.2501e-04 - acc: 1.0000 - val_loss: 11.7528 - val_acc: 0.2708\n",
            "Epoch 169/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.4285e-04 - acc: 1.0000 - val_loss: 10.9642 - val_acc: 0.3125\n",
            "Epoch 170/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 10.7485 - val_acc: 0.3333\n",
            "Epoch 171/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 4.8220e-04 - acc: 1.0000 - val_loss: 10.4096 - val_acc: 0.3542\n",
            "Epoch 172/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 173/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.7144e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 174/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 175/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 176/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 10.4096 - val_acc: 0.3542\n",
            "Epoch 177/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 178/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0056 - acc: 0.9948 - val_loss: 11.2391 - val_acc: 0.2917\n",
            "Epoch 179/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 180/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 6.5410e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 181/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0223 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 182/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 13.7675 - val_acc: 0.1458\n",
            "Epoch 183/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0272 - acc: 0.9896 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 184/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 4.1137e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 185/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 5.4259e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 186/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 187/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 7.0173e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 188/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.4985e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 189/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 190/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 191/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 192/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 193/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 10.6774 - val_acc: 0.3333\n",
            "Epoch 194/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 3.8145e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 195/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 196/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 197/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.2886e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 198/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.4009e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 199/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 2.6958e-04 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 200/200\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 11.0812 - val_acc: 0.3125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UIfryv3X_x5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "2a0f6d89-e534-47c1-a6da-7bc8feaaedf2"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FXT-72Y0_z1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "6b6a0035-f93c-4f3a-f7ee-9ecdb345ece7"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYRKSNMWQgghVOI/x8P6iHbtoj0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rS0z0ltGAGSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "9cfe18f0-b1cc-40ff-84ee-7336142951b2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        19\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.30      1.00      0.46        18\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.30      0.30      0.30        60\n",
            "   macro avg       0.07      0.25      0.12        60\n",
            "weighted avg       0.09      0.30      0.14        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aqO_K2UGAKmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "a1dccd09-1318-48ac-9561-e20d68a7e36e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['apple', 'banana', 'orange', 'mixed'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAG+CAYAAAC+rlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZI0SfwHts3gTR3PiOIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AVLcqfn3DSai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27163
        },
        "outputId": "2f24ef22-7b59-4213-cf14-c8fd44f3c89f"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.densenet import DenseNet201\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model =  DenseNet201(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 3s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
            "                                                                 conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
            "                                                                 conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
            "                                                                 conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
            "                                                                 conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
            "                                                                 conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
            "                                                                 conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
            "                                                                 conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
            "                                                                 conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_0_bn (BatchNormal (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_0_relu (Activatio (None, 14, 14, 1280) 0           conv4_block33_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 14, 14, 128)  163840      conv4_block33_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_concat (Concatena (None, 14, 14, 1312) 0           conv4_block32_concat[0][0]       \n",
            "                                                                 conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_0_bn (BatchNormal (None, 14, 14, 1312) 5248        conv4_block33_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_0_relu (Activatio (None, 14, 14, 1312) 0           conv4_block34_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 14, 14, 128)  167936      conv4_block34_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_concat (Concatena (None, 14, 14, 1344) 0           conv4_block33_concat[0][0]       \n",
            "                                                                 conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_0_bn (BatchNormal (None, 14, 14, 1344) 5376        conv4_block34_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_0_relu (Activatio (None, 14, 14, 1344) 0           conv4_block35_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 14, 14, 128)  172032      conv4_block35_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_concat (Concatena (None, 14, 14, 1376) 0           conv4_block34_concat[0][0]       \n",
            "                                                                 conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_0_bn (BatchNormal (None, 14, 14, 1376) 5504        conv4_block35_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_0_relu (Activatio (None, 14, 14, 1376) 0           conv4_block36_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 14, 14, 128)  176128      conv4_block36_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_concat (Concatena (None, 14, 14, 1408) 0           conv4_block35_concat[0][0]       \n",
            "                                                                 conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_0_bn (BatchNormal (None, 14, 14, 1408) 5632        conv4_block36_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_0_relu (Activatio (None, 14, 14, 1408) 0           conv4_block37_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_conv (Conv2D)   (None, 14, 14, 128)  180224      conv4_block37_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block37_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block37_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block37_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_concat (Concatena (None, 14, 14, 1440) 0           conv4_block36_concat[0][0]       \n",
            "                                                                 conv4_block37_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_0_bn (BatchNormal (None, 14, 14, 1440) 5760        conv4_block37_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_0_relu (Activatio (None, 14, 14, 1440) 0           conv4_block38_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_conv (Conv2D)   (None, 14, 14, 128)  184320      conv4_block38_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block38_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block38_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block38_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_concat (Concatena (None, 14, 14, 1472) 0           conv4_block37_concat[0][0]       \n",
            "                                                                 conv4_block38_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_0_bn (BatchNormal (None, 14, 14, 1472) 5888        conv4_block38_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_0_relu (Activatio (None, 14, 14, 1472) 0           conv4_block39_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_conv (Conv2D)   (None, 14, 14, 128)  188416      conv4_block39_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block39_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block39_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block39_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_concat (Concatena (None, 14, 14, 1504) 0           conv4_block38_concat[0][0]       \n",
            "                                                                 conv4_block39_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_0_bn (BatchNormal (None, 14, 14, 1504) 6016        conv4_block39_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_0_relu (Activatio (None, 14, 14, 1504) 0           conv4_block40_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_conv (Conv2D)   (None, 14, 14, 128)  192512      conv4_block40_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block40_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block40_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block40_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_concat (Concatena (None, 14, 14, 1536) 0           conv4_block39_concat[0][0]       \n",
            "                                                                 conv4_block40_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_0_bn (BatchNormal (None, 14, 14, 1536) 6144        conv4_block40_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_0_relu (Activatio (None, 14, 14, 1536) 0           conv4_block41_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_conv (Conv2D)   (None, 14, 14, 128)  196608      conv4_block41_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block41_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block41_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block41_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_concat (Concatena (None, 14, 14, 1568) 0           conv4_block40_concat[0][0]       \n",
            "                                                                 conv4_block41_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_0_bn (BatchNormal (None, 14, 14, 1568) 6272        conv4_block41_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_0_relu (Activatio (None, 14, 14, 1568) 0           conv4_block42_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_conv (Conv2D)   (None, 14, 14, 128)  200704      conv4_block42_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block42_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block42_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block42_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_concat (Concatena (None, 14, 14, 1600) 0           conv4_block41_concat[0][0]       \n",
            "                                                                 conv4_block42_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_0_bn (BatchNormal (None, 14, 14, 1600) 6400        conv4_block42_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_0_relu (Activatio (None, 14, 14, 1600) 0           conv4_block43_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_conv (Conv2D)   (None, 14, 14, 128)  204800      conv4_block43_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block43_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block43_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block43_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_concat (Concatena (None, 14, 14, 1632) 0           conv4_block42_concat[0][0]       \n",
            "                                                                 conv4_block43_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_0_bn (BatchNormal (None, 14, 14, 1632) 6528        conv4_block43_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_0_relu (Activatio (None, 14, 14, 1632) 0           conv4_block44_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_conv (Conv2D)   (None, 14, 14, 128)  208896      conv4_block44_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block44_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block44_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block44_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_concat (Concatena (None, 14, 14, 1664) 0           conv4_block43_concat[0][0]       \n",
            "                                                                 conv4_block44_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_0_bn (BatchNormal (None, 14, 14, 1664) 6656        conv4_block44_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_0_relu (Activatio (None, 14, 14, 1664) 0           conv4_block45_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_conv (Conv2D)   (None, 14, 14, 128)  212992      conv4_block45_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block45_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block45_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block45_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_concat (Concatena (None, 14, 14, 1696) 0           conv4_block44_concat[0][0]       \n",
            "                                                                 conv4_block45_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_0_bn (BatchNormal (None, 14, 14, 1696) 6784        conv4_block45_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_0_relu (Activatio (None, 14, 14, 1696) 0           conv4_block46_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_conv (Conv2D)   (None, 14, 14, 128)  217088      conv4_block46_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block46_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block46_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block46_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_concat (Concatena (None, 14, 14, 1728) 0           conv4_block45_concat[0][0]       \n",
            "                                                                 conv4_block46_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_0_bn (BatchNormal (None, 14, 14, 1728) 6912        conv4_block46_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_0_relu (Activatio (None, 14, 14, 1728) 0           conv4_block47_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_conv (Conv2D)   (None, 14, 14, 128)  221184      conv4_block47_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block47_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block47_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block47_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_concat (Concatena (None, 14, 14, 1760) 0           conv4_block46_concat[0][0]       \n",
            "                                                                 conv4_block47_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_0_bn (BatchNormal (None, 14, 14, 1760) 7040        conv4_block47_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_0_relu (Activatio (None, 14, 14, 1760) 0           conv4_block48_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_conv (Conv2D)   (None, 14, 14, 128)  225280      conv4_block48_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block48_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block48_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block48_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_concat (Concatena (None, 14, 14, 1792) 0           conv4_block47_concat[0][0]       \n",
            "                                                                 conv4_block48_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1792) 7168        conv4_block48_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1792) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 896)  1605632     pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 896)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 896)    3584        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 896)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 928)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 928)    3712        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 928)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    118784      conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 960)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 960)    3840        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 960)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    122880      conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 992)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 992)    3968        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 992)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    126976      conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 1024)   0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 1024)   0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    131072      conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 1056)   0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 1056)   4224        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 1056)   0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    135168      conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 1088)   0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 1088)   4352        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 1088)   0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    139264      conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 1120)   0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 1120)   4480        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 1120)   0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    143360      conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 1152)   0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 1152)   4608        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 1152)   0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    147456      conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 1184)   0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 1216)   0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 1248)   0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 1280)   0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 1312)   0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 1344)   0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 1376)   0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1408)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_concat (Concatena (None, 7, 7, 1440)   0           conv5_block16_concat[0][0]       \n",
            "                                                                 conv5_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_concat (Concatena (None, 7, 7, 1472)   0           conv5_block17_concat[0][0]       \n",
            "                                                                 conv5_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_concat (Concatena (None, 7, 7, 1504)   0           conv5_block18_concat[0][0]       \n",
            "                                                                 conv5_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_concat (Concatena (None, 7, 7, 1536)   0           conv5_block19_concat[0][0]       \n",
            "                                                                 conv5_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_concat (Concatena (None, 7, 7, 1568)   0           conv5_block20_concat[0][0]       \n",
            "                                                                 conv5_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_concat (Concatena (None, 7, 7, 1600)   0           conv5_block21_concat[0][0]       \n",
            "                                                                 conv5_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_concat (Concatena (None, 7, 7, 1632)   0           conv5_block22_concat[0][0]       \n",
            "                                                                 conv5_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_concat (Concatena (None, 7, 7, 1664)   0           conv5_block23_concat[0][0]       \n",
            "                                                                 conv5_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1664)   6656        conv5_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_0_relu (Activatio (None, 7, 7, 1664)   0           conv5_block25_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    212992      conv5_block25_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_concat (Concatena (None, 7, 7, 1696)   0           conv5_block24_concat[0][0]       \n",
            "                                                                 conv5_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1696)   6784        conv5_block25_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_0_relu (Activatio (None, 7, 7, 1696)   0           conv5_block26_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    217088      conv5_block26_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_concat (Concatena (None, 7, 7, 1728)   0           conv5_block25_concat[0][0]       \n",
            "                                                                 conv5_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1728)   6912        conv5_block26_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_0_relu (Activatio (None, 7, 7, 1728)   0           conv5_block27_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    221184      conv5_block27_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_concat (Concatena (None, 7, 7, 1760)   0           conv5_block26_concat[0][0]       \n",
            "                                                                 conv5_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1760)   7040        conv5_block27_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_0_relu (Activatio (None, 7, 7, 1760)   0           conv5_block28_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    225280      conv5_block28_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_concat (Concatena (None, 7, 7, 1792)   0           conv5_block27_concat[0][0]       \n",
            "                                                                 conv5_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1792)   7168        conv5_block28_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_0_relu (Activatio (None, 7, 7, 1792)   0           conv5_block29_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    229376      conv5_block29_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_concat (Concatena (None, 7, 7, 1824)   0           conv5_block28_concat[0][0]       \n",
            "                                                                 conv5_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1824)   7296        conv5_block29_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_0_relu (Activatio (None, 7, 7, 1824)   0           conv5_block30_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    233472      conv5_block30_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_concat (Concatena (None, 7, 7, 1856)   0           conv5_block29_concat[0][0]       \n",
            "                                                                 conv5_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1856)   7424        conv5_block30_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_0_relu (Activatio (None, 7, 7, 1856)   0           conv5_block31_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    237568      conv5_block31_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_concat (Concatena (None, 7, 7, 1888)   0           conv5_block30_concat[0][0]       \n",
            "                                                                 conv5_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1888)   7552        conv5_block31_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_0_relu (Activatio (None, 7, 7, 1888)   0           conv5_block32_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    241664      conv5_block32_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_concat (Concatena (None, 7, 7, 1920)   0           conv5_block31_concat[0][0]       \n",
            "                                                                 conv5_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1920)   7680        conv5_block32_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1920)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 1920)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1000)         1921000     global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 4)            4004        dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 20,246,988\n",
            "Trainable params: 1,925,004\n",
            "Non-trainable params: 18,321,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h5mUFitlDoA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7145
        },
        "outputId": "8b93d0eb-73be-4ab0-a4f6-d3dc43b6c1a7"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 200, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/200\n",
            "192/192 [==============================] - 23s 119ms/step - loss: 2.4255 - acc: 0.4062 - val_loss: 8.7301 - val_acc: 0.3750\n",
            "Epoch 2/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.6245 - acc: 0.7188 - val_loss: 4.2174 - val_acc: 0.4375\n",
            "Epoch 3/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.2116 - acc: 0.8906 - val_loss: 9.1741 - val_acc: 0.3333\n",
            "Epoch 4/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.0776 - acc: 0.9010 - val_loss: 6.7203 - val_acc: 0.5000\n",
            "Epoch 5/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.6552 - acc: 0.9219 - val_loss: 4.6859 - val_acc: 0.3750\n",
            "Epoch 6/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.1586 - acc: 0.9427 - val_loss: 6.0885 - val_acc: 0.4375\n",
            "Epoch 7/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0928 - acc: 0.9844 - val_loss: 6.6210 - val_acc: 0.4583\n",
            "Epoch 8/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0961 - acc: 0.9688 - val_loss: 5.9397 - val_acc: 0.4583\n",
            "Epoch 9/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0325 - acc: 1.0000 - val_loss: 6.1468 - val_acc: 0.4375\n",
            "Epoch 10/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 6.7643 - val_acc: 0.4792\n",
            "Epoch 11/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 6.6302 - val_acc: 0.5208\n",
            "Epoch 12/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 5.8383 - val_acc: 0.5208\n",
            "Epoch 13/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 6.6763 - val_acc: 0.4792\n",
            "Epoch 14/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 7.1373 - val_acc: 0.5000\n",
            "Epoch 15/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 7.3284 - val_acc: 0.4792\n",
            "Epoch 16/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 7.1395 - val_acc: 0.4792\n",
            "Epoch 17/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 6.9773 - val_acc: 0.5000\n",
            "Epoch 18/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 7.1136 - val_acc: 0.5000\n",
            "Epoch 19/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 7.1806 - val_acc: 0.5000\n",
            "Epoch 20/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 7.3771 - val_acc: 0.4583\n",
            "Epoch 21/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 7.0241 - val_acc: 0.5000\n",
            "Epoch 22/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.9133 - val_acc: 0.5000\n",
            "Epoch 23/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 6.3150 - val_acc: 0.5208\n",
            "Epoch 24/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 6.8471 - val_acc: 0.5000\n",
            "Epoch 25/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 6.8385 - val_acc: 0.5000\n",
            "Epoch 26/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.1602 - val_acc: 0.5208\n",
            "Epoch 27/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.7354 - val_acc: 0.5208\n",
            "Epoch 28/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 5.9497 - val_acc: 0.5208\n",
            "Epoch 29/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.1426 - val_acc: 0.5000\n",
            "Epoch 30/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3697 - val_acc: 0.5208\n",
            "Epoch 31/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 6.6954 - val_acc: 0.5208\n",
            "Epoch 32/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 6.7631 - val_acc: 0.5000\n",
            "Epoch 33/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.3673 - val_acc: 0.4583\n",
            "Epoch 34/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 5.3863 - val_acc: 0.5000\n",
            "Epoch 35/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 5.3224 - val_acc: 0.4792\n",
            "Epoch 36/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 5.8022 - val_acc: 0.5000\n",
            "Epoch 37/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 6.2695 - val_acc: 0.5000\n",
            "Epoch 38/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8370 - val_acc: 0.5208\n",
            "Epoch 39/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.6558 - val_acc: 0.5417\n",
            "Epoch 40/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.6890 - val_acc: 0.5417\n",
            "Epoch 41/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 6.6044 - val_acc: 0.5208\n",
            "Epoch 42/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.5177 - val_acc: 0.5208\n",
            "Epoch 43/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.4521e-04 - acc: 1.0000 - val_loss: 6.4059 - val_acc: 0.5208\n",
            "Epoch 44/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.6981 - val_acc: 0.5000\n",
            "Epoch 45/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8866 - val_acc: 0.5000\n",
            "Epoch 46/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.8679e-04 - acc: 1.0000 - val_loss: 7.0146 - val_acc: 0.5208\n",
            "Epoch 47/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.9908e-04 - acc: 1.0000 - val_loss: 7.0369 - val_acc: 0.4792\n",
            "Epoch 48/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 6.9027 - val_acc: 0.5000\n",
            "Epoch 49/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 6.5000 - val_acc: 0.5417\n",
            "Epoch 50/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.1349 - val_acc: 0.5208\n",
            "Epoch 51/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.4888 - val_acc: 0.5208\n",
            "Epoch 52/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 6.8118 - val_acc: 0.5417\n",
            "Epoch 53/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.1746 - val_acc: 0.5208\n",
            "Epoch 54/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.3348e-04 - acc: 1.0000 - val_loss: 5.9521 - val_acc: 0.5208\n",
            "Epoch 55/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.0926 - val_acc: 0.5208\n",
            "Epoch 56/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 7.4874 - val_acc: 0.4375\n",
            "Epoch 57/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.7647e-04 - acc: 1.0000 - val_loss: 8.2226 - val_acc: 0.3958\n",
            "Epoch 58/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 8.2223 - val_acc: 0.3958\n",
            "Epoch 59/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.8865e-04 - acc: 1.0000 - val_loss: 7.2372 - val_acc: 0.4792\n",
            "Epoch 60/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.8253 - val_acc: 0.5208\n",
            "Epoch 61/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.5280e-04 - acc: 1.0000 - val_loss: 6.6863 - val_acc: 0.5208\n",
            "Epoch 62/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.5576e-04 - acc: 1.0000 - val_loss: 6.7896 - val_acc: 0.5417\n",
            "Epoch 63/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0203 - val_acc: 0.5417\n",
            "Epoch 64/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.8978e-04 - acc: 1.0000 - val_loss: 7.1541 - val_acc: 0.4792\n",
            "Epoch 65/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.7636e-04 - acc: 1.0000 - val_loss: 7.1922 - val_acc: 0.4792\n",
            "Epoch 66/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.2404 - val_acc: 0.4792\n",
            "Epoch 67/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.7176e-04 - acc: 1.0000 - val_loss: 7.2168 - val_acc: 0.4792\n",
            "Epoch 68/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.3808e-04 - acc: 1.0000 - val_loss: 7.2287 - val_acc: 0.4792\n",
            "Epoch 69/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.2898e-04 - acc: 1.0000 - val_loss: 7.2000 - val_acc: 0.4792\n",
            "Epoch 70/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.8497e-04 - acc: 1.0000 - val_loss: 7.1223 - val_acc: 0.5208\n",
            "Epoch 71/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.3571e-04 - acc: 1.0000 - val_loss: 7.0532 - val_acc: 0.5417\n",
            "Epoch 72/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.4058 - val_acc: 0.4167\n",
            "Epoch 73/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.8431e-04 - acc: 1.0000 - val_loss: 7.7265 - val_acc: 0.3958\n",
            "Epoch 74/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.7150e-04 - acc: 1.0000 - val_loss: 7.6468 - val_acc: 0.4167\n",
            "Epoch 75/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.9487e-04 - acc: 1.0000 - val_loss: 7.6071 - val_acc: 0.4375\n",
            "Epoch 76/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.7085e-04 - acc: 1.0000 - val_loss: 7.5272 - val_acc: 0.4375\n",
            "Epoch 77/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.9376e-04 - acc: 1.0000 - val_loss: 7.3128 - val_acc: 0.4583\n",
            "Epoch 78/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.8350e-04 - acc: 1.0000 - val_loss: 7.3000 - val_acc: 0.4792\n",
            "Epoch 79/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.3229e-04 - acc: 1.0000 - val_loss: 7.2760 - val_acc: 0.4792\n",
            "Epoch 80/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.8286e-04 - acc: 1.0000 - val_loss: 7.2774 - val_acc: 0.4792\n",
            "Epoch 81/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.1703e-04 - acc: 1.0000 - val_loss: 7.2721 - val_acc: 0.4792\n",
            "Epoch 82/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.9977e-04 - acc: 1.0000 - val_loss: 7.2599 - val_acc: 0.4792\n",
            "Epoch 83/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.5580e-04 - acc: 1.0000 - val_loss: 7.2508 - val_acc: 0.5000\n",
            "Epoch 84/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.5284e-04 - acc: 1.0000 - val_loss: 7.2504 - val_acc: 0.4792\n",
            "Epoch 85/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.0974e-04 - acc: 1.0000 - val_loss: 7.3477 - val_acc: 0.4583\n",
            "Epoch 86/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.0021e-04 - acc: 1.0000 - val_loss: 7.5856 - val_acc: 0.4583\n",
            "Epoch 87/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.5031e-04 - acc: 1.0000 - val_loss: 7.6422 - val_acc: 0.4167\n",
            "Epoch 88/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.0172e-04 - acc: 1.0000 - val_loss: 7.5583 - val_acc: 0.4375\n",
            "Epoch 89/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.6657e-04 - acc: 1.0000 - val_loss: 7.4167 - val_acc: 0.4583\n",
            "Epoch 90/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.3013 - val_acc: 0.4792\n",
            "Epoch 91/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.0464e-04 - acc: 1.0000 - val_loss: 7.5555 - val_acc: 0.4792\n",
            "Epoch 92/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3064 - val_acc: 0.4583\n",
            "Epoch 93/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.5516e-04 - acc: 1.0000 - val_loss: 7.3032 - val_acc: 0.4792\n",
            "Epoch 94/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.1236e-04 - acc: 1.0000 - val_loss: 7.2793 - val_acc: 0.4792\n",
            "Epoch 95/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.1673e-04 - acc: 1.0000 - val_loss: 7.2524 - val_acc: 0.5000\n",
            "Epoch 96/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.9688e-04 - acc: 1.0000 - val_loss: 7.2211 - val_acc: 0.5208\n",
            "Epoch 97/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.5976e-04 - acc: 1.0000 - val_loss: 7.1089 - val_acc: 0.5208\n",
            "Epoch 98/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.5166e-04 - acc: 1.0000 - val_loss: 7.0374 - val_acc: 0.5000\n",
            "Epoch 99/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.1547 - val_acc: 0.5000\n",
            "Epoch 100/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9059e-04 - acc: 1.0000 - val_loss: 7.0467 - val_acc: 0.5208\n",
            "Epoch 101/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.1330e-04 - acc: 1.0000 - val_loss: 6.9865 - val_acc: 0.5208\n",
            "Epoch 102/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.7718e-04 - acc: 1.0000 - val_loss: 7.0505 - val_acc: 0.5208\n",
            "Epoch 103/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.3031e-04 - acc: 1.0000 - val_loss: 7.1066 - val_acc: 0.5208\n",
            "Epoch 104/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.3415e-04 - acc: 1.0000 - val_loss: 7.2349 - val_acc: 0.4792\n",
            "Epoch 105/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.0746e-04 - acc: 1.0000 - val_loss: 7.2698 - val_acc: 0.4583\n",
            "Epoch 106/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.4726e-04 - acc: 1.0000 - val_loss: 7.2953 - val_acc: 0.4583\n",
            "Epoch 107/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.4597e-04 - acc: 1.0000 - val_loss: 7.3062 - val_acc: 0.4792\n",
            "Epoch 108/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.3476e-04 - acc: 1.0000 - val_loss: 7.3049 - val_acc: 0.4792\n",
            "Epoch 109/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.0414e-04 - acc: 1.0000 - val_loss: 7.3058 - val_acc: 0.4792\n",
            "Epoch 110/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.0377e-04 - acc: 1.0000 - val_loss: 7.3300 - val_acc: 0.4792\n",
            "Epoch 111/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.7110e-04 - acc: 1.0000 - val_loss: 7.3287 - val_acc: 0.4792\n",
            "Epoch 112/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.5578e-04 - acc: 1.0000 - val_loss: 7.3218 - val_acc: 0.4792\n",
            "Epoch 113/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9647e-04 - acc: 1.0000 - val_loss: 7.3299 - val_acc: 0.4583\n",
            "Epoch 114/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.2987e-04 - acc: 1.0000 - val_loss: 7.3209 - val_acc: 0.4792\n",
            "Epoch 115/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.9395e-05 - acc: 1.0000 - val_loss: 7.3038 - val_acc: 0.4792\n",
            "Epoch 116/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.7249e-04 - acc: 1.0000 - val_loss: 7.2416 - val_acc: 0.4583\n",
            "Epoch 117/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.2902e-04 - acc: 1.0000 - val_loss: 7.2093 - val_acc: 0.4792\n",
            "Epoch 118/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.6144e-04 - acc: 1.0000 - val_loss: 7.1835 - val_acc: 0.4792\n",
            "Epoch 119/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.6875e-04 - acc: 1.0000 - val_loss: 7.2139 - val_acc: 0.4792\n",
            "Epoch 120/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.3460e-04 - acc: 1.0000 - val_loss: 7.2301 - val_acc: 0.4792\n",
            "Epoch 121/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.3219e-04 - acc: 1.0000 - val_loss: 7.2158 - val_acc: 0.4583\n",
            "Epoch 122/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.9200e-05 - acc: 1.0000 - val_loss: 7.2145 - val_acc: 0.4583\n",
            "Epoch 123/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.4210e-04 - acc: 1.0000 - val_loss: 7.2360 - val_acc: 0.4583\n",
            "Epoch 124/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.7013e-04 - acc: 1.0000 - val_loss: 7.3367 - val_acc: 0.4792\n",
            "Epoch 125/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9496e-04 - acc: 1.0000 - val_loss: 7.4110 - val_acc: 0.4583\n",
            "Epoch 126/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.4781e-05 - acc: 1.0000 - val_loss: 7.4622 - val_acc: 0.4167\n",
            "Epoch 127/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8679e-04 - acc: 1.0000 - val_loss: 7.4886 - val_acc: 0.4167\n",
            "Epoch 128/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.6199e-04 - acc: 1.0000 - val_loss: 7.4110 - val_acc: 0.4583\n",
            "Epoch 129/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.2286e-04 - acc: 1.0000 - val_loss: 7.3652 - val_acc: 0.4792\n",
            "Epoch 130/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.3763e-05 - acc: 1.0000 - val_loss: 7.4111 - val_acc: 0.4583\n",
            "Epoch 131/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.2531e-04 - acc: 1.0000 - val_loss: 7.4271 - val_acc: 0.4583\n",
            "Epoch 132/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.9865e-05 - acc: 1.0000 - val_loss: 7.4115 - val_acc: 0.4583\n",
            "Epoch 133/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.0980e-04 - acc: 1.0000 - val_loss: 7.3345 - val_acc: 0.4792\n",
            "Epoch 134/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.1493e-04 - acc: 1.0000 - val_loss: 7.4333 - val_acc: 0.4583\n",
            "Epoch 135/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.3996e-04 - acc: 1.0000 - val_loss: 7.5614 - val_acc: 0.4375\n",
            "Epoch 136/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.4982e-05 - acc: 1.0000 - val_loss: 7.8889 - val_acc: 0.4375\n",
            "Epoch 137/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.6372e-04 - acc: 1.0000 - val_loss: 8.0252 - val_acc: 0.4167\n",
            "Epoch 138/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.7273e-04 - acc: 1.0000 - val_loss: 7.5716 - val_acc: 0.4167\n",
            "Epoch 139/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.5002e-05 - acc: 1.0000 - val_loss: 7.4542 - val_acc: 0.4792\n",
            "Epoch 140/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.7639e-04 - acc: 1.0000 - val_loss: 7.4527 - val_acc: 0.4583\n",
            "Epoch 141/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.7101e-04 - acc: 1.0000 - val_loss: 7.4433 - val_acc: 0.4375\n",
            "Epoch 142/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.4355e-04 - acc: 1.0000 - val_loss: 7.4314 - val_acc: 0.4792\n",
            "Epoch 143/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.0486e-04 - acc: 1.0000 - val_loss: 7.4368 - val_acc: 0.4792\n",
            "Epoch 144/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.3341e-04 - acc: 1.0000 - val_loss: 7.4209 - val_acc: 0.4792\n",
            "Epoch 145/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8765e-04 - acc: 1.0000 - val_loss: 7.4048 - val_acc: 0.4792\n",
            "Epoch 146/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.3100e-05 - acc: 1.0000 - val_loss: 7.3395 - val_acc: 0.4792\n",
            "Epoch 147/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.1184e-04 - acc: 1.0000 - val_loss: 7.2907 - val_acc: 0.4792\n",
            "Epoch 148/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.0435e-04 - acc: 1.0000 - val_loss: 7.5833 - val_acc: 0.4792\n",
            "Epoch 149/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.9091e-04 - acc: 1.0000 - val_loss: 7.5431 - val_acc: 0.4583\n",
            "Epoch 150/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.7791e-05 - acc: 1.0000 - val_loss: 7.5908 - val_acc: 0.4792\n",
            "Epoch 151/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.0975e-04 - acc: 1.0000 - val_loss: 7.5976 - val_acc: 0.4792\n",
            "Epoch 152/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.0485e-05 - acc: 1.0000 - val_loss: 7.5645 - val_acc: 0.4583\n",
            "Epoch 153/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.4120e-04 - acc: 1.0000 - val_loss: 7.5023 - val_acc: 0.4583\n",
            "Epoch 154/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.7639e-04 - acc: 1.0000 - val_loss: 7.4517 - val_acc: 0.4583\n",
            "Epoch 155/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.2702e-05 - acc: 1.0000 - val_loss: 7.3647 - val_acc: 0.4583\n",
            "Epoch 156/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.8046e-04 - acc: 1.0000 - val_loss: 7.3611 - val_acc: 0.4792\n",
            "Epoch 157/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.7808e-05 - acc: 1.0000 - val_loss: 7.4538 - val_acc: 0.4792\n",
            "Epoch 158/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.0095e-04 - acc: 1.0000 - val_loss: 7.5465 - val_acc: 0.4792\n",
            "Epoch 159/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.2705e-05 - acc: 1.0000 - val_loss: 7.5782 - val_acc: 0.4792\n",
            "Epoch 160/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.0297e-05 - acc: 1.0000 - val_loss: 7.5615 - val_acc: 0.4792\n",
            "Epoch 161/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.1104e-04 - acc: 1.0000 - val_loss: 7.5067 - val_acc: 0.4583\n",
            "Epoch 162/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.2108e-04 - acc: 1.0000 - val_loss: 7.4398 - val_acc: 0.4583\n",
            "Epoch 163/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.4143e-04 - acc: 1.0000 - val_loss: 7.3772 - val_acc: 0.4583\n",
            "Epoch 164/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.0439e-04 - acc: 1.0000 - val_loss: 7.3364 - val_acc: 0.4792\n",
            "Epoch 165/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.2853e-05 - acc: 1.0000 - val_loss: 7.3302 - val_acc: 0.4792\n",
            "Epoch 166/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.3876e-05 - acc: 1.0000 - val_loss: 7.3411 - val_acc: 0.4792\n",
            "Epoch 167/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.3512e-05 - acc: 1.0000 - val_loss: 7.3562 - val_acc: 0.4792\n",
            "Epoch 168/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.6331e-05 - acc: 1.0000 - val_loss: 7.3596 - val_acc: 0.4792\n",
            "Epoch 169/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.8872e-05 - acc: 1.0000 - val_loss: 7.3628 - val_acc: 0.4792\n",
            "Epoch 170/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.1824e-04 - acc: 1.0000 - val_loss: 7.3398 - val_acc: 0.4792\n",
            "Epoch 171/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.3039e-04 - acc: 1.0000 - val_loss: 7.5539 - val_acc: 0.4375\n",
            "Epoch 172/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.1608e-05 - acc: 1.0000 - val_loss: 8.2866 - val_acc: 0.3958\n",
            "Epoch 173/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.9032 - val_acc: 0.4167\n",
            "Epoch 174/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.7246e-04 - acc: 1.0000 - val_loss: 6.1865 - val_acc: 0.4583\n",
            "Epoch 175/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.9832e-04 - acc: 1.0000 - val_loss: 5.4644 - val_acc: 0.5000\n",
            "Epoch 176/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.1020e-04 - acc: 1.0000 - val_loss: 6.8712 - val_acc: 0.4792\n",
            "Epoch 177/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 5.9848e-04 - acc: 1.0000 - val_loss: 7.3803 - val_acc: 0.4583\n",
            "Epoch 178/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.5735e-05 - acc: 1.0000 - val_loss: 7.8403 - val_acc: 0.4167\n",
            "Epoch 179/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.6883e-05 - acc: 1.0000 - val_loss: 8.4056 - val_acc: 0.3958\n",
            "Epoch 180/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.5170e-04 - acc: 1.0000 - val_loss: 8.5185 - val_acc: 0.3958\n",
            "Epoch 181/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.3232e-04 - acc: 1.0000 - val_loss: 8.3632 - val_acc: 0.3958\n",
            "Epoch 182/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.2467e-05 - acc: 1.0000 - val_loss: 8.2293 - val_acc: 0.3958\n",
            "Epoch 183/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.0734e-05 - acc: 1.0000 - val_loss: 8.0744 - val_acc: 0.4167\n",
            "Epoch 184/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.0354e-05 - acc: 1.0000 - val_loss: 7.9425 - val_acc: 0.4375\n",
            "Epoch 185/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.6429e-05 - acc: 1.0000 - val_loss: 7.8051 - val_acc: 0.3958\n",
            "Epoch 186/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.7739e-05 - acc: 1.0000 - val_loss: 7.7155 - val_acc: 0.3958\n",
            "Epoch 187/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 8.9440e-04 - acc: 1.0000 - val_loss: 7.7244 - val_acc: 0.4375\n",
            "Epoch 188/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.6264e-04 - acc: 1.0000 - val_loss: 7.8413 - val_acc: 0.4583\n",
            "Epoch 189/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 7.2068e-04 - acc: 1.0000 - val_loss: 7.8085 - val_acc: 0.4583\n",
            "Epoch 190/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8925e-04 - acc: 1.0000 - val_loss: 7.5115 - val_acc: 0.4375\n",
            "Epoch 191/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.9170e-05 - acc: 1.0000 - val_loss: 7.6845 - val_acc: 0.4792\n",
            "Epoch 192/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 3.6542e-05 - acc: 1.0000 - val_loss: 7.8318 - val_acc: 0.4583\n",
            "Epoch 193/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 4.9744e-05 - acc: 1.0000 - val_loss: 7.9010 - val_acc: 0.4583\n",
            "Epoch 194/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 9.3687e-05 - acc: 1.0000 - val_loss: 7.8966 - val_acc: 0.4583\n",
            "Epoch 195/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.1380e-05 - acc: 1.0000 - val_loss: 7.8428 - val_acc: 0.4583\n",
            "Epoch 196/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.0415e-04 - acc: 1.0000 - val_loss: 7.7415 - val_acc: 0.4792\n",
            "Epoch 197/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.1170e-04 - acc: 1.0000 - val_loss: 7.6038 - val_acc: 0.4792\n",
            "Epoch 198/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.6202e-05 - acc: 1.0000 - val_loss: 7.5459 - val_acc: 0.4375\n",
            "Epoch 199/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.0699e-04 - acc: 1.0000 - val_loss: 7.4851 - val_acc: 0.4583\n",
            "Epoch 200/200\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 6.1735e-05 - acc: 1.0000 - val_loss: 7.4495 - val_acc: 0.4583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YV-wGBAWDvDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "701906b7-86ef-411c-dd51-b2d93c80392e"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4U2WiBvD3JN1om6ZNaSldEqDI\nLvteWoQLAiqOiiPFBddBxwV11BmFcRiXAnPVUa/iHUSd8SIoo6AiDqAo2gKVssiO7E26QDfadF/S\n5P4Rz2nSJmm6nLaHvr/n4SlZes7Xpsl7vl2w2Ww2EBERkWKoOrsARERE1DIMbyIiIoVheBMRESkM\nw5uIiEhhGN5EREQKw/AmIiJSGIY30RVk6dKleOuttzw+Z9OmTbjnnns6pkBEJAuGNxERkcIwvIk6\nSXZ2NqZMmYI1a9Zg1qxZmDVrFg4dOoRFixYhMTERzz33nPTcrVu34oYbbsDs2bOxcOFCmEwmAEBx\ncTHuu+8+TJ8+HYsWLUJZWZn0PWfPnsWdd96JWbNmYe7cuTh69GizZVq1ahVmzZqFGTNm4MEHH0Rp\naSkAoLq6Gn/84x8xffp0zJkzB19++aXH+5999lm888470nEdb0+fPh1vv/02Zs2ahdzcXJw/fx4L\nFizAnDlzMHPmTGzZskX6vtTUVFx//fWYNWsWHnzwQZSUlGDx4sV4//33peecPn0aEydOhMViafFr\nQKRUDG+iTlRcXIyIiAhs374dAwcOxJNPPomVK1di8+bN2LJlC0wmE3Jzc/H8889j1apV2LZtG665\n5hr85S9/AQCsWbMGYWFh+P777/GXv/wFu3btAgBYrVY88sgj+M1vfoPt27fjr3/9Kx5++GGPAXfs\n2DGsW7cOGzduxDfffIPa2lp89NFHAIAPPvgAdXV1+P777/HPf/4TL730EvLy8tze35y8vDxs374d\n0dHR+O///m9MmzYNW7duxfLly7F06VLU1dWhsrISzzzzDF5//XVs374der0eb775Jm644QangP/2\n229x7bXXwsfHpy0vBZGi8K+dqBNZLBbMnj0bADBgwAAAgE6nAwBEREQgPz8fFy5cwIQJE2AwGAAA\nv/3tb/HKK6/AYrFg//79WLRoEQAgNjYW48ePBwCcP38eRUVFuPXWWwEAY8aMgU6nw88//+y2LMOG\nDcMPP/wAPz8/AMCoUaOQlZUFwF4DfuCBBwAAUVFR+PHHHxEUFOT2/uZcc8010v/feecdiKs0jxkz\nBjU1NSgoKMD58+cRFRUl/V6eeeYZAIDNZsNzzz2H8+fPo1+/ftixYwf+9Kc/NXtOoisJw5uoE6nV\nagQEBAAAVCoVAgMDnR6rr69HcXExQkJCpPs1Gg1sNhuKi4thNpuh0Wikx8TnlZaWorq6GnPmzJEe\nKy8vR0lJiduyVFVVYcWKFdi7dy8AwGw2SyFbXFzsdB4xoN3d3xytViv9Py0tDf/7v/+L4uJiCIIA\nm80Gq9Xa5OcWLyoASM3rt956KwoKCqSLFqLuguFN1MWFh4c71ZjNZjNUKhXCwsIQEhLi1M99+fJl\nxMXFITIyEkFBQdi2bVuT423atMnleT788ENkZmZi06ZNCAoKwuuvvy41gYeFhaG4uFh67qVLl6DV\nat3er1KpYLVancrsSl1dHZ544gm88cYbmDp1KmprazF8+HCX56yqqoLZbEZUVBSuv/56rFixAhqN\nBrNmzYJKxR5A6l74F0/UxSUkJGD//v1SE/Ynn3yChIQE+Pj4YOTIkdixYwcAwGQy4cCBAwCAmJgY\nREVFSeF9+fJl/OEPf0BlZaXb8xQVFaFfv34ICgpCTk4OfvzxR+n506dPxxdffAGbzYaCggLcdNNN\nKC4udnt/REQEfvnlFwBAVlYWDh486PKcVVVVqKysxLBhwwDYLyB8fX1RWVmJMWPGoKCgAEeOHAFg\nb15ftWoVAGDy5MkoKSnB2rVrnVoXiLoL1ryJurioqCi8/PLLePjhh1FXV4fY2Fi89NJLAIAHH3wQ\nTz75JKZPn474+Hhce+21AABBEPD3v/8df/3rX/HGG29ApVLh3nvvdWqWbyw5ORmLFy/GrFmzMHDg\nQDz77LN47LHH8K9//Qv33HMPjEYjpk2bhoCAAPzpT39CdHS02/tvu+02PProo7j22msxZMgQzJo1\ny+U5Q0JC8MADD+Cmm25CeHg4fv/732PGjBl46KGHsGXLFrz11ltSX7fBYMDKlSsB2LsUZs+eje++\n+w5jxoxpz183kSII3M+biJRozZo1KC4uxh//+MfOLgpRh2OzOREpzuXLl/Hvf/8bCxYs6OyiEHUK\nhjcRKconn3yCefPm4Xe/+x3i4uI6uzhEnYLN5kRERArDmjcREZHCMLyJiIgUhuFNRESkMAxvIiIi\nhWF4ExERKQzDm4iISGEY3kRERArD8CYiIlIYhjcREZHCMLyJiIgUhuFNRESkMAxvIiIihZE1vE+f\nPo0ZM2bgo48+avLYnj17cOutt2L+/PlYtWqVnMUgIiK6osgW3pWVlXjppZcwadIkl4+//PLLeOut\nt/Dxxx9j9+7dOHv2rFxFISIiuqL4yHVgPz8/rFmzBmvWrGnyWFZWFrRaLXr37g0AmDp1KtLT09G/\nf3+5itP+Pv8cOH3a+b45c4Dhw+3///FH4KefOr5cRETUOaKjgTvvBARB9lPJFt4+Pj7w8XF9+IKC\nAuh0Oum2TqdDVlaWXEVpf3l5wLx5QOOt0F98EfjmG8BotL+A3CqdiKh7mT0biIiQ/TSyhfcV7fhx\nezDfcYf9HwBkZgKLF9tfuKoqICQE+Mc/AK22U4tKREQdpHfvDgluoJPCOzIyEoWFhdLtvLw8REZG\ndkZRWufkSfvXOXPs/0Q6HXD77UBgILBtGzBxYueUj4iIrmidMlUsNjYW5eXlyM7OhsViwc6dO5GQ\nkNAZRWkdMbwHD3a+f/58YM8eYP9+BjcREclGsNnk6Zg9duwY/va3vyEnJwc+Pj7o1asXpk+fjtjY\nWMycORP79u3Dq6++CgC49tprcf/998tRDHn8138B338PlJcDQUGdXRoiIupmZAvvK47Vah9BKAj2\nEYV+fvZ+biIiog7GFda8cfky0LMnsHIlYDYDFy82bTInIiLqIAxvbxw7BhQXA6tXAydO2O9jeBMR\nUSdheHvDaGz4+vHH9v8zvImIqJMwvL0hhjcAiCvGMbyJiKiTMLy94Rje1dX2rwxvIiLqJAxvb5hM\n9q8zZ9q/RkQA4eGdVx4iIurWGN7eMBrtYX3XXfbbrHUTEVEnYng3x2az17wNBmDuXGDAAODGGzu7\nVERE1I1xY5LmFBTYNxoxGIDQUODUqc4uERERdXOseTdH7O82GDq3HERERL9ieDdHHGmu13duOYiI\niH7F8G6OGN6seRMRURfB8G4Ow5uIiLoYhndz2OdNRERdDMO7OUYj0KMHF2UhIqIug+HdHKPRXusW\nhM4uCREREQCGt2fl5fa9vNlkTkREXQjD25MLF+xfGd5ERNSFMLw92bvX/nXkyM4tBxERkQOGtyep\nqfaviYmdWw4iIiIHgs1ms3V2Ibqsvn2B0lL7+uYqXucQEVHXwERyJysLyMwEpkxhcBMRUZfCVHIn\nLc3+lU3mRETUxTC83RHDOympc8tBRETUCPu83Rk61N5sXlIC+Pp2dmmIiIgkrHm7UlgInDgBTJ7M\n4CYioi6H4e3Krl32r+zvJiKiLojh7Qr7u4mIqAtjeLuSmmpvLp8wobNLQkRE1ATDu7HycuDnn4Fx\n4+xbgRIREXUxDO/G0tOB+nr2dxMRUZfF8G5MXM+c/d1ERNRFyRrey5cvx/z585GcnIwjR444PbZj\nxw7MmzcPCxYswEcffSRnMVomLQ0QBPs0MSIioi5ItvDOyMiA0WjEhg0bkJKSgpSUFOkxq9WKl156\nCWvWrMG6deuwc+dOXLp0Sa6ieK+mBvjpJ2D4cCA0tLNLQ0RE5JJs4Z2eno4ZM2YAAOLj42E2m1Fe\nXg4AKC4uRkhICHQ6HVQqFSZOnIg9e/bIVRTvpaXZA5z93URE1IXJFt6FhYUICwuTbut0OhQUFEj/\nr6ioQGZmJurq6rB3714UFhbKVRTvvfKK/evtt3duOYiIiDzw6agTOS6hLggCVq5ciSVLlkCj0SA2\nNrajiuHevn3AN98A06YBkyZ1dmmIiIjcki28IyMjnWrT+fn5iIiIkG6PHz8e69evBwC89tpriImJ\nkaso3lm+3P516dLOLQcREVEzZGs2T0hIwPbt2wEAx48fR2RkJIKDg6XHH3jgARQVFaGyshI7d+7E\npM6s7Z46BXzxhX1FtenTO68cREREXpCt5j169GgMHToUycnJEAQBy5Ytw6ZNm6DRaDBz5kzcdttt\nuO+++yAIAhYtWgSdTidXUZp37Jj96/z59mliREREXRj38waA9euBO+4AVq8GFi3q7NIQERF5xBXW\nAKC62v7V379zy0FEROQFhjdgn9sNAAEBnVsOIiIiLzC8gYbwZs2biIgUgOENNDSbs+ZNREQKwPAG\nWPMmIiJFYXgDHLBGRESKwvAGOGCNiIgUheENsOZNRESKwvAGWPMmIiJFYXgDrHkTEZGiMLwB1ryJ\niEhRGN4Aa95ERKQoDG+ANW8iIlIUhjdgD29BAHxk2yGViIio3TC8AXuzub8/9/ImIiJFYHgD9po3\nm8yJiEghGN5AQ82biIhIARjeAGveRESkKAxvgDVvIiJSFIY3wJo3EREpCsMbYM2biIgUheFts9lr\n3gxvIiJSCIa3xWIPcDabExGRQjC8ua45EREpDMOb65oTEZHCMLxZ8yYiIoVheLPmTURECsPwZs2b\niIgUhuHNmjcRESkMw5s1byIiUhiGt1jzZngTEZFC+Mh58OXLl+Pw4cMQBAFLlizB8OHDpcfWrVuH\nzZs3Q6VSYdiwYVi6dKmcRXGPzeZERKQwstW8MzIyYDQasWHDBqSkpCAlJUV6rLy8HO+//z7WrVuH\njz/+GOfOncOhQ4fkKopnbDYnIiKFkS2809PTMWPGDABAfHw8zGYzysvLAQC+vr7w9fVFZWUlLBYL\nqqqqoNVq5SqKZ6x5ExGRwsgW3oWFhQgLC5Nu63Q6FBQUAAD8/f3xyCOPYMaMGZg2bRpGjBiBvn37\nylUUz1jzJiIihemwAWs2m036f3l5OVavXo1t27bhu+++w+HDh/HLL790VFGcseZNREQKI1t4R0ZG\norCwULqdn5+PiIgIAMC5c+cQFxcHnU4HPz8/jB07FseOHZOrKJ6x5k1ERAojW3gnJCRg+/btAIDj\nx48jMjISwcHBAICYmBicO3cO1b8G57Fjx9CnTx+5iuIZa95ERKQwsk0VGz16NIYOHYrk5GQIgoBl\ny5Zh06ZN0Gg0mDlzJu6//34sXLgQarUao0aNwtixY+UqimeseRMRkcIINsfO6O7oz38GUlKA1FQg\nMbGzS0NERNQsrrAm1rzZbE5ERArB8ObyqEREpDAMbw5YIyIihWF4c8AaEREpDMObNW8iIlIYhjdr\n3kREpDAMb9a8iYhIYRjeYs3bz69zy0FEROQlhndNDeDrC6j4qyAiImVgYlVXs8mciIgUheFdU8PB\nakREpCgM75oa1ryJiEhRGN7V1ax5ExGRojC8WfMmIiKFYXiz5k1ERArD8GbNm4iIFKZ7h3d9PWCx\nsOZNRESK0r3Dm3t5ExGRAnXv8BaXRmWzORERKUj3Dm/WvImISIG6d3iz5k1ERArUvcObNW8iIlIg\nhjfAmjcRESlK9w5vsdmcNW8iIlKQ7h3ebDYnIiIF6t7hzQFrRESkQN07vFnzJiIiBere4c2aNxER\nKVD3Du+6OvtXX9/OLQcREVELeBXeNptN7nJ0DovF/pXhTURECuJVeE+bNg2vv/46srKy5C5PxxJr\n3j4+nVsOIiKiFvAqvD/99FNERERgyZIluPfee/HVV1+htrZW7rLJT6x5M7yJiEhBBFsL28SNRiOe\ne+45nDt3DsnJyXj44Yfh72a09vLly3H48GEIgoAlS5Zg+PDhAIC8vDw8/fTT0vOysrLw1FNPYe7c\nuW34UVph1Srg0UeBf/8b+O1vO/bcREREreT1gLV9+/bhueeew+9+9zuMHj0a69evR0hICB5//HGX\nz8/IyIDRaMSGDRuQkpKClJQU6bFevXph7dq1WLt2Lf75z3+id+/emD59ett/mpZizZuIiBTIq9Sa\nOXMmYmJicNttt+HFF1+E768DvOLj47Fjxw6X35Oeno4ZM2ZIzzObzSgvL0dwcLDT8z7//HPMmjUL\nQUFBbfk5WofhTURECuRVar333nuw2Wzo06cPAODEiRMYMmQIAGD9+vUuv6ewsBBDhw6Vbut0OhQU\nFDQJ708//RQffPBBa8redgxvIiJSIK+azTdt2oTVq1dLt9999128+uqrAABBELw6kauu9Z9//hn9\n+vVrEugdhuFNREQK5FV47927FytWrJBuv/HGGzhw4IDH74mMjERhYaF0Oz8/HxEREU7P+eGHHzBp\n0qSWlLd9MbyJiEiBvArvuro6p6lhFRUVsIjB50ZCQgK2b98OADh+/DgiIyOb1LCPHj2KQYMGtbTM\n7YfhTURECuRVaiUnJ+O6667DsGHDYLVacfToUTz66KMev2f06NEYOnQokpOTIQgCli1bhk2bNkGj\n0WDmzJkAgIKCAoSHh7f9p2gthjcRESmQ1/O8c3NzcfToUQiCgKuvvhrBwcHQaDRyl09eTz8NvPYa\nkJEBjBvX2aUhIiLyitfzvCsrK6HT6RAWFobz58/jtttuk7NcHYM1byIiUiCvUuvll1/G7t27UVhY\nCL1ej6ysLNx3331yl01+DG8iIlIgr2reR48exdatWzFo0CBs3LgRH3zwAaqqquQum/y4qxgRESmQ\nV+Ht5+cHwD7q3GazYdiwYTh48KCsBesQrHkTEZECeZVaffv2xbp16zB27Fjce++96Nu3L8rKyuQu\nm/wY3kREpEBepdYLL7wAs9mMkJAQfP311ygqKsKDDz4od9nkx/AmIiIF8iq1li9fjqVLlwJAx2/b\nKSeGNxERKZBXfd5qtRrp6emoqamB1WqV/ikew5uIiBTIq9T69NNP8eGHHzptLiIIAk6ePClbwToE\nw5uIiBTIq9RqbhMSxaqrs39leBMRkYJ4lVpvvvmmy/sff/zxdi1Mh2PNm4iIFMjrPm/xn9Vqxd69\nezlVjIiIqJN4lVqNdxCrr6/HY489JkuBOpQY3mp155aDiIioBbzemMSRxWKByWRq77J0PIvFXusW\nhM4uCRERkde8qnlPnToVgkPAmc1m3HzzzbIVqsOI4U1ERKQgXiXX+vXrpf8LgoDg4GCEhITIVqgO\nw/AmIiIF8qrZvKqqCp988gliYmIQHR2NFStW4MyZM3KXTX4MbyIiUiCvwvuFF17A1KlTpdvz5s3D\niy++KFuhOgzDm4iIFMir8K6vr8fYsWOl22PHjnVabU2xGN5ERKRAXiWXRqPB+vXrMWHCBFitVqSl\npSEoKEjussmP4U1ERAok2LyoQl++fBmvvfYajhw5AgAYPXo0Hn/8ceh0OtkLKCu93j7H+8KFzi4J\nERGR17wKbwDIzMxEnz59AAAnTpzAkCFD5CxXx4iOBoKCgCth8B0REXUbXvV5v/7661i9erV0+913\n38Wrr74qW6E6jMUC+Pp2dimIiIhaxKvw3rt3L1asWCHdfuONN66MncbY501ERArkVXjX1dWhtrZW\nul1RUQGLuC64kjG8iYhIgbxKruTkZFx33XUYNmwYrFYrjh49irvvvlvussmP4U1ERArk9YC1ffv2\nobi4GIIgoKKiAqtXr8bWrVvlLp+8/PyAsWOBPXs6uyRERERe86ramZKSgl27dqGwsBB6vR5ZWVm4\n77775C6b/FjzJiIiBfKqz/vIkSPYunUrBg0ahI0bN+KDDz5AVVWV3GWTl9UK2GwMbyIiUhyvwtvP\nzw+AfeCazWbDsGHDcPDgQVkLJjtxwB3Dm4iIFMar5Orbty/WrVuHsWPH4t5770Xfvn1RVlYmd9nk\nVVdn/8rwJiIihfFqwJrNZoPZbEZISAi+/vprFBUVYfbs2YiKiuqIMsrDbAZCQ4G5c4HNmzu7NERE\nRF7zqtopCAJCQ0MBAHPnzvX64MuXL8fhw4chCAKWLFmC4cOHS49dvHgRf/jDH1BXV4chQ4Z0/Baj\nbDYnIiKF8qrPuzUyMjJgNBqxYcMGpKSkICUlxenxlStX4r777sNnn30GtVqN3NxcuYrimhjeXB6V\niIgURrbwTk9Px4wZMwAA8fHxMJvNKC8vBwBYrVYcOHAA06dPBwAsW7YM0dHRchXFNda8iYhIoWQL\n78LCQoSFhUm3dTodCgoKANi3GA0KCsKKFSuwYMECvPbaa3IVwz2GNxERKZRs4d2Y47g4m82GvLw8\nLFy4EB999BFOnDiBH374oaOKYsfwJiIihZItvCMjI1FYWCjdzs/PR0REBAAgLCwM0dHR0Ov1UKvV\nmDRpEs509J7aDG8iIlIo2cI7ISEB27dvBwAcP34ckZGRCA4OBgD4+PggLi4OmZmZ0uN9+/aVqyiu\nMbyJiEihZEuu0aNHY+jQoUhOToYgCFi2bBk2bdoEjUaDmTNnYsmSJXj22Wdhs9kwYMAAafBah2F4\nExGRQnm9q9gVZ/9+YNw44A9/ADpjwBwREVErddiAtS6HNW8iIlIohjfDm4iIFIbhzRXWiIhIYRje\nrHkTEZHCMLwZ3kREpDAMb4Y3EREpDMOb4U1ERArD8GZ4ExGRwjC8Gd5ERKQwDG+GNxERKUz3De+6\nOvtXhjcRESlM9w1v1ryJiEihGN5cYY2IiBSG4c2aNxERKQzDm+FNREQKw/BmeBMRkcIwvBneRESk\nMAxvhrfXPjn2CRZ9tQiLvlqEj49+3ObjZZdmY0XaCtTV1zndb642468//BWlNaVtPofo3QPvSmXf\ndnZbq49zLP8YVmWsardyERG1RvdNLoZ3i9TV1+H+zfejsq4SAPDRkY8wb8g8+Kn9Wn3MVRmrsHL3\nSvTX9cdvh/5Wun/1gdV44ccXoPHT4KnJT7W57IWVhXhwy4PS7b05ezG7/+xWHeuZb5/BtrPbcOPA\nGxGnjWtz2YiIWoM1b4a3Vw5ePIjKukrcNfwu3DX8LlRZqnDw4sE2HfNCyQUAQJopzen+VGOqy/tb\na5dpFwDgyYlPwqA1IL8iv1XHqbfWY7dpNwC0a6sAEVFLdd/w5gprLSIG6Zz+czCn/xz7fca2havJ\nbHI6NmAPSDFsd5l2wWqztukcQEM55w6Yi96a3iisLITNZmvxcQ7nHUZZbRkASC0QRESdofuGN2ve\nLSLWhhMNiUg0JNrvM6W26ZhGsxEAcPjSYZRUlwCw9ymba8wAgKKqIpwsONmmcwD2iwNflS8mxE5A\nz8CesFgt0jlaQvwdAAxvIupcDG+usNYsq82KXaZd6BvaF7EhsYgNiUXf0L5tqhnX1tfiYtlFAIAN\nNuzJ2gOgoRY+OW6y0+3WKq8tx8GLBzE2eiwCfQMRERgBACioKGjxsRzLwvAmos7E8GbNu1nH84+j\nuLpYqnEDQJIhCSXVJTiWf6xVx8wyZ8EGG2I0MQAaarXi16WJS51ut1Z6VjrqbfVIMiQBAHoG9gRg\nH8TWEjabzamboKKuok3lIiJqC4Y3w7tZYo0zSZ8k3Zeotwd5a/u9xf7u3w75LdSCGmmmNHtAmtLQ\nO7g35vSfg8igSKQaU1vVPy2Smvt/La9U865sWc37VNEpFFQWwEdl/3thzZuIOlP3Ta52Du9qS7VU\nm+sd3Btqlbpdjiuy2WywWC3wVTdt5i+sLES1pVq6HeATINUwAfu86bLaMviofBAVHNXiczv2d4vE\nmuy357/Fbwb9Rro/vEc4evj2aFJ2q83q9DsR+7uHRg7F6N6jsS9nH340/ohL5Zcwf+h8CIKARH0i\nNp7ciIycDMSE2Gvo/mp/RARFNFvmyrpKXK66jJ2ZOyFAQII+AUDra97iRcrkuMlINaZeEeFts9lw\nsfwirDYrQgNCEewX3OQ5+RX5qK2vbXJ/oG8gdD10HVFMInKB4d0O4W2z2TD0naE4X3weADBv8Dx8\ndttnbT6uo/d/fh+Lty7Gkd8fQX9df+n+r059hRs/ubHJ8zfethG3DL4FJwtOYvg/hsNitf+8r896\nHU9MfMLr84q14V5BvXCV7irp/v66/ogKjsKXp77El6e+lO6P0cTgwuMXnC4yUtJS8Pf0v+Pc4nMI\n6xEGADCW2MPboDUgyZCEfbn7MO3DaQAaaslJhiRsPLkRE9+f6FSmj27+CHcMv8Ntmast1ej7Zl9p\nStiIXiMQGhAKAFLwt7TPe1eWfQT87PjZV0x4P/PtM3gt/TUAQLBfMM4vPu90YfT+wffxwFcPuPxe\nAQJ2LNyB6X2nd0hZicgZw7sdwju/Ih/ni8+jT2gfXK66jPTs9DYfs7FPT3yKKksV/nPmP1g8YbF0\n/+ZTmwEANw26CUG+QaiyVGHTyU3YfGozbhl8C7ae3QqL1YJpfabhh8wfsPnU5haF9/ni88gty8Wt\nQ26FIAjS/YIg4O05b+PzXz6X7jucdxjH8o/h4MWDmBA7Qbr/38f/jeLqYpwoOCHVgMVmc0OoAY+O\nfxTFVcWoqa+Bxk+D26++HQBw5/A7caLgBMprywHYR59vO7sNR/OPNlvm/Ip8DAwfiHEx47Bw+ELp\nMbHZvKU17zNFZ+Cj8sGo3qMAXBnN5l+e+hJBvkEYFjkMe3P2YmfmTtw29DanxwEgeVgy1EJDq8ml\n8kv47sJ3yMjJYHgTdRKGdzuEtxhENw+6GQcvHkSqMRW19bVtWn3MkcVqkUZjpxpTncI71ZQKjZ8G\nn/32M6hValhtVvT8755NBoB9eNOHuOHjG5Cend6ison93WJt2NG8IfMwb8g86fYnxz7Bgo0LkGpM\nlcL7ctVlKWxNZhMSYA9vsdk8LiQOPXx74P3fvN/k+LoeOvzjhn9It08UnMC2s9tgrvY8zUt8Pe4a\nfheWJi11ekxqNq9qWXibzCbEhsRC46cBAFTUKnvA2sWyizh7+Syuu+o6/Dnxz5j8gb07QAxvcYZB\nv7B++Hie81K4R/OOYvg/hkvaq7hoAAAgAElEQVS/ZyLqeByw1g7hLQaRXquHXquHDTZkl2a3+bii\nQ5cOSbVPcWAXAOSV5+F00Wkk6BOk/mSVoMIU/RRcKLmALHMW0kxp6BPaB3HaOCTpk1BtqcaB3ANe\nn1vs6xX7uD2RBrE5TKkSVyQDGn5P4v8jgyKb9I97IjZ9l9SUeHye2CSv1+qbPNaaZvPa+lrkluVC\nr9Uj0DcQgPJr3o6DEMdEj0EPnx5Or5s4w8DV6y7+Xh1fTyLqWN03vNtxhTXH/luD1uB0X3sQa88a\nPw3yK/Jxuug0APe1YvEDd/WB1bhcdVl6XFpcpQXTr1JNqQjxD8HVkVc3+9yYkBj0C+vnNP/bMRDE\n34nVZkWWOUv6XXlL668FgGZr3mKoGEKbHl/jp4GvyrdFzebZpdmwwQaD1oAgvyAAyg9vx0GIfmo/\nTIydiKN5R1FcVez8uIsWF22AFlp/bbv+jRNRy3Tf8Jah5m0INUiB0Z5NimIAPjLuEafbYq248Qes\nePvtjLedbruqGXsiNq1O0U/xevR8oj4RxdXFOJ5/HIA9BFSC/c/MVGr/neRX5KOmvsZlzdiTQN9A\n+Kh8ml0dTXo9XFwcCIKAiKCIFk0Vk/rntYaGmrdF2eGdZkpDgE8AxkaPBWB/3WywYXfWbulx8X5X\nDKEGGM3GNk3jI6LWkzW8ly9fjvnz5yM5ORlHjhxxemz69Om4/fbbcdddd+Guu+5CXl6enEVpSoY+\nb7HZHGi/JkWrzYo0Yxr0Wr00wlrqzzalwl/tj3Ex45y+Z3Tv0Qj0DZRCTqyJ99b0Rn9df+wy7UK9\ntb7Zczf3Ae6K+NxUYyoqaitw4OIBjIse51RTc2ypaAlBEKD110pLqbpjMpugElTS9LLGegb2bFHN\n27EZXgxvJfd5F1cV42jeUUyMnSiNfXBslbHZbEg1piIqOMppZoMjvVaP8tryZl8LIpKHbOGdkZEB\no9GIDRs2ICUlBSkpKU2es2bNGqxduxZr165Fr1695CqKa+1c8w70DUR4j/B2bzb/pfAXFFUVIcmQ\nhCERQ6DroUOaKQ3majMOXzqM8THjEeAT4PQ9vmpfTIqdBACIDIrEgPAB0mNJ+iSYa8xerYzWkv5u\n6fi/PjfNlIa9OXthsVqQqE90qql5atZujjZA23yzeYkRMZoYaUGVxiICI1BaU4oaS41X53Qsb5Cv\n8pvNd2fthg02p4uySbGT4KPyQZopDeeLz+Ni+UUk6hOdZhg4kv7O2e9N1ClkC+/09HTMmDEDABAf\nHw+z2Yzy8nK5TtdyFgugUtn//araUo3nv3++xcFrLDHCoDVAEIQmNe/PT36Oz09+3uR7vjn3De7/\n8n6nf6/sfkV6/EjeESz6ahEe/c+jAOw1WnEwWmZJJhZsXAAbbG6D1bGp3PED2FW/99sZbzsNYntr\n71u4/8v78dnJz5yaVr3RX9cfvYJ6Yfu57Vj6vX2kd5IhCQatAeW15SiuLnZqhm6p0IBQj7W9uvo6\n5JTleLwwEEecF1UVeXVOx5YCP7UfVIJKtvC22qz4266/4UTBCVmODzS89o5/O0F+QRjdezT25+7H\nQ18/1OTxxuQY20Hdz9nLZ7Fy10qvWgLJmWxTxQoLCzF06FDptk6nQ0FBAYKDG1ZxWrZsGXJycjBm\nzBg89dRTbq/yZWGxNKl17zLtwstpL8Pfxx9/TvqzV4cpqylDcXWxNDWqh28PRARGwGQ2wWK14O4v\n7gYAzB0416km+Pi2x/FL4S9NjnfH8DsQrYnGq3texdojawEAfmo/zOw3036cAXOx+dRmbD27FQBw\n/VXXuyzXjQNvxEupL+GWwbc43T8x1r7gyc+XfgZg//B9bOtjuKbPNdh5905cLLuIxdsapqL9ZuBv\nWjTlTRAEzB0wF+/9/B5+yv4JIf4hSDQkYvu57QDsTdrHC+z94fG6eK+PK9L6a1FRVwGL1eKyZp1T\nlgOrzerxwsBxc5JoTXSz5xT76vVaPQRBQKBvoGzhnWZMw7PfPYt9ufvafaEf6RymNKgFtfS3IJo7\nYC4ycjKw4/wO+Kh8MCt+lttjiBepnC5GbfHGT29g1b5VGNFrBOZcNaezi6MoHTbPu/HAlsWLFyMx\nMRFarRaPPPIItm/fjtmzZ3dUcVyGt/iBXFZT5vVhpP7ukIbBV4ZQA47mHcWhS4ek/Z8PXzqMMdFj\nANgHbP1S+Auu6XMN3pv7HgDglT2vYPWB1cgsyUS0JhqZJZkQIODkIycRERQhLUX5wOgHMCt+Fmrr\na6Hx1yAyKNJluUb1HgXzs2apj1bUJ7QPgIaWgcySTADAT9k/oba+VurnfjbhWTww+oFWNW2vnrsa\nzyU+B5vNhp6BPaEN0DrV1FKNqQgNCMWQiCEtPrY2wD7ivLSm1OXynN7U6lu6RKqxxIiIwAhpWlug\nb6BsG5OItWJxSmB7X9BW1FZgf+5+jIke02Q51KWJS3HX8LtgsVoQGhCK8MBwt8cR/y7YbE5tcaHk\nAgD73zvDu2VkazaPjIxEYWHDh2N+fj4iIhqWXrzpppsQHh4OHx8fJCUl4fTp03IVxTUX4S2uD96S\nWpWr/luD1oCa+hp8dqKh5uQ4wnuXyb7U5oy+MxCvi0e8Ll6aiiUN6jIbEa2JxsCeA5uEVJw2DvG6\neLfBLQryC2ry4R/gE4BeQb2czgNAmv8t9nPPHTgX8bp4t/3GnqgEFfqF9UO8Ll4KW/H3k56djvPF\n5zFFP0Uahd4S0lxvN03nnuZ4i6S53l6MOLfarDCZTU6vb5BvkHw171//TvIr8nHm8pl2P77jOITG\nBEGAIdSAeF28x+AG2OdN7UN8v7Z169/uSLbwTkhIwPbt9qbS48ePIzIyUmoyLysrw/3334/aWvuG\nB/v27cNVV13l9liyaK/wdjFyWvz/uqPrpPsc+5hd9Tk61mQsVgtySj3327aFIdSArNIsKZgcy9V4\nClG7nbPR78Rxh7KWaG6utzeD4VpS8y6oKEBNfY3T6ytXs7njSnpA27dDdcXV315r9AruBT+1H5vN\nqdUcB69m5GQ4ba5EzZMtvEePHo2hQ4ciOTkZL7/8MpYtW4ZNmzbh22+/hUajQVJSkjSNTKfTdWyT\nOeAyvMXRxy2Zw+s4TUwk/j+7NBtxIXGIC4lzWhktzZQGP7Wf0xQvaaBbiRG5Zbmot9W3akCXNwxa\nA2rra3Gp/JLTgKPNpzfjSN4RpylE7cXxdwI471DWElJ4u5nr7c00NMc+7+Y4rp4nkiu8f774Myrq\nKpAQZ19CVo7aiHhM8RytpRJUiAuJ44A1arWS6hJp5cja+lpk5GR0comURdY+76efftrp9qBBg6T/\n33333bj77rvlPL1nHmreLZnD67LZ3OH/SYYk2GDD+qPr8UvhL4gJicGhS4eQEJfgNMVLDBtTqcmr\npt+2cBxsJJY/RhMj1fpaWyv2RKyp1dbXItA3EKN7j27VcZprNnccXOZOS2reri4GAn0DUW2pRr21\nvl23fhVrxQ+NfQgnCk60eq90d2rra5GelY5hkcOabRb3hiHUgO8vfI9qS3WT6YpEzXH87Mkpy0Gq\nMbXNLULdSfddYa2urt36vNWC2mnUsuMHfaI+UQrDNFMa9mTtgdVmbdLn6LjkZFumUnnDcfCYyWxC\nz8CeuDb+2oYyt7JW7IlKUEmB2paavdiH7rbZvMSI8B7h0jKmrrSkz9vVxZl47CpLlXeF9pJYK55q\nmIpEQyIulFxo1zXyD148iCpLVYsW3fFE/DvKMme1y/GoexEvjMVdBNnv3TLde1cxf3+nu1oT3uJu\nU44DuxxrfY5Xkt+c+wYxmpgm94sMoQacLz7fpkVMvCEeN7MkEyazCUMihiDJkIR/HvonfFQ+0gIv\n7U2v1ePs5bNtqtl7qnnbbDaYzCYMjhjs8RjhPey1zuzS7GabfcX51o2bzQH730njEdueFFQUuP3b\nssGGXaZd0iYyifpEbD61GWnGNCy4eoFXx6+tr8XFsosAgKjgKPj72P++6631yC7NxtenvwbQ9v5u\nkeOaBleFO49ZKa4qRmlNqVfHidPGSYMXqy3VyCu3r7YYrYmW9oWvq69Dblmuy+/vGdjT7cWazWZD\nbX2t9LvwpLkWhBpLDfzUfl7PAKi31sMGW5NBn55+FnfCeoQhxD8EgP1nulh+EXX1ddD4a1zOumis\nqLJIaqJ2Ra1SI0YT4/Znq6qrQn5FfovK3NzGQ2IlZWz0WAzqOQh7sva4nQIqJ3evU2PingyA57+5\njtK9wzvY+YO3pv7XPm8vw1t8EzbuP9T10EHjp4G/jz8G9bR3FfQM7ImNJzcCsNdCJ8U1DUi9Vo8j\neUdw6NIhAPLVvMUP3QMXD6DKUgW9Vi/Vxkb3Hi3bH2Xf0L4A2laz99TnXVhZKP08nviqfREWEIb0\n7HT0ebOPV+dt3GwOtOwib8f5HZi5dmazz7vuqusANARsqjHV6/Ce8sEU7MvdBwAYFTUKBx88CACY\n/9l86W8PaNlyt56Iv5Pzxeed7j9TdAZD3xmKOmudV8dZOGIhPrzpQ9hsNoz8x0icKjoFANLaAwBw\n/frr8e35b11+f2RQJIxPGF0G7//s/R8s+X4Jjj98XJom6cqPmT9i2ofTsPWOrZjVv+n89sySTAx9\nZyhW/NcKpy15PRm5eiSGRgzFJ7d+4nT/deuvw47zO7w6hijINwjnFp9Dr+Be+J+9/4Mntj8BwP5Z\ncujBQ7i6l/uNg/bn7sf4NeNhg+d16JcmLsXL019ucn+9tR5D3hkiTSv1VlxIHDKfyHQ7q8RxPEmS\nPgnvHnwXhy4davfBss2Z/MFkRARGYMvtWzw+774v78OHhz8EYP88z3oyq1O7i7p3eLex2Ty7NNu+\nIEijGrIgCFgzdw0CfQOlK9n/vf5/8dXprwAAk2MnS1fRjsQPQ7HvU64+78bnMWjt04PemvMWRkWN\nkuWcAPDUpKcQHxaPa/pc0+pjeGo2v1x1GUDDgDRP3pj9Br678J1X5xweOdypjzjQp+Xrm391yv7a\n3zjwRqn1oDEfwQdPTX4KgD18A30DW7SJzL7cfegX1g+AfRGe7NJsRAZF4j9n/oPIoEjM7j8bI3qN\ncLvme0uJ4xb2Zu/FojGLpPu3nd2GOmsdpvWZhjhtnMdjbDm9BVtOb4HVZsWZojM4VXQKA8MHorKu\nEj9m/ghztRkqQYXvL3yP2JBYTO873en7xYvdjJwMly0KG09uRGVdJbaf3Y4Hxz7othyf//I5bLBh\n08lNLsN729ltqKyrxMaTG70K72pLNY7lH8PZy2dRY6mRav42mw17s/civEc4rh/geoGlxs5ePos9\nWXuwM3MnkoclY/PpzQCAGf1mYMf5Hdh6dqvH8N5yegtssGF2/9lup5duOLYBX53+ymV4H80/isyS\nTAyJGOJ1sO4y7cL54vO4VH7J7UJIjhsIJRoS8e7Bd5FqTO3Q8K6x1CAjJwNqQY2ymjJo/DUun2e1\nWfHV6a+g66FDZFAkfin8BReKLzTbyicnhrcDacCalwtweNq9av6w+U63bx1yK24dcqvH44nHyavI\nQ1hAmNs/pLYKDQiFxk+DvAp786R48fHo+EdlOZ9ocMTgNv+xe2o2F+9zF46OFo5YiIUjFraqDK3Z\nFlTcRGbDrRu8ulr3Vftictxk7Di/A0WVRc0OMBNDftHoRVAJKvxxxx+RZkxD37C+qLJU4Z6R9+Cd\n69/xurzeGBY5DFp/LVJNzlPaxNvv3fiedDHhzsLPF2LtkbU4UXAC6VnpAIDHJzyO3LJcvJz2MnZn\n7YaPygf1tnrcefWdWDFjhdP3f37yc9zy71tcDnaqtlRjb85eqUyewttxsx9XxN/v3uy9TmHsjjgY\nstpSjf25+5Ggt7fOlVSXoKy2DNdfdT0+vOlDj8cQ7c3ei4nvT0SqMRW3DL5FGnT44U0fIubvMUg1\npuKPCX/0+LMJELD+lvUI6xHm8jkmswk/Zv6I4qriJs8RfzfPTH4G94y8x6syP/PNM3g1/VUYS4zu\nw7vECD+1H3oF93LaE+EPk/7g1TnaQ1apvRm83laP9Ox0p7E/jk4UnMDlqstYOGIhrtJdhed3Pg+j\n2dip4d19B6x5mirm5Yeyq2libeF4HLn6u4GGxThcnber89RsLt4nPkcuLW0297SJjCdi87a4qI8n\n0vawhkSpWyLNlOZ229j2oFapkaBPwNnLZ6W+dpvNhjRjGqI10VI3iSfSNrXGtIZd7Bx/BmOa08/W\n2BT9FPvzXLRQ7MvZh9p6+1oS4m5prpirzTicdxiAfSOgxn274i5rgL1rTeya8MRxJoNj2VozGFXc\nJTDNlOY06DBaE434sHiPuwTW1tfip+yfMCxymNvgBppuCeuoNbsLerM1sslsQlxInDSYVa/VI82Y\nBqvN6vV52sqxfJ5mdzi+j7rKuv4MbwfV9S1rNm/t1pbuNF6lTU5OFwoyn6s9Sc3mLsJbrHmLz5FL\nS8Nb3MWrpQPFHPu9m5NqSpUW13H8sHcMRDk4zqQAgDOXzyCvIs/jjmRO3+9Q40ozpUHXQ4chEUMw\nKXYSVIIKaaY0pJrsNUdXc9MjgiIwuOdgabCTI/H3FuIfYh+c6GY1OHEGiNiV1fhiyWg2Irs0W3rc\nm9fDcQ0Bx+e7WjegOb5qX0yMnYhj+cfw5S9fAmj4vSUZPO8SeCDXPq6lub896XVoFGDihUu0JrrZ\nVhRHzW2NXG2pRl5FXpNptUVVRS73fJCLYwC7a3VxfCxRn9hl1vVneDsQm81r62ubfBC40t6jwl2t\n0iYXp3PJWMtvb35qP/Tw6eGy2VzsB/em2bwtpD29vexeaW3td0LMBPiqfJvt9268P7ef2k/6sN+Z\nuRN9Q/siNiS2Ref2lmMN2fGrtxcqA8IHIDIoEl+f+RqZJZnSsrkafw1G9x6NjJwM7M3eixFRI9xe\nlCXqE1FeWy4N9BSJv7dHxj3iVLbGxOc9Ou5Rl88Tw1c6jhfjEBxr3ruzdks1Y+mCv4XvOfEi6Z39\n9q4Px10DPZXJ21rzxNiJUAvqJgF25vIZ5Ffke30xJmquduqqBUIsoxwrC7ojfoarBbXUJdKY2Jok\nbq/cVdb1757hbbMB9fVum80B72pV7d1sLi5k0p7HdEd804j7kCuJuz29O6rZvKV7eqeZ0qASVJgc\nN7lF5+nh2wPjYsbh4MWDHqf5SDV7hyl44v/La8tlXfhibPRYBPgESB/6jjUUbwiCgER9ojStzPFn\nSNQnos5ah5r6Go/TC121UFisFuzO2o2B4QMxb/A8AJ4DTiWo8MTEJ+Cn9msSYGKY3zrkVgwIH4Dd\npt3NbmEpriGg66FDaU0pjuQdAeB5nIwn4kVSaU0p+oX1kwYdNtc6I97fXMtLsF8wxkSPwf7c/U5/\n161dTre5gHMV3o6tMB1FLN+18de67RK5UHIBOWU50gVMjCYGKkHF8O4U9b++8dzUvAHvPpiNZiN6\nBvZssnNXa4lLTgLy14bFiwNxm0slcbend0sGrLVFS5rNq+qqkJGTgVFRo1o1ADFRn2gfTPPrYC5X\nXPUJO/1fhv5ukVjLP5p3FMVVxUgzpiEsIAxDI4c2/80uyueu3J7Cx7GPX3T40mGU15YjUZ+IEVEj\nEOwX7DLgqi3VyMjJwMiokYgIisC46HE4dOmQ0xz1NFMaNH4ajOg1Akn6JJTVlkl95O6INe8bB97o\nVDYptFr4/p4YO1Gah+z4e+kX1g+9g3s7Lb8sqrfWY5dpF+LD4r3a+jZRnwiL1YK92Xul+1rT3w3Y\n34Mh/iFum5ZdrSI5MHwgIgIjPI5PaG9i+aSFYly0zjRuOfNV+yJGE9Ppfd7dc7R53a/zT70Mb6vN\niue/fx7ZZdlQCSo8NOYhjI8ZD5PZhKER3n9IecMQasC54nPyN5v/+uGhpP5ukdZf22RuMdDQbN6V\n+rwzcjJQZ61rde03yZCEv+3+G5Z8vwTrjq7DvSPvxdQ+U52ek2ZKa7K4jvhhb7FaZF9yMkmfhB8y\nf8D8z+bjQskFzB0wt0U7xonlC/INcpqqKA5GAzyHh16rh0FrwHfnv8PdX9iXXD53+Zx0bB+VDxLi\nErD93HbkV+Q7TZfKyMlAbX2tVLNPMiRhd9ZuLNi4AD0De8Jqs+JU0SnM7j8bapUaiYZEvPfze0gz\npnlc4lfs875l0C3416F/IdWYisUTFsNoNsJX5Yuo4Civfz+A/W9ubPRY/JT9k9PrKQgCkgxJ2HB8\nAxZsXOA0Cr6itgLmGjNuGXyLV+dIMiThtfTX8Ox3z0rrU2w5vaXFF2MivVbvtnbqqstREAQkGhKx\n6eQmGM1Gj/PyW+OV3a/gWIF9bMDtw27HrP6zYCwxoldQL8zsZ1+DYc3BNfilyLnP/UDuAQBNN5La\nk7UHdfV1OJJ3BKv2rUK9rR7RwdF4efrL7bpssjvdM7wtv/ZnN242r3fdbL7btBvLdy2XbueU5mDt\nzWtRbalu9xpykj4JR/KOYGDPge163MaGRAyBrodO1lqZXLQBWtTW1zZZEasrjjaXmi1b+Xueop+C\nsIAw7M/dj/25+5FVmoXv+jTMT6+sq8S+3H1NFtcJ9A3EdVddhwvFF9Bf179V5/bWDQNuwEupL0mL\nqIi1TW8N7zUc/XX9MS56nLSiGmAfjDbVMBUWqwW9gnt5PMaNA2/EWxlv4f8O/590Xw+fHvivfv8F\nwH4xs/3cdhy6dMhpOtDPF38GAEyInSD9LCt2rcB/zvzH6fhzB8wF4NBMbUrF4xMfd1uewip7zXtc\nzDjEaGKkmrGxxOi0olxLzBs8D0fzjkpB4/izbzi+ARuOb3D5fWLZm5OoT4TWX4uMnAynTULuGn5X\nq8pr0BpwLP8YSqpLmrSGues+mBgzEZtObsLPF39u1/DOLMnEH3c0TKfbl7MPx+KPIas0CyOjRqJX\ncC9MiJmAvTl7pT3GHem1egzvNdzp9i7TLuSW5eKFH1+Q1vAI8AnA05Ofbpe9A5rTvcPb19fpbnc1\nb7Hp6N0b3sVr6a9hT9YeqebX3jXX56c+j6VJS2VfIjA0IBSXnrrU4UsRtgfHud6ONZiOajYXQ9Kb\nRVrEvx3HWmRLhPiHwPSkCUWVRRj/3vgmTXV7s+37c7vqE95420bYbDbZu0XGxYxDwTMFKK8th5/a\nD701vVv0/WqVGscfPg610LS2smPhDq+aUN+c/Saenvy003NDA0KlVhhx2lrj358YIuJI6slxk1Hw\nTIHTa+ur9pWanQ1aA2JDYpFmTPP4uxVr3uE9wpFkSMLHxz7G0fyjyKvIw7SIac3+PK48NekpPDb+\nsSZzzG+/+nZM7zvd5WCrAJ+AZi98RGE9wpD1ZJa02JGouYV23HEctBYa5fyeNJlNECA0GUjZN+zX\n16md+5PFpu8XrnkBOzN34ofMH3As/xhq62sbFq26N1Wa8thYZFCkU21a/J7MkkzsMu2CQWvAj/f8\n6PQ3JzflfXK3Bzc1b8fwdnzzirWnGwfeiP25+/HuwXfx5Sn7lI32HlimElStusptDcdajpI47unt\nGN7mGjMECLItbiPytuYt7s89uOdgaTOU1gj2C0awXzD6hPbBoUuHYLVZpb8RTwOSOvLCLDwwvE21\nDXcb1Xj7MwiC4PG96G7esauBUz0De0o7z7k6T5IhCeuPrsepolNS83JjhZWFCAsIg6/aF4n6RHx8\n7GOsO7LOqSwtJQiC28VhWtoM747GX9Nu7x/HKVUjokY4PWYsMTqtvy+Sdlds52lY4vvkhgE3QCWo\n8EPmD1h/dL1TOf3Ufl6/NmI5/3PmPyiuLsbcgXM7fNZO9xyw5q7Z3MVoc/EDeGD4QPQK7iV9SK47\n+usbUYF9xkrnbqGWkuoSaPw1sl/8eBve4v7c7dXn7LgPu6i99ue+0rmbd2w0G+Gv9m/RxZXjwjLu\nFFQWSBcA4uu//pg9LLrLZ4a7Eef11npklWa5DLvm5oe3luOgQ/H1a8tnuFh28TXtjO5HhrcDV83m\nhy8dRlltmfTiiG9EcatGJc2RvlK4WyLVXG2WvckccAhvi+fwbmt/d2ON587W1dchPbv99ue+ksWG\nxEKA0DS8S4zQa/WtGmDnblEPq82Kosoi6YJgcMRg6HropM8MJa1o2Bbu5npfKr8Ei9XiMjQjgyIR\n4BPQriO588rzcKroFBL0CVCr1BgfMx5+ar82fYaLr6F4jM7Yh5zh7cBVeDdeoUpcxk/UXd6IXYm7\nzUnMNWbZB6sBDfO8m+vzbu/VzRo3/R68eBCVdZWKHHTY0fzUfojWRDuFQmVdJQoqC1r84T2452CE\n9wh3W/M2V5tRb6uXat4qQeX0GnW3mrep1LkJ3NMqc2L3R3vWvMUV88RxIT18e2Bc9Djp8dZ8hju+\nhpFBkbhKd5WHZ8uD4e3AcbS5uHqWq0UKxP8rcYGTK4GrmrfVZoW52twhg0W8aTa32qxIM6XBoDW0\n+9r34gdbaxfQ6K70Wj2yS7OlBVbEvZlbGqbilCaj2eiyb1ZcoMVxdzun8O4mrXVRwVHwVfk2HSTY\nzLLSeq0ehZWFLdr4xxNX40Kcpn214mIqyC9I+uxPMiR1yloZ3T68xY0LbDZbk5q3zWZDmikNsSGx\nLpfxM2gNilvg5Ergqs+7vLYcNtg6pNncT+0HlaBy++GSXZqN7y98j8tVl9t1TfHGzZCtXUCjuzKE\nGlBvq0duWS6A1q0zLhJ/51/88gUuFF9w2kxDXKDFcdCb49+BuBDTlU4lqBCnjXM5zgBwfxHT2kFr\n1ZZqlzMT0kxp8Ff7O9W2xddP46dp9WeGWP7Oev916/DOCCiC/8v++P7C91KIi9NVKusqcfbyWRRW\nFjZZ11e8amvvRQTIO+KbrbiqWLpPWqClA5rNBUFAoG+gy/B+/+D7iHs9DjPX2ufitucb27EZ0mqz\nYpdpl9NSmeSZdPHza3i0ZWMh8TPg8W2Po9//9MPirQ17fIvTxBxr3qOiRiHINwjRmuhmtxO9khi0\nBlwqv+RUMWpuZ7XW7HCd8QoAABl4SURBVNqVWZKJ8P8Ox9sZbzvdX15bjsN59h39HH/vk+MmQyWo\n0Ce0T6srYOL0w84K7+45VezXFdb2+9mvkA9fOowxvccAsK9FXFBZgMq6SmkwQuP+jIHhA7HqulVO\nV3LUccR5xDllOdJ90o5iHRDegL3f29XGJOJiDXcOvxPhPcKxYNiCdjun1l8LjZ8GxhIjjucfR3F1\ncYsXROnOpG6HEiOm6Ke0aWOhMb3H4IVrXkBmSSY+O/EZtpzegrevsweHq5q3r9oXa29e2yErb3Ul\njgO7xMWCmmvxaM2I821nt6GyrhJ7svfgsQmPSfeLrSLDIoc5PV8boMX/3fR/bZpi9+ekPyPJkISR\nUSNbfYy26J7h/WvNu1Bt7+Mury2X+rvDeoRJ4e3qTQjYa14Pj3u4AwtMjsRmR8dmNbEJvSOazQG4\nrHmLtWGD1oC1N69t93OK+7AbzUb2d7dCk5p3KzcJAeyvxV+m/gUAUFxdjC9++QImswl6rb6hz7vR\n9LObB9/c6rIrlWMtWgrvEiO0/lq341O82Qu8MbELyd0iPK4uFO4YfofXx3dlZNTITgtuoJs3mxeo\n7U055bXlUrOOrocOgH0ksbs3IXUufx9/RAVHOV2Zd9Re3iJX4X2y4CSKqopk2zsbsH8YltaUSjV8\n9nd7r3EoiKt8tbXbofG8b3cX/d1R47neNpsNRrPRY2tH44us5oh7jrv6nrZ0jXR13Tq8C1UNNW8x\nvMURhJUW9zVv6nwGrQFZ5ixpoFBH9nkDrsO7IwaQiR9C357/FlHBUbKvW34ladwcaywxIloT7XZ1\nN2813pbT1Wjz7qrx4LOS6hKU15Z7HCQozcn3ss/baDZKXZwXyy5K45ccz3sljvDv1uFdoKoCAJTV\nlkmrq4k178q6SpcDT6hrMIQaUGetk9Yi7uhm8yC/IFRbqp32de6IpmzxQ89qszYZSEmehfiHIDQg\nFMYSIyxWC7JLs9vlQ31k1EgE+wVLF2+86G/Q5ILJi64KcS15b2ve4vtOLahhg00Kcm/Pp1TdOrwL\nYa85Oda8wwLCADQs4ADwTdgV6UMa1k0GOqfZHACqLPYLQLHpLiIwAgPD5dsRzjFs2N/dcgatfcxA\nblku6m317fKh7qPyweS4yThZeBIFFQUoqCiAv9ofwX7B7VBiZRM3NRFr0d42YxtCDcgpzYHFamn2\nHGJ3xaz+s5zOAdjD20fl025rv3cl3Tq8C1yEt8ZfAx+VDypqK3gF3YU17kvrjGZzoGGhlsySTOSU\n5SDRIG9t2NV6A+Q9Q6gBlXWV0lag7VUjE1+LXaZdKKwsRM/AnmwVgX1XM8fxKd42Yxu0znPyPRHX\nLb9xgH3mhWON3VhiRFxI3BU5yr/bhrcNQCHsU33Kasuk0eYBPgEI8g2Sat4aP023mpepFI3ngnbG\naHPAxTK6Mgeq2AwZGhDaZPoLNU9ssVn2wzL77XZa/U5sBfnrj39FTlkOB7k60Gv10vgUbxfGcZzW\n54m4bvnkuMnStq7iBUKNpQYXyy9ekf3dQDcO7zJ/oBb2/krHmre/2l8ajFRYWcg3YRfVuC+to5vN\nIwMj7ecv6dilSntreqO/rj/mDZ53RdYm5DYpbhIA4HDeYagEFcbFtM9aDeNjxiMqOApH8o6gtr62\nU6cQdTUGrX18yqXySziWfwwAmh1oKa6tIT7fHWndckNSk8C/0jeC6bbzvAsDG246hneATwACfQNR\nUVeBgooCjOo9qpMKSZ40nvYj1rw7qtl8ctxkIN1e457aZ6rTloNyUgkqnHr0lKznuJLdfvXtmNlv\nJmrqaxDkG4SwHmHtctwAnwCcW3wOl6suAwCiNdHtctwrgdhKdr74vLS9cnNdkVP0UwDY31+/H/d7\nt89z3LmvNYPjlKzbhneBQ3iX1TSMNhfD22i2j0jlSPOuKTQgFCH+IU593j4qH6k5W26OHy555Xk4\nXXQas/vP7pDasNz7lV/p5GpNC/QN7LC/PyURL7Q3n9qMstoyr1qnBoQPQGRQJFKNqbDZbG7HD0jr\nlseMQ4BPACKDIp3m8QNXbnjL+imwfPlyzJ8/H8nJyThy5IjL57z22mu466675CxGU3V1bmve/j7+\nCPILkkY5crBa12XQGmAsMcJms6GkugRaf22HDRKKCIrAoJ6DsCdrD3Zm7gTAAWRErog14vVH1wPw\n7n0iCAKm6KcgpywHmSWZLp9jrjZL65YH+ARI5zKZ7Wv/i83nV2qzuWzhnZGRAaPRiA0bNiAlJQUp\nKSlNnnP27Fns27dPriK4FxSEgqCGmzX1NSivLQfQUPMWsebddem1epTVlqGkusS+l3cH9XeLkvRJ\nKK8tx1sZb9lvc+oWURNizVfci8Db94m4/7Y4GLSxPVl7YLVZm2zvWVNfg/yK/DatXa8EsoV3eno6\nZsyYAQCIj4+H2WxGeXm503NWrlyJJ598Uq4iuPeb36DwyQcB2OdoAg0LKzQOb9a8uy7H1ZtKqks6\nbKS5SFwGdU/WniZbDhKRnWN4xoXEeR2m4vtL7NduzNUMD8dZKG3Z8lUJZAvvwsJChIU1DAbR6XQo\nKCiQbm/atAnjx49HTEwnbGfo64uC3vZamvjCiuEtjjYXcbR51yV+CJwrPofKusoOG6wmcrzinxA7\ngVMKiVwQx6cALWudGtFrBDR+Grc171RjKlSCyj549FeOA1lNZhN6BfWSmtSvNB028sVxk/SSkhJs\n2rQJ9957b0edvgkxrMU9WQurGmreQb4NbeqseXdd4oWXeGXe0TVvvVYvlYH93UTuteZ9olapkaBP\nwOmi08jIycCZojPSv5MFJ7Evdx9GRY2Cxl/T5DwHLx6Udnm7Usk22jwyMhKFhYXS7fz8fERE2Gux\nP/30Ey5fvow77rgDtbW1MJlMWL58OZYsWSJXcZoQw7pPaB/7bTfN5uzz7rrEC683974JoGFp246U\nZEjCR0c+YngTedA3tC+O5R9r8Y57SfokbDu7DRPem+Dy8cbvO/EzYeXulQAaPt+vRLKFd0JCAt56\n6y0kJyfj+PHjiIyMRHCwfa3f2bNnY/bs2QCA7OxsPPfccx0a3ABQUFEAtaBGbEgsAIdmcx9/9nkr\nxNjosXg+6XlcLLsItUqNR8Y90uFlWDZ1GYZFDMOMfjM6/NxESvHCNS/guquuw5CIIS36vgdGP4BL\n5Zea7OAH2D+rn5j4hNN9w3sNxwvXvIAscxZUggoPjX2oTeXuymQL79GjR2Po0KFITk6GIAhYtmwZ\nNm3aBI1Gg5kzZ8p1Wq+J6w+LfTFua97s8+6y1Co1Xpz2YqeWob+uP/405U+dWgairm5U71GtWvAq\nIigCb8550+vnC4KAv0z9S4vPo0SyLtLy9NNPO90eNGhQk+fExsZi7dq1chbDpYLKAsSGxEo7/7gK\nbx+VT4cPgiIiImpOt1yqqa6+DiXVJegZ2FMKb3FRFn+1vzRgjTsDERFRV9Qtw7uoqgiAfTBa4z13\nHWve7O8mIqKuqFuGt+M+3Ro/jdNjjuHNkeZERORo+/btXj0vJSUFWVlZspWjW4Z3QYV9sRhXNW/H\n0easeRMRkSg7Oxtff/21V89dunQp4uLiZCtLt9xVzLHm7RjevipfqAQVgvzsfd6seRMRkejFF1/E\nkSNHMGjQINx4443Izs7Gv/71Lzz33HPIy8tDZWUlHnvsMfx/e/ceFHX1/3H8uSyLgKKoCeTXzHIU\nSdHkq6SZGpTaTUsS8wJko6ONeR1vaCo6DqZiN8WmdNJMIU1yGiZ1vOSUVkgmjtcxRSqxzAC5rEhj\n0Of3hz/2K19WxW/C8nFfj//2w6KvM8fzeXvO7ueciIgIYmNjmTdvHjt37sRut/PTTz9x7tw55syZ\nQ9++ff9xFrcs3gENA/CyevFw0MNVduep3EYvuHkwjbwa0fO+nq6KKCIiNzNjBmzZcmf/zOhoSEq6\n4Y9Hjx5NSkoK7dq1Iycnh9TUVAoKCnjssccYPHgwubm5TJ48mYiIiCq/9/vvv7NmzRr27dvHpk2b\nVLz/V33b9MU+246X1YuiP4sc1yv3pv5X439hn213VTwREannOnfuDEDjxo05duwYmzdvxsPDg6Ki\nomrvDQsLAyAoKAi7/c7UFrcs3gBeVi+AKvuY360b2IuI3HWSkm46S65tNpsNgC+++ILi4mJSU1Mp\nKipiyJAh1d7r6XnnS61bfmHtejarjQbWazNuFW8REbkRDw8PysvLq1wrLCykVatWeHh4sHv3bq5e\nvVo3Werkb6nnKj/3VvEWEZEbadu2LSdPnqyy9N2/f3/27t3Lyy+/jI+PD0FBQSQnJ9d6Fotx/Vmd\nbuqBdx/g56Kf+fe9/+aHsT+4Oo6IiMhNaeYNjsfFNPMWEREzUPEGxy5rKt4iImIGKt78Z+Zd+aiY\niIhIfabijZbNRUTEXFS8UfEWERFzUfHmP595Vz7vLSIiUp+peKOZt4iI1ExNjwStdPDgQQoKCu54\nDhVvVLxFROTWbudI0EqfffZZrRRvt93b/HqVO6xp2VxERG6k8kjQ5ORkTp8+TXFxMRUVFcydO5cO\nHTqwevVqdu/ejYeHBxEREYSGhrJnzx7OnDnDypUradmy5R3LouKNZt4iImYzY9cMtpy8s0eCRj8U\nTVL/Wx8JarFY6N27N9HR0WRnZ5OYmMi6detYu3Yt33zzDVarlU8++YRevXoREhLCvHnz7mjhBhVv\nQMVbRERq7vDhw1y6dIn09HQAysrKABgwYACvvPIKzz33HIMGDarVDCrewEMtHqKBtQEhLUJcHUVE\nRGogqX/STWfJtclmszFv3jy6du1a5frChQs5e/YsO3bsIDY2li1b7uzKwPX0hTWgc2Bn7LPtDAqu\n3f8piYiIeVUeCdqlSxf27NkDQHZ2NuvWrcNut5OcnEzbtm2ZMGECTZo04fLly1gsFioqKu54Fs28\n/5/NanN1BBERqccqjwRt1aoVFy5cYMSIEfz999+8/vrr+Pn5UVhYyJAhQ/D19aVr1674+/sTHh7O\npEmTeO+992jXrt0dy6IjQUVERExGy+YiIiImo+ItIiJiMireIiIiJqPiLSIiYjIq3iIiIiaj4i0i\nImIytfqc9+LFizly5AgWi4U5c+bQuXNnx88+/fRT0tLS8PDwoEOHDiQkJGCxWGozjoiIyF2h1mbe\n33//Pb/88gubN28mMTGRxMREx8/KysrYtm0bKSkpbNq0iZycHA4fPlxbUURERO4qtVa8MzIyePLJ\nJ4Fru9IUFxdz+fJlAHx8fFi/fj02m42ysjIuX75MixYtaiuKiIjIXaXWind+fj5NmzZ1vG7WrBl5\neXlV3rN69Wr69evHU089xX333VdbUURERO4qdfaFNWe7sI4dO5Y9e/awf/9+Dh06VFdRRERETK3W\nindAQAD5+fmO13/88YdjabyoqIiDBw8C4O3tTZ8+fcjKyqqtKCIiIneVWivevXr1YufOnQCcOHGC\ngIAAGjVqBEB5eTnx8fGUlpYCcOzYMR544IHaiiIiInJXqdVTxZYvX84PP/yAxWIhISGBkydP4ufn\nR79+/di6dSspKSl4enoSHBzMwoUL9aiYiIhIDehIUBEREZPRDmsiIiImo+ItIiJiMrW6PWp9dbNt\nW81g2bJlHDp0iPLycsaNG8fevXs5ceIE/v7+AIwePZrHH3/ctSFrIDMzk8mTJ9OuXTsA2rdvz5gx\nY5g5cyYVFRW0aNGCpKQkvLy8XJz01rZs2UJ6errj9fHjx+nUqRNXrlzB19cXgFmzZtGpUydXRayR\n06dPM378eEaNGkVMTAwXLlxw2h/p6emsX78eDw8Phg4dSnR0tKujV+OsLbNnz6a8vBxPT0+SkpJo\n0aIFHTt2JCwszPF7H330EVar1YXJq/vvtsTHxzsd82bsl0mTJlFYWAhcexLp4YcfZty4cQwcONAx\nXpo2bcqKFStcGbua/74Ph4aG1u1YMdxMZmamMXbsWMMwDCM7O9sYOnSoixPdnoyMDGPMmDGGYRjG\npUuXjL59+xqzZs0y9u7d6+Jkt+/AgQPGxIkTq1yLj483tm/fbhiGYbz55ptGSkqKK6L9I5mZmcaC\nBQuMmJgY48cff3R1nBorLS01YmJijLlz5xobNmwwDMN5f5SWlhr9+/c3SkpKjLKyMuPZZ581CgsL\nXRm9GmdtmTlzprFt2zbDMAxj48aNxtKlSw3DMIzw8HCX5awJZ21xNubN2i/Xi4+PN44cOWLk5uYa\ngwcPdkHCmnF2H67rseJ2y+Y327bVDLp37867774LQOPGjSkrK6OiosLFqe6czMxMnnjiCQAiIiLI\nyMhwcaLbt2rVKsaPH+/qGLfNy8uLNWvWEBAQ4LjmrD+OHDlCaGgofn5+eHt7ExYWVu/2aXDWloSE\nBAYMGABcm8kVFRW5Kt5tcdYWZ8zaL5VycnKw2+2mWAl1dh+u67HidsW7Jtu21mdWq9WxDJuWlkaf\nPn2wWq1s3LiRuLg4pk6dyqVLl1ycsuays7N59dVXGT58ON9++y1lZWWOZfLmzZubqm8Ajh49yr33\n3uvYkGjFihWMHDmS+fPn8+eff7o43c15enri7e1d5Zqz/sjPz6dZs2aO99THMeSsLb6+vlitVioq\nKkhNTWXgwIEAXL16lWnTpjFs2DDWrVvnirg35awtQLUxb9Z+qfTxxx8TExPjeJ2fn8+kSZMYNmxY\nlY+k6gNn9+G6Hitu+Zn39QyTPim3Z88e0tLSWLt2LcePH8ff35+QkBBWr15NcnIy8+fPd3XEW2rT\npg0TJkzg6aefJjc3l7i4uCqrCGbsm7S0NAYPHgxAXFwcwcHBtG7dmoSEBFJSUhg9erSLE/7vbtQf\nZuqniooKZs6cSY8ePejZsycAM2fOZNCgQVgsFmJiYujWrRuhoaEuTnpzzz//fLUx37Vr1yrvMVO/\nXL16lUOHDrFgwQIA/P39mTx5MoMGDcJutxMdHU2PHj1uufpQ166/D/fv399xvS7GitvNvG+2batZ\n7N+/n/fff581a9bg5+dHz549CQkJASAyMpLTp0+7OGHNBAYG8swzz2CxWGjdujX33HMPxcXFjhnq\nxYsX691gvZXMzEzHTbRfv360bt0aMFe/XM/X17dafzgbQ2bpp9mzZ3P//fczYcIEx7Xhw4fTsGFD\nfH196dGjhyn6ydmYN3O/HDx4sMpyeaNGjXjxxRex2Ww0a9aMTp06kZOT48KE1f33fbiux4rbFe+b\nbdtqBna7nWXLlvHBBx84vmk6ceJEcnNzgWvFo/Lb2/Vdeno6H374IQB5eXkUFBQQFRXl6J9du3bR\nu3dvV0a8LRcvXqRhw4Z4eXlhGAajRo2ipKQEMFe/XO/RRx+t1h9dunTh2LFjlJSUUFpaSlZWFt26\ndXNx0ltLT0/HZrMxadIkx7WcnBymTZuGYRiUl5eTlZVlin5yNubN2i9wbYvsDh06OF4fOHCAN954\nA4ArV65w6tSperWFtrP7cF2PFbdbNg8LC6Njx44MGzbMsW2rmWzfvp3CwkKmTJniuBYVFcWUKVPw\n8fHB19fX8Y++vouMjGT69Ol8+eWX/PXXXyxYsICQkBBmzZrF5s2badmyJS+88IKrY9ZYXl6e4/Mt\ni8XC0KFDGTVqFD4+PgQGBjJx4kQXJ7y548ePs3TpUn799Vc8PT3ZuXMny5cvJz4+vkp/2Gw2pk2b\nxujRo7FYLLz22mv4+fm5On4VztpSUFBAgwYNiI2NBa59YXXBggUEBQUxZMgQPDw8iIyMrHdfmHLW\nlpiYmGpj3tvb25T9snLlSvLy8hyrVADdunXj888/56WXXqKiooKxY8cSGBjowuRVObsPL1myhLlz\n59bZWNH2qCIiIibjdsvmIiIiZqfiLSIiYjIq3iIiIiaj4i0iImIyKt4iIiImo+ItIv/Y1q1bmT59\nuqtjiLgNFW8RERGTcbtNWkTc2YYNG9ixYwcVFRU8+OCDjBkzhnHjxtGnTx9OnToFwNtvv01gYCBf\nffUVq1atwtvbGx8fHxYtWkRgYCBHjhxh8eLF2Gw2mjRpwtKlSwG4fPky06dP5+zZs7Rs2ZLk5GQs\nFosrmyty19LMW8RNHD16lN27d5OSksLmzZvx8/Pju+++Izc3l6ioKFJTUwkPD2ft2rWUlZUxd+5c\nVq5cyYYNG+jTpw/vvPMOADNmzGDRokVs3LiR7t278/XXXwPXTohbtGgRW7du5cyZM5w4ccKVzRW5\nq2nmLeImMjMzOXfuHHFxccC1PaMvXryIv78/nTp1Aq5tH7x+/Xp+/vlnmjdvTlBQEADh4eFs2rSJ\nS5cuUVJSQvv27QEYNWoUcO0z79DQUHx8fIBrh87Y7fY6bqGI+1DxFnETXl5eREZGVjku9vz580RF\nRTleG4aBxWKpttx9/fUb7ahstVqr/Y6I1A4tm4u4ibCwMPbt20dpaSkAKSkp5OXlUVxczMmTJwHI\nysoiODiYNm3aUFBQwG+//QZARkYGXbp0oWnTpvj7+3P06FEA1q5dS0pKimsaJOLGNPMWcROhoaGM\nHDmS2NhYGjRoQEBAAI888giBgYFs3bqVJUuWYBgGb731Ft7e3iQmJjJ16lS8vLzw9fUlMTERgKSk\nJBYvXoynpyd+fn4kJSWxa9cuF7dOxL3oVDERN3b+/HlGjBjBvn37XB1FRG6Dls1FRERMRjNvERER\nk9HMW0RExGRUvEVERExGxVtERMRkVLxFRERMRsVbRETEZFS8RURETOb/AK5tIzR78SQJAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TDqUTqRXD091",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "8677cee1-85ee-48b0-89f2-906f016ecfdb"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFnCAYAAACcvYGMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9NZ41l1REbTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "e1a78c7f-f6e5-4c1f-ebed-58673d1db6ea"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.47      0.62        19\n",
            "           1       0.37      0.94      0.53        18\n",
            "           2       1.00      0.22      0.36        18\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.50      0.50      0.50        60\n",
            "   macro avg       0.57      0.41      0.38        60\n",
            "weighted avg       0.70      0.50      0.47        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xTewRVkrEhZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "30a013b3-7de3-46c6-a3de-8b0fccf6c299"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['apple', 'banana', 'orange', 'mixed'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAG+CAYAAACteRxWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUhYEQRCEQeLfqRfBWfB+Ry4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7BRytaD0FFcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6790
        },
        "outputId": "1cf990b3-233d-46a6-b01b-a7f8309f5d80"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.resnet50 import ResNet50\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "base_model = ResNet50(input_tensor = input_tensor, include_top = False, pooling = 'average', weights='imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(4, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 56, 56, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 56, 56, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 56, 56, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_358[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 28, 28, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 28, 28, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 28, 28, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 28, 28, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 2048)         0           activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1000)         2049000     global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 4)            4004        dense_11[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,640,716\n",
            "Trainable params: 25,587,596\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfilPVduFRue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1058
        },
        "outputId": "c69109c7-f51f-44ea-c9f0-ea954e04b45d"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 200, verbose=1,  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-669dd202e42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,256,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_5/Adam/gradients/zeros_169}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_5/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OCgAMKaDFWaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8Y3p9X5FZrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJKnpGi4FdeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vfrom sklearn.metrics import classification_report\n",
        "pred = model.predict(x_test)\n",
        "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGSvKL2JFhaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['apple', 'banana', 'orange', 'mixed'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}